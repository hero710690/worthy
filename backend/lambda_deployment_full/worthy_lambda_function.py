"""
Worthy App Complete Backend - Single File Lambda Function
Authentication system with hashlib-based password hashing
Asset management with UPDATE and DELETE functionality
Stock price caching with cachetools to reduce API calls
"""
import json
import os
import logging
import hashlib
import secrets
import jwt
import requests
import pytz
import math
from datetime import datetime, timedelta
from dateutil.relativedelta import relativedelta
from email_validator import validate_email, EmailNotValidError

# Caching imports
from cachetools import TTLCache
import threading

# Configure logging
logger = logging.getLogger()
logger.setLevel(logging.INFO)

# Initialize cache for stock prices
# TTL Cache with 5-minute expiration and max 1000 entries
# Thread-safe for Lambda concurrent executions
_cache_lock = threading.RLock()
stock_price_cache = TTLCache(maxsize=1000, ttl=1200)  # 20 minutes TTL
exchange_rate_cache = TTLCache(maxsize=100, ttl=3600)  # 1 hour TTL

logger.info("Initialized caching system - Stock prices: 5min TTL, Exchange rates: 1hr TTL")

class FIRECalculator:
    """
    Enhanced FIRE calculator based on coast-fire-calculator's proven algorithms
    with daily compounding, iterative convergence, and comprehensive edge case handling
    """
    
    def __init__(self):
        self.COMPOUNDING_PERIODS = 365  # Daily compounding for maximum accuracy
        self.MAX_CONVERGENCE_ITERATIONS = 3  # Proven optimal from coast-fire-calculator
        self.CONVERGENCE_STEPS = 10  # Number of steps in each convergence iteration
        # Legacy attributes for backward compatibility
        self.DEFAULT_INFLATION_RATE = 0.025  # 2.5% default inflation
        self.MIN_YEARS_PRECISION = 0.1  # Minimum precision for years calculation
        self.CONVERGENCE_TOLERANCE = 0.01  # 1% tolerance for convergence

def update_user_profile(user_id, profile_data):
    """Update user profile information"""
    try:
        # Validate input data
        if 'email' in profile_data:
            try:
                validate_email(profile_data['email'])
            except EmailNotValidError:
                return {"success": False, "message": "Invalid email address"}
        
        # Build update query dynamically based on provided fields
        update_fields = []
        params = []
        
        if 'name' in profile_data:
            update_fields.append("name = %s")
            params.append(profile_data['name'])
        
        if 'email' in profile_data:
            # Check if email already exists for another user
            existing_user = execute_query(
                DATABASE_URL,
                "SELECT user_id FROM users WHERE email = %s AND user_id != %s",
                (profile_data['email'], user_id)
            )
            
            if existing_user:
                return {"success": False, "message": "Email already in use by another account"}
            
            update_fields.append("email = %s")
            params.append(profile_data['email'])
        
        if 'base_currency' in profile_data:
            valid_currencies = ['USD', 'TWD', 'EUR', 'GBP', 'JPY', 'KRW', 'SGD', 'HKD']
            if profile_data['base_currency'] not in valid_currencies:
                return {"success": False, "message": "Invalid currency"}
            
            update_fields.append("base_currency = %s")
            params.append(profile_data['base_currency'])
        
        if 'birth_year' in profile_data:
            current_year = datetime.now().year
            if not isinstance(profile_data['birth_year'], int) or profile_data['birth_year'] < 1900 or profile_data['birth_year'] > current_year:
                return {"success": False, "message": "Invalid birth year"}
            
            update_fields.append("birth_year = %s")
            params.append(profile_data['birth_year'])
        
        if not update_fields:
            return {"success": False, "message": "No fields to update"}
        
        # Add user_id to params
        params.append(user_id)
        
        # Execute update query
        execute_update(
            DATABASE_URL,
            f"UPDATE users SET {', '.join(update_fields)} WHERE user_id = %s",
            tuple(params)
        )
        
        # Get updated user data
        updated_user = execute_query(
            DATABASE_URL,
            "SELECT user_id, name, email, base_currency, birth_year, created_at FROM users WHERE user_id = %s",
            (user_id,)
        )[0]
        
        # Convert datetime to string for JSON serialization
        if updated_user.get('created_at'):
            updated_user['created_at'] = updated_user['created_at'].isoformat()
        
        return {
            "success": True,
            "message": "Profile updated successfully",
            "user": updated_user
        }
    except Exception as e:
        logger.error(f"Error updating user profile: {str(e)}")
        return {"success": False, "message": f"Error updating profile: {str(e)}"}
        
    def future_value(self, principal: float, rate: float, periods: int, time: float) -> float:
        """Calculate future value with compound interest"""
        if rate == 0 or time <= 0:
            return principal
        return principal * math.pow(1 + (rate / periods), periods * time)
    
    def future_value_series(self, payment: float, rate: float, periods: int, time: float, principal: float = 0) -> float:
        """Calculate future value of a series of payments plus principal"""
        if time <= 0:
            return principal
            
        if rate == 0:
            return principal + (payment * periods * time)
        
        # Future value of annuity + future value of principal
        compound_factor = math.pow(1 + (rate / periods), periods * time)
        annuity_fv = payment * ((compound_factor - 1) / (rate / periods))
        principal_fv = self.future_value(principal, rate, periods, time)
        
        return annuity_fv + principal_fv
    
    def pmt_monthly_to_daily(self, monthly_payment: float) -> float:
        """Convert monthly payment to daily payment for accurate calculations"""
        return monthly_payment * 12 / 365
    
    def calculate_real_return(self, nominal_return: float, inflation_rate: float) -> float:
        """Calculate real return rate adjusted for inflation"""
        return (1 + nominal_return) / (1 + inflation_rate) - 1
    
    def converge_coast_fire(self, iterations: int, fire_number: float, current_age: int, 
                          retirement_age: int, daily_payment: float, min_years: float, 
                          max_years: float, rate: float, principal: float = 0, 
                          daily_barista_payment: float = 0, previous_result: dict = None) -> dict:
        """
        Numerically converge on coast FIRE amount and date using iterative refinement
        Based on coast-fire-calculator's proven convergence algorithm
        """
        
        # Base case - return converged result
        if iterations == 0 and previous_result:
            return previous_result
        
        # Default result for failure cases
        result = previous_result or {
            'is_possible': False,
            'already_coast_fire': False,
            'coast_fire_number': None,
            'coast_fire_age': None,
            'final_amount': None
        }
        
        # Convergence iteration - divide range into steps and find crossing point
        step = (max_years - min_years) / self.CONVERGENCE_STEPS
        
        for i in range(1, self.CONVERGENCE_STEPS + 1):
            num_saving_years = min_years + (i * step)
            
            # Calculate amount accumulated during saving phase
            coast_amount = self.future_value_series(daily_payment, rate, 365, num_saving_years, principal)
            
            # Calculate years remaining for coasting phase
            num_coasting_years = retirement_age - num_saving_years - current_age
            
            # Calculate final amount after coasting phase with barista contributions
            final_amount = self.future_value_series(daily_barista_payment, rate, 365, num_coasting_years, coast_amount)
            
            # Check if this scenario meets the FIRE target
            if final_amount > fire_number:
                # Found crossing point - refine with recursive convergence
                new_min = min_years + ((i - 1) * step)
                new_max = num_saving_years
                new_result = {
                    'is_possible': True,
                    'already_coast_fire': False,
                    'coast_fire_number': coast_amount,
                    'coast_fire_age': num_saving_years + current_age,
                    'final_amount': final_amount
                }
                
                # Recursive refinement for higher precision
                return self.converge_coast_fire(
                    iterations - 1, fire_number, current_age, retirement_age,
                    daily_payment, new_min, new_max, rate, principal, 
                    daily_barista_payment, new_result
                )
        
        return result
    
    def calculate_years_to_target(self, current_amount: float, target_amount: float,
                                monthly_contribution: float, annual_return: float) -> float:
        """Calculate years needed to reach target with monthly contributions"""
        
        if target_amount <= current_amount:
            return 0
        
        if monthly_contribution <= 0:
            if annual_return <= 0:
                return float('inf')
            # Only compound growth
            return math.log(target_amount / current_amount) / math.log(1 + annual_return)
        
        # Use iterative approach with daily compounding
        daily_payment = self.pmt_monthly_to_daily(monthly_contribution)
        
        for years in range(1, 101):  # Check up to 100 years
            future_val = self.future_value_series(daily_payment, annual_return, 365, years, current_amount)
            if future_val >= target_amount:
                # Refine with binary search
                return self._binary_search_years(
                    current_amount, target_amount, daily_payment, annual_return, years - 1, years
                )
        
        return float('inf')
    
    def _binary_search_years(self, current_amount: float, target_amount: float,
                           daily_payment: float, annual_return: float, 
                           min_years: float, max_years: float) -> float:
        """Binary search for precise years calculation"""
        
        for _ in range(20):  # 20 iterations for high precision
            mid_years = (min_years + max_years) / 2
            future_val = self.future_value_series(daily_payment, annual_return, 365, mid_years, current_amount)
            
            if abs(future_val - target_amount) < 1:  # Within $1
                return mid_years
            
            if future_val < target_amount:
                min_years = mid_years
            else:
                max_years = mid_years
        
        return (min_years + max_years) / 2
    
    def calculate_monthly_payment_needed(self, current_amount: float, target_amount: float, 
                                       years_available: float, annual_return: float) -> float:
        """Calculate monthly payment needed to reach target in given time"""
        if years_available <= 0 or target_amount <= current_amount:
            return 0
        
        # Amount needed from contributions
        future_current = self.future_value(current_amount, annual_return, 365, years_available)
        amount_needed_from_contributions = target_amount - future_current
        
        if amount_needed_from_contributions <= 0:
            return 0
        
        # Calculate required daily payment, then convert to monthly
        daily_rate = annual_return / 365
        periods = 365 * years_available
        
        if daily_rate == 0:
            daily_payment = amount_needed_from_contributions / periods
        else:
            daily_payment = amount_needed_from_contributions * daily_rate / (math.pow(1 + daily_rate, periods) - 1)
        
        return daily_payment * 365 / 12  # Convert to monthly
    
    def calculate_inflation_adjusted_expenses(self, current_expenses: float, inflation_rate: float, years: float) -> float:
        """Calculate future expenses adjusted for inflation"""
        if years <= 0:
            return current_expenses
        return current_expenses * math.pow(1 + inflation_rate, years)
        return current_expenses * math.pow(1 + inflation_rate, years)
    
    def calculate_years_to_target(self, current_value: float, target_value: float, monthly_contribution: float, annual_return: float) -> float:
        """Calculate years needed to reach target with monthly contributions using proper mathematical formula"""
        if current_value >= target_value:
            return 0
        
        if monthly_contribution <= 0:
            if annual_return <= 0:
                return float('inf')  # Impossible without contributions or growth
            # Only growth, no contributions
            return math.log(target_value / current_value) / math.log(1 + annual_return)
        
        if annual_return == 0:
            # No growth, only contributions
            return (target_value - current_value) / (monthly_contribution * 12)
        
        # Both growth and contributions - use proper mathematical solution
        monthly_rate = annual_return / 12
        
        # Future Value formula: FV = PV * (1 + r)^n + PMT * [((1 + r)^n - 1) / r]
        # We need to solve for n (time in months), then convert to years
        
        # Rearrange to: ((1 + r)^n - 1) / r = (FV - PV * (1 + r)^n) / PMT
        # This requires iterative solution, but let's use a more efficient approach
        
        # Use binary search for better performance and accuracy
        low_years = 0
        high_years = 100  # Maximum reasonable timeframe
        tolerance = 0.001  # 0.001 years = ~4 days precision
        
        while high_years - low_years > tolerance:
            mid_years = (low_years + high_years) / 2
            
            # Calculate future value at mid_years
            months = mid_years * 12
            monthly_growth = math.pow(1 + monthly_rate, months)
            
            # FV = PV * (1 + r)^n + PMT * [((1 + r)^n - 1) / r]
            fv_principal = current_value * monthly_growth
            fv_annuity = monthly_contribution * (monthly_growth - 1) / monthly_rate if monthly_rate > 0 else monthly_contribution * months
            total_fv = fv_principal + fv_annuity
            
            if total_fv < target_value:
                low_years = mid_years
            else:
                high_years = mid_years
        
        return (low_years + high_years) / 2
    
    def calculate_monthly_payment_needed(self, current_value: float, target_value: float, years: float, annual_return: float) -> float:
        """Calculate monthly payment needed to reach target in given years"""
        if years <= 0 or current_value >= target_value:
            return 0
        
        if annual_return == 0:
            # No growth, only contributions needed
            return (target_value - current_value) / (years * 12)
        
        # Calculate required monthly payment using present value of annuity formula
        monthly_rate = annual_return / 12
        periods = years * 12
        
        # Future value of current principal
        future_principal = self.future_value(current_value, annual_return, 12, years)
        
        # Amount needed from contributions
        amount_needed_from_contributions = target_value - future_principal
        
        if amount_needed_from_contributions <= 0:
            return 0
        
        # Monthly payment needed
        if monthly_rate == 0:
            return amount_needed_from_contributions / periods
        
        return amount_needed_from_contributions * monthly_rate / (math.pow(1 + monthly_rate, periods) - 1)
    
    def calculate_traditional_fire_simple(self, annual_expenses: float, safe_withdrawal_rate: float, 
                                        monthly_contribution: float = 0) -> dict:
        """Calculate Traditional FIRE target - CORRECTED to use recurring investments for timeline"""
        if safe_withdrawal_rate <= 0:
            return {'target': 0, 'annual_income': 0}
        
        # FIRE target calculation: Annual Expenses Ã· Safe Withdrawal Rate
        fire_target = annual_expenses / safe_withdrawal_rate
        
        # âœ… CORRECTED: annual_income represents user's actual monthly recurring investment capacity
        # This is used for timeline calculations, not target calculations
        annual_investment_capacity = monthly_contribution * 12
        
        return {
            'target': fire_target,
            'annual_income': annual_investment_capacity,  # âœ… CORRECTED: User's recurring investment capacity
            'annual_expenses': annual_expenses,
            'safe_withdrawal_rate': safe_withdrawal_rate,
            'method': 'simple_fire_rule_corrected'
        }
    
    def calculate_investment_gap_analysis(self, current_monthly: float, needed_monthly: float) -> dict:
        """Calculate gap between current and needed monthly investment for actionable insights"""
        gap = needed_monthly - current_monthly
        gap_percentage = (gap / needed_monthly * 100) if needed_monthly > 0 else 0
        
        return {
            'current_monthly': current_monthly,
            'needed_monthly': needed_monthly,
            'monthly_gap': gap,
            'gap_percentage': gap_percentage,
            'is_sufficient': gap <= 0,
            'additional_needed': max(0, gap),
            'sufficiency_status': 'sufficient' if gap <= 0 else 'insufficient'
        }
    
    def calculate_coast_fire_simple(self, fire_number: float, current_age: int, retirement_age: int, 
                                  expected_return: float, current_portfolio: float = 0) -> dict:
        """
        Calculate Coast FIRE using simple approach without inflation adjustments
        """
        years_to_retirement = retirement_age - current_age
        
        if years_to_retirement <= 0:
            return {
                'target': fire_number,
                'achievable': current_portfolio >= fire_number,
                'already_achieved': current_portfolio >= fire_number,
                'years_remaining': 0,
                'method': 'immediate_retirement'
            }
        
        # Check if already coast FIRE achieved
        # Can current portfolio grow to FIRE target with no additional contributions?
        final_with_growth_only = current_portfolio * math.pow(1 + expected_return, years_to_retirement)
        
        if final_with_growth_only >= fire_number:
            return {
                'target': current_portfolio,
                'achievable': True,
                'already_achieved': True,
                'years_remaining': 0,
                'final_value': final_with_growth_only,
                'expected_return': expected_return,
                'method': 'already_coast_fire'
            }
        
        # Calculate Coast FIRE target using present value approach
        # This is the amount needed today to grow to FIRE target by retirement
        coast_fire_target = fire_number / math.pow(1 + expected_return, years_to_retirement)
        
        # Check if already achieved
        already_achieved = current_portfolio >= coast_fire_target
        
        # Calculate years remaining if not achieved
        years_remaining = 0
        if not already_achieved and current_portfolio > 0:
            if expected_return > 0:
                years_remaining = math.log(coast_fire_target / current_portfolio) / math.log(1 + expected_return)
                years_remaining = max(0, years_remaining)
            else:
                years_remaining = float('inf')
        
        return {
            'target': coast_fire_target,
            'achievable': True,
            'already_achieved': already_achieved,
            'years_remaining': years_remaining,
            'final_value': current_portfolio * math.pow(1 + expected_return, years_to_retirement),
            'expected_return': expected_return,
            'method': 'simple_coast_fire'
        }
    
    def calculate_barista_fire_simple(self, annual_expenses: float, safe_withdrawal_rate: float,
                                    barista_annual_contribution: float, current_portfolio: float = 0,
                                    full_time_contribution: float = 0, expected_return: float = 0.07,
                                    years_to_retirement: float = 20) -> dict:
        """
        Calculate Barista FIRE target - Coast FIRE variation without inflation adjustments
        
        Key Concept: Barista FIRE = Amount needed NOW so you can switch to part-time work 
        and still reach Traditional FIRE by retirement age with reduced contributions
        """
        if safe_withdrawal_rate <= 0:
            return {'target': 0, 'traditional_fire_target': 0}
        
        # Calculate Traditional FIRE target (what we need to reach by retirement)
        traditional_fire_target = annual_expenses / safe_withdrawal_rate
        
        # ðŸ”§ CORRECT BARISTA FIRE LOGIC:
        # Find the portfolio value where you can switch to part-time contributions
        # and still reach Traditional FIRE by retirement age
        
        # If we have contribution amounts, calculate the crossover point
        if full_time_contribution > 0 and barista_annual_contribution >= 0 and years_to_retirement > 0:
            # Use iterative approach to find the crossover point
            # At what portfolio value can we switch to part-time and still reach the target?
            
            monthly_full_time = full_time_contribution / 12
            monthly_barista = barista_annual_contribution / 12
            monthly_return = expected_return / 12
            months_to_retirement = years_to_retirement * 12
            
            # Binary search for the crossover point
            low, high = 0, traditional_fire_target
            tolerance = 1000  # $1000 tolerance
            
            for _ in range(50):  # Max 50 iterations
                mid = (low + high) / 2
                
                # Assume we switch to barista mode immediately at this portfolio value
                # Calculate final value with reduced contributions
                final_value = self.future_value_series(
                    monthly_barista, expected_return, 12, years_to_retirement, mid
                )
                
                if abs(final_value - traditional_fire_target) < tolerance:
                    barista_target = mid
                    break
                elif final_value < traditional_fire_target:
                    low = mid
                else:
                    high = mid
            else:
                # If no convergence, use a simpler approximation
                # Calculate what we need now if we only make barista contributions
                if monthly_barista > 0:
                    barista_target = self.present_value_of_annuity_target(
                        traditional_fire_target, monthly_barista, expected_return, years_to_retirement
                    )
                else:
                    # If no barista contributions, need full amount now (pure coast)
                    barista_target = traditional_fire_target / math.pow(1 + expected_return, years_to_retirement)
        else:
            # Fallback: Simple coast fire calculation
            barista_target = traditional_fire_target / math.pow(1 + expected_return, years_to_retirement)
        
        # Ensure barista target is between coast fire and traditional fire
        coast_fire_target = traditional_fire_target / math.pow(1 + expected_return, years_to_retirement)
        barista_target = max(coast_fire_target, min(barista_target, traditional_fire_target))
        
        return {
            'target': barista_target,
            'traditional_fire_target': traditional_fire_target,
            'coast_fire_target': coast_fire_target,
            'barista_annual_contribution': barista_annual_contribution,
            'full_time_contribution': full_time_contribution,
            'crossover_point': barista_target,
            'concept': 'coast_fire_variation',
            'explanation': f'Need ${barista_target:,.0f} to switch to part-time work (${barista_annual_contribution:,.0f}/year contributions) and still reach Traditional FIRE by retirement',
            'method': 'simple_barista_fire'
        }
    
    def present_value_of_annuity_target(self, future_target: float, monthly_payment: float, 
                                      annual_rate: float, years: float) -> float:
        """Calculate present value needed when making monthly payments to reach a future target"""
        if monthly_payment <= 0:
            return future_target / math.pow(1 + annual_rate, years)
        
        monthly_rate = annual_rate / 12
        months = years * 12
        
        # Future value of annuity
        if monthly_rate > 0:
            fv_annuity = monthly_payment * (math.pow(1 + monthly_rate, months) - 1) / monthly_rate
        else:
            fv_annuity = monthly_payment * months
        
        # Present value needed = (Target - Future Value of Payments) / Growth Factor
        remaining_needed = max(0, future_target - fv_annuity)
        return remaining_needed / math.pow(1 + annual_rate, years)
    
    def calculate_comprehensive_fire_with_inflation(self, user_data: dict) -> dict:
        """Main function to calculate all FIRE types with proper inflation handling and complete metrics"""
        current_age = user_data['current_age']
        retirement_age = user_data['target_retirement_age']
        annual_expenses = user_data['annual_expenses']
        safe_withdrawal_rate = user_data['safe_withdrawal_rate']
        expected_return = user_data['expected_annual_return']
        inflation_rate = user_data.get('inflation_rate', self.DEFAULT_INFLATION_RATE)
        monthly_contribution = user_data.get('monthly_contribution', 0)
        monthly_barista_contribution = user_data.get('monthly_barista_contribution', 0)
        current_portfolio = user_data.get('current_portfolio_value', 0)
        
        years_to_retirement = retirement_age - current_age
        
        # Calculate Traditional FIRE with inflation
        traditional_fire_result = self.calculate_traditional_fire_with_inflation(
            annual_expenses, safe_withdrawal_rate, inflation_rate, years_to_retirement
        )
        
        # Use current purchasing power target for Coast and Barista FIRE calculations
        fire_target = traditional_fire_result['current_power']
        
        # Calculate Coast FIRE with inflation
        coast_fire_result = self.calculate_coast_fire_with_inflation(
            fire_target, current_age, retirement_age, expected_return, inflation_rate, current_portfolio
        )
        
        # Calculate Barista FIRE with correct Coast FIRE variation logic
        barista_fire_result = self.calculate_barista_fire_with_inflation(
            annual_expenses, safe_withdrawal_rate, monthly_barista_contribution * 12, 
            inflation_rate, years_to_retirement, current_portfolio,
            monthly_contribution * 12, expected_return
        )
        
        # Calculate progress percentages
        traditional_progress = (current_portfolio / fire_target * 100) if fire_target > 0 else 0
        coast_progress = (current_portfolio / coast_fire_result['target'] * 100) if coast_fire_result['target'] > 0 else 0
        
        # Barista progress based on actual Barista FIRE target (not transition point)
        barista_target = barista_fire_result['current_power']
        barista_progress = (current_portfolio / barista_target * 100) if barista_target > 0 else 0
        
        # ðŸ†• Calculate years to FIRE for each type
        years_to_traditional = self.calculate_years_to_target(
            current_portfolio, fire_target, monthly_contribution, expected_return
        )
        
        years_to_coast = self.calculate_years_to_target(
            current_portfolio, coast_fire_result['target'], monthly_contribution, expected_return
        )
        
        years_to_barista = self.calculate_years_to_target(
            current_portfolio, barista_target, monthly_contribution, expected_return
        )
        
        # ðŸ†• Calculate monthly investment needed for each type (if achievable in retirement timeframe)
        monthly_needed_traditional = self.calculate_monthly_payment_needed(
            current_portfolio, fire_target, years_to_retirement, expected_return
        ) if years_to_retirement > 0 else 0
        
        monthly_needed_coast = self.calculate_monthly_payment_needed(
            current_portfolio, coast_fire_result['target'], years_to_retirement, expected_return
        ) if years_to_retirement > 0 else 0
        
        monthly_needed_barista = self.calculate_monthly_payment_needed(
            current_portfolio, barista_target, years_to_retirement, expected_return
        ) if years_to_retirement > 0 else 0
        
        # Calculate real return for display
        real_return = self.calculate_real_return(expected_return, inflation_rate)
        
        return {
            'traditional_fire': {
                'target': fire_target,
                'target_inflation_adjusted': traditional_fire_result['inflation_adjusted'],
                'future_expenses': traditional_fire_result['future_expenses'],
                'inflation_impact': traditional_fire_result['inflation_impact'],
                'progress_percentage': min(traditional_progress, 100),
                'achieved': current_portfolio >= fire_target,
                'years_remaining': years_to_traditional,
                'monthly_investment_needed': monthly_needed_traditional,
                'message': f"Need {fire_target:,.0f} (current purchasing power) or {traditional_fire_result['inflation_adjusted']:,.0f} (inflation-adjusted) to withdraw {annual_expenses:,.0f} annually at {safe_withdrawal_rate*100:.1f}% rate"
            },
            'coast_fire': {
                'target': coast_fire_result['target'],
                'progress_percentage': min(coast_progress, 100),
                'achieved': coast_fire_result['already_achieved'],
                'years_remaining': years_to_coast,
                'monthly_investment_needed': monthly_needed_coast,
                'real_return_used': coast_fire_result['real_return_used'],
                'final_value_at_retirement': coast_fire_result.get('final_value', 0),
                'message': f"Need {coast_fire_result['target']:,.0f} now to coast to Traditional FIRE by age {retirement_age} (using {real_return*100:.2f}% real return)"
            },
            'barista_fire': {
                'target': barista_target,
                'target_inflation_adjusted': barista_fire_result['inflation_adjusted'],
                'traditional_fire_target': barista_fire_result['traditional_fire_target'],
                'coast_fire_target': barista_fire_result['coast_fire_target'],
                'crossover_point': barista_fire_result['crossover_point'],
                'barista_annual_contribution': barista_fire_result['barista_annual_contribution'],
                'full_time_contribution': barista_fire_result['full_time_contribution'],
                'inflation_impact': barista_fire_result['inflation_impact'],
                'progress_percentage': min(barista_progress, 100),
                'achieved': current_portfolio >= barista_target,
                'years_remaining': years_to_barista,
                'monthly_investment_needed': monthly_needed_barista,
                'concept': barista_fire_result['concept'],
                'explanation': barista_fire_result['explanation'],
                'message': f"Need {barista_target:,.0f} to switch to part-time work and still reach Traditional FIRE by age {retirement_age}"
            },
            'inflation_analysis': {
                'inflation_rate': inflation_rate,
                'nominal_return': expected_return,
                'real_return': real_return,
                'purchasing_power_erosion': f"{inflation_rate*100:.1f}% annually",
                'real_growth_rate': f"{real_return*100:.2f}% after inflation",
                'inflation_impact_over_time': traditional_fire_result['inflation_impact'],
                'years_to_retirement': years_to_retirement
            },
            'summary_metrics': {
                'current_portfolio': current_portfolio,
                'monthly_contribution': monthly_contribution,
                'monthly_barista_contribution': monthly_barista_contribution,
                'total_monthly_needed_traditional': monthly_needed_traditional,
                'total_monthly_needed_coast': monthly_needed_coast,
                'total_monthly_needed_barista': monthly_needed_barista,
                'fastest_fire_type': 'Coast' if years_to_coast <= min(years_to_traditional, years_to_barista) else 
                                   ('Barista' if years_to_barista <= years_to_traditional else 'Traditional'),
                'most_achievable_target': min(coast_fire_result['target'], barista_target, fire_target)
            },
            'metadata': {
                'current_age': current_age,
                'target_retirement_age': retirement_age,
                'years_to_retirement': years_to_retirement,
                'calculation_method': 'enhanced_mathematical_approach_with_proper_formulas',
                'inflation_methodology': 'fisher_equation_real_return',
                'compounding_frequency': 'monthly',
                'convergence_tolerance': self.CONVERGENCE_TOLERANCE
            }
        }
    
    def calculate_comprehensive_fire_simple(self, user_data: dict) -> dict:
        """Main function to calculate all FIRE types without inflation adjustments - simplified approach"""
        current_age = user_data['current_age']
        retirement_age = user_data['target_retirement_age']
        annual_expenses = user_data['annual_expenses']
        safe_withdrawal_rate = user_data['safe_withdrawal_rate']
        expected_return = user_data['expected_annual_return']
        monthly_contribution = user_data.get('monthly_contribution', 0)
        monthly_barista_contribution = user_data.get('monthly_barista_contribution', 0)
        current_portfolio = user_data.get('current_portfolio_value', 0)
        
        years_to_retirement = retirement_age - current_age
        
        # Calculate Traditional FIRE (corrected) - âœ… CORRECTED: Pass monthly contribution
        traditional_fire_result = self.calculate_traditional_fire_simple(
            annual_expenses, safe_withdrawal_rate, monthly_contribution
        )
        
        # Use traditional fire target for Coast and Barista FIRE calculations
        fire_target = traditional_fire_result['target']
        
        # Calculate Coast FIRE (simple)
        coast_fire_result = self.calculate_coast_fire_simple(
            fire_target, current_age, retirement_age, expected_return, current_portfolio
        )
        
        # Calculate Barista FIRE (simple)
        barista_fire_result = self.calculate_barista_fire_simple(
            annual_expenses, safe_withdrawal_rate, monthly_barista_contribution * 12, 
            current_portfolio, monthly_contribution * 12, expected_return, years_to_retirement
        )
        
        # Calculate progress percentages
        traditional_progress = (current_portfolio / fire_target * 100) if fire_target > 0 else 0
        coast_progress = (current_portfolio / coast_fire_result['target'] * 100) if coast_fire_result['target'] > 0 else 0
        
        # Barista progress based on actual Barista FIRE target
        barista_target = barista_fire_result['target']
        barista_progress = (current_portfolio / barista_target * 100) if barista_target > 0 else 0
        
        # Calculate years to FIRE for each type
        years_to_traditional = self.calculate_years_to_target(
            current_portfolio, fire_target, monthly_contribution, expected_return
        )
        
        years_to_coast = self.calculate_years_to_target(
            current_portfolio, coast_fire_result['target'], monthly_contribution, expected_return
        )
        
        years_to_barista = self.calculate_years_to_target(
            current_portfolio, barista_target, monthly_contribution, expected_return
        )
        
        # Calculate monthly investment needed for each type (if achievable in retirement timeframe)
        monthly_needed_traditional = self.calculate_monthly_payment_needed(
            current_portfolio, fire_target, years_to_retirement, expected_return
        ) if years_to_retirement > 0 else 0
        
        monthly_needed_coast = self.calculate_monthly_payment_needed(
            current_portfolio, coast_fire_result['target'], years_to_retirement, expected_return
        ) if years_to_retirement > 0 else 0
        
        monthly_needed_barista = self.calculate_monthly_payment_needed(
            current_portfolio, barista_target, years_to_retirement, expected_return
        ) if years_to_retirement > 0 else 0
        
        # âœ… ENHANCED: Calculate investment gap analysis for all FIRE types
        traditional_gap = self.calculate_investment_gap_analysis(monthly_contribution, monthly_needed_traditional)
        coast_gap = self.calculate_investment_gap_analysis(monthly_contribution, monthly_needed_coast)
        barista_gap = self.calculate_investment_gap_analysis(monthly_contribution, monthly_needed_barista)
        
        return {
            'traditional_fire': {
                'target': fire_target,
                'annual_income': traditional_fire_result['annual_income'],  # âœ… FIXED: Now shows actual investment capacity
                'annual_expenses': traditional_fire_result['annual_expenses'],
                'safe_withdrawal_rate': traditional_fire_result['safe_withdrawal_rate'],
                'progress_percentage': min(traditional_progress, 100),
                'achieved': current_portfolio >= fire_target,
                'years_remaining': years_to_traditional,
                'monthly_investment_needed': monthly_needed_traditional,
                'investment_gap_analysis': traditional_gap,  # âœ… NEW: Gap analysis
                'method': traditional_fire_result['method'],
                'message': f"Need {fire_target:,.0f} for complete financial independence"
            },
            'coast_fire': {
                'target': coast_fire_result['target'],
                'progress_percentage': min(coast_progress, 100),
                'achieved': coast_fire_result['already_achieved'],
                'years_remaining': years_to_coast,
                'monthly_investment_needed': monthly_needed_coast,
                'investment_gap_analysis': coast_gap,  # âœ… NEW: Gap analysis
                'expected_return': coast_fire_result['expected_return'],
                'final_value_at_retirement': coast_fire_result.get('final_value', 0),
                'method': coast_fire_result['method'],
                'message': f"Need {coast_fire_result['target']:,.0f} now to coast to Traditional FIRE by age {retirement_age}"
            },
            'barista_fire': {
                'target': barista_target,
                'traditional_fire_target': barista_fire_result['traditional_fire_target'],
                'coast_fire_target': barista_fire_result['coast_fire_target'],
                'crossover_point': barista_fire_result['crossover_point'],
                'barista_annual_contribution': barista_fire_result['barista_annual_contribution'],
                'full_time_contribution': barista_fire_result['full_time_contribution'],
                'progress_percentage': min(barista_progress, 100),
                'achieved': current_portfolio >= barista_target,
                'years_remaining': years_to_barista,
                'monthly_investment_needed': monthly_needed_barista,
                'investment_gap_analysis': barista_gap,  # âœ… NEW: Gap analysis
                'concept': barista_fire_result['concept'],
                'explanation': barista_fire_result['explanation'],
                'method': barista_fire_result['method'],
                'message': f"Need {barista_target:,.0f} to switch to part-time work and still reach Traditional FIRE by age {retirement_age}"
            },
            'summary_metrics': {
                'current_portfolio': current_portfolio,
                'monthly_contribution': monthly_contribution,
                'monthly_barista_contribution': monthly_barista_contribution,
                'total_monthly_needed_traditional': monthly_needed_traditional,
                'total_monthly_needed_coast': monthly_needed_coast,
                'total_monthly_needed_barista': monthly_needed_barista,
                # âœ… ENHANCED: Investment sufficiency analysis
                'investment_sufficiency': {
                    'traditional_sufficient': traditional_gap['is_sufficient'],
                    'coast_sufficient': coast_gap['is_sufficient'],
                    'barista_sufficient': barista_gap['is_sufficient'],
                    'total_additional_needed_traditional': traditional_gap['additional_needed'],
                    'total_additional_needed_coast': coast_gap['additional_needed'],
                    'total_additional_needed_barista': barista_gap['additional_needed']
                },
                'fastest_fire_type': 'Coast' if years_to_coast <= min(years_to_traditional, years_to_barista) else 
                                   ('Barista' if years_to_barista <= years_to_traditional else 'Traditional'),
                'most_achievable_target': min(coast_fire_result['target'], barista_target, fire_target),
                # âœ… NEW: Actionable insights
                'most_feasible_fire_type': 'Coast' if coast_gap['is_sufficient'] else 
                                          ('Barista' if barista_gap['is_sufficient'] else 
                                           ('Traditional' if traditional_gap['is_sufficient'] else 'None'))
            },
            'metadata': {
                'current_age': current_age,
                'target_retirement_age': retirement_age,
                'years_to_retirement': years_to_retirement,
                'calculation_method': 'simplified_fire_calculations_enhanced',
                'inflation_methodology': 'none_simplified_approach',
                'compounding_frequency': 'monthly'
            }
        }

def calculate_cd_compound_interest(principal, annual_rate, start_date, maturity_date, compounding_frequency='daily'):
    """
    Calculate compound interest for Certificate of Deposit (CD) assets
    
    Args:
        principal (float): Initial investment amount
        annual_rate (float): Annual interest rate as percentage (e.g., 4.5 for 4.5%)
        start_date (str): Start date in YYYY-MM-DD format
        maturity_date (str): Maturity date in YYYY-MM-DD format
        compounding_frequency (str): 'daily', 'monthly', 'quarterly', or 'annually'
    
    Returns:
        dict: Contains current value, accrued interest, days elapsed, etc.
    """
    try:
        # Convert dates
        start_dt = datetime.strptime(start_date, '%Y-%m-%d')
        maturity_dt = datetime.strptime(maturity_date, '%Y-%m-%d')
        current_dt = datetime.now()
        
        # Calculate time periods
        total_days = (maturity_dt - start_dt).days
        elapsed_days = min((current_dt - start_dt).days, total_days)
        
        if elapsed_days <= 0:
            return {
                'current_value': principal,
                'accrued_interest': 0,
                'total_days': total_days,
                'elapsed_days': 0,
                'maturity_value': 0,
                'annual_rate': annual_rate,
                'is_matured': False
            }
        
        # Convert annual rate to decimal
        rate_decimal = annual_rate / 100
        
        # Determine compounding periods per year
        if compounding_frequency == 'daily':
            n = 365
        elif compounding_frequency == 'monthly':
            n = 12
        elif compounding_frequency == 'quarterly':
            n = 4
        else:  # annually
            n = 1
        
        # Calculate time in years for current value
        time_years = elapsed_days / 365.25
        
        # Calculate compound interest: A = P(1 + r/n)^(nt)
        current_value = principal * math.pow(1 + rate_decimal / n, n * time_years)
        accrued_interest = current_value - principal
        
        # Calculate maturity value
        total_time_years = total_days / 365.25
        maturity_value = principal * math.pow(1 + rate_decimal / n, n * total_time_years)
        
        # Check if CD has matured
        is_matured = current_dt.date() >= maturity_dt.date()
        
        return {
            'current_value': round(current_value, 2),
            'accrued_interest': round(accrued_interest, 2),
            'total_days': total_days,
            'elapsed_days': elapsed_days,
            'maturity_value': round(maturity_value, 2),
            'annual_rate': annual_rate,
            'is_matured': is_matured,
            'compounding_frequency': compounding_frequency,
            'effective_annual_rate': round((math.pow(1 + rate_decimal / n, n) - 1) * 100, 4)
        }
        
    except Exception as e:
        logger.error(f"Error calculating CD compound interest: {str(e)}")
        return {
            'current_value': principal,
            'accrued_interest': 0,
            'total_days': 0,
            'elapsed_days': 0,
            'maturity_value': principal,
            'annual_rate': annual_rate,
            'is_matured': False,
            'error': str(e)
        }

# Database connection handling
try:
    import psycopg2
    import psycopg2.extras
    from contextlib import contextmanager
    PSYCOPG2_AVAILABLE = True
    logger.info("psycopg2 is available")
except ImportError:
    PSYCOPG2_AVAILABLE = False
    logger.warning("psycopg2 not available, will use mock database")

# Configuration
JWT_SECRET = os.environ.get('JWT_SECRET', 'REDACTED_JWT_SECRET')
JWT_ALGORITHM = 'HS256'
JWT_EXPIRATION_HOURS = 24
DATABASE_URL = os.environ.get('DATABASE_URL', '')

# API Configuration
ALPHA_VANTAGE_API_KEY = os.environ.get('ALPHA_VANTAGE_API_KEY', '')
ALPHA_VANTAGE_BASE_URL = 'https://www.alphavantage.co/query'
EXCHANGE_RATE_BASE_URL = 'https://api.exchangerate-api.com/v4/latest'

def get_cors_headers():
    """Return proper CORS headers"""
    return {
        "Access-Control-Allow-Origin": "*",
        "Access-Control-Allow-Methods": "GET, POST, PUT, DELETE, OPTIONS",
        "Access-Control-Allow-Headers": "Content-Type, Authorization, X-Requested-With, Accept, Origin",
        "Access-Control-Max-Age": "86400",
        "Content-Type": "application/json"
    }

def create_response(status_code, body, additional_headers=None):
    """Create a proper API Gateway response with CORS headers"""
    headers = get_cors_headers()
    if additional_headers:
        headers.update(additional_headers)
    
    return {
        "statusCode": status_code,
        "headers": headers,
        "body": json.dumps(body) if isinstance(body, (dict, list)) else body
    }

def create_error_response(status_code, message):
    """Create an error response"""
    return create_response(status_code, {
        "error": True,
        "message": message
    })

# Database functions
if PSYCOPG2_AVAILABLE:
    @contextmanager
    def get_db_connection(database_url):
        """Context manager for database connections"""
        conn = None
        try:
            conn = psycopg2.connect(database_url)
            yield conn
        except Exception as e:
            if conn:
                conn.rollback()
            logger.error(f"Database error: {str(e)}")
            raise
        finally:
            if conn:
                conn.close()

    def execute_query(database_url, query, params=None):
        """Execute a SELECT query and return results"""
        with get_db_connection(database_url) as conn:
            with conn.cursor(cursor_factory=psycopg2.extras.RealDictCursor) as cursor:
                cursor.execute(query, params)
                return cursor.fetchall()

    def execute_update(database_url, query, params=None):
        """Execute an INSERT/UPDATE/DELETE query and return affected rows"""
        with get_db_connection(database_url) as conn:
            with conn.cursor() as cursor:
                cursor.execute(query, params)
                conn.commit()
                return cursor.rowcount
else:
    # Mock database functions
    def execute_query(database_url, query, params=None):
        """Mock database query"""
        logger.warning("Using mock database - query not executed")
        return []

    def execute_update(database_url, query, params=None):
        """Mock database update"""
        logger.warning("Using mock database - update not executed")
        return 0

def ensure_cd_columns_exist():
    """Ensure CD-specific columns exist in the assets table"""
    if not PSYCOPG2_AVAILABLE:
        logger.warning("Skipping CD column migration - psycopg2 not available")
        return
    
    try:
        # Check if columns exist by trying to select them
        test_query = "SELECT interest_rate, maturity_date FROM assets LIMIT 1"
        execute_query(DATABASE_URL, test_query)
        logger.info("CD columns already exist")
        return
        
    except Exception as e:
        logger.info(f"CD columns don't exist, attempting to add them: {str(e)}")
        
        # Add interest_rate column
        try:
            execute_update(DATABASE_URL, "ALTER TABLE assets ADD COLUMN interest_rate DECIMAL(5,4)")
            logger.info("Added interest_rate column successfully")
        except Exception as e:
            logger.warning(f"Failed to add interest_rate column (may already exist): {str(e)}")
        
        # Add maturity_date column
        try:
            execute_update(DATABASE_URL, "ALTER TABLE assets ADD COLUMN maturity_date DATE")
            logger.info("Added maturity_date column successfully")
        except Exception as e:
            logger.warning(f"Failed to add maturity_date column (may already exist): {str(e)}")
        
        logger.info("CD column migration completed")

# Password hashing functions
def hash_password(password):
    """Hash password using PBKDF2 with SHA256"""
    salt = secrets.token_hex(16)  # 32 character hex string
    password_hash = hashlib.pbkdf2_hmac('sha256', password.encode('utf-8'), salt.encode('utf-8'), 100000)
    return f"{salt}:{password_hash.hex()}"

def verify_password(password, stored_hash):
    """Verify password against stored hash"""
    try:
        salt, password_hash = stored_hash.split(':')
        new_hash = hashlib.pbkdf2_hmac('sha256', password.encode('utf-8'), salt.encode('utf-8'), 100000)
        return password_hash == new_hash.hex()
    except ValueError:
        return False

# Cache helper functions
def get_cached_stock_price(symbol):
    """Get stock price from cache if available"""
    with _cache_lock:
        cache_key = f"stock_{symbol.upper()}"
        cached_data = stock_price_cache.get(cache_key)
        if cached_data:
            logger.info(f"ðŸ“¦ Cache HIT for {symbol} - using cached data")
            # Add cache info to response
            cached_data['cached'] = True
            cached_data['cache_age_seconds'] = int((datetime.now() - datetime.fromisoformat(cached_data['cached_at'])).total_seconds())
            return cached_data
        else:
            logger.info(f"ðŸ“¦ Cache MISS for {symbol} - will fetch from API")
            return None

def set_cached_stock_price(symbol, price_data):
    """Store stock price in cache"""
    with _cache_lock:
        cache_key = f"stock_{symbol.upper()}"
        # Add cache metadata
        price_data['cached'] = False
        price_data['cached_at'] = datetime.now().isoformat()
        stock_price_cache[cache_key] = price_data.copy()
        logger.info(f"ðŸ“¦ Cached stock price for {symbol} (TTL: 5 minutes)")

def get_cached_exchange_rate(base_currency, target_currency):
    """Get exchange rate from cache if available"""
    with _cache_lock:
        cache_key = f"rate_{base_currency}_{target_currency}"
        cached_data = exchange_rate_cache.get(cache_key)
        if cached_data:
            logger.info(f"ðŸ“¦ Cache HIT for {base_currency}->{target_currency} exchange rate")
            return cached_data
        else:
            logger.info(f"ðŸ“¦ Cache MISS for {base_currency}->{target_currency} exchange rate")
            return None

def set_cached_exchange_rate(base_currency, target_currency, rate_data):
    """Store exchange rate in cache"""
    with _cache_lock:
        cache_key = f"rate_{base_currency}_{target_currency}"
        rate_data['cached_at'] = datetime.now().isoformat()
        exchange_rate_cache[cache_key] = rate_data.copy()
        logger.info(f"ðŸ“¦ Cached exchange rate {base_currency}->{target_currency} (TTL: 1 hour)")

def get_cache_stats():
    """Get cache statistics for monitoring"""
    with _cache_lock:
        return {
            'stock_price_cache': {
                'size': len(stock_price_cache),
                'maxsize': stock_price_cache.maxsize,
                'ttl': stock_price_cache.ttl,
                'hits': getattr(stock_price_cache, 'hits', 0),
                'misses': getattr(stock_price_cache, 'misses', 0)
            },
            'exchange_rate_cache': {
                'size': len(exchange_rate_cache),
                'maxsize': exchange_rate_cache.maxsize,
                'ttl': exchange_rate_cache.ttl,
                'hits': getattr(exchange_rate_cache, 'hits', 0),
                'misses': getattr(exchange_rate_cache, 'misses', 0)
            }
        }

# JWT functions
def generate_token(user_id, email):
    """Generate JWT token"""
    payload = {
        'user_id': user_id,
        'email': email,
        'exp': datetime.utcnow() + timedelta(hours=JWT_EXPIRATION_HOURS),
        'iat': datetime.utcnow()
    }
    return jwt.encode(payload, JWT_SECRET, algorithm=JWT_ALGORITHM)

def verify_token(headers):
    """Verify JWT token from Authorization header"""
    try:
        auth_header = headers.get('Authorization') or headers.get('authorization')
        if not auth_header:
            return {"error": "Authorization header missing"}
        
        if not auth_header.startswith('Bearer '):
            return {"error": "Invalid authorization header format"}
        
        token = auth_header.split(' ')[1]
        
        try:
            payload = jwt.decode(token, JWT_SECRET, algorithms=[JWT_ALGORITHM])
            return {
                "user_id": payload['user_id'],
                "email": payload['email'],
                "exp": payload['exp']
            }
        except jwt.ExpiredSignatureError:
            return {"error": "Token has expired"}
        except jwt.InvalidTokenError:
            return {"error": "Invalid token"}
            
    except Exception as e:
        logger.error(f"Token verification error: {str(e)}")
        return {"error": "Token verification failed"}

# Authentication handlers
def verify_jwt_token(auth_header):
    """Verify JWT token from Authorization header"""
    try:
        if not auth_header or not auth_header.startswith('Bearer '):
            return {'valid': False, 'error': 'Missing or invalid authorization header'}
        
        token = auth_header.split(' ')[1]
        
        # Decode and verify the token
        payload = jwt.decode(token, JWT_SECRET, algorithms=['HS256'])
        
        return {
            'valid': True,
            'user_id': payload.get('user_id'),
            'email': payload.get('email')
        }
        
    except jwt.ExpiredSignatureError:
        return {'valid': False, 'error': 'Token has expired'}
    except jwt.InvalidTokenError:
        return {'valid': False, 'error': 'Invalid token'}
    except Exception as e:
        logger.error(f"Token verification error: {str(e)}")
        return {'valid': False, 'error': 'Token verification failed'}

def handle_create_asset(body, user_id):
    """Handle asset creation/initialization"""
    try:
        ticker_symbol = body.get('ticker_symbol', '').strip().upper()
        asset_type = body.get('asset_type', 'Stock')
        total_shares = body.get('total_shares', 0)
        average_cost_basis = body.get('average_cost_basis', 0)
        currency = body.get('currency', 'USD')
        
        # CD-specific fields
        interest_rate = body.get('interest_rate')  # Annual interest rate as percentage (e.g., 4.5 for 4.5%)
        maturity_date = body.get('maturity_date')  # ISO date string for CD maturity
        start_date = body.get('start_date')  # ISO date string for CD start date
        
        if not ticker_symbol:
            return create_error_response(400, "Ticker symbol is required")
        
        if total_shares <= 0:
            return create_error_response(400, "Total shares must be greater than 0")
        
        if average_cost_basis <= 0:
            return create_error_response(400, "Average cost basis must be greater than 0")
        
        # Validate CD-specific fields
        if asset_type == 'CD':
            if interest_rate is None or interest_rate <= 0:
                return create_error_response(400, "Interest rate is required for CD assets and must be greater than 0")
            
            if not maturity_date:
                return create_error_response(400, "Maturity date is required for CD assets")
            
            if not start_date:
                return create_error_response(400, "Start date is required for CD assets")
            
            # Validate date formats and logic
            try:
                maturity_dt = datetime.strptime(maturity_date, '%Y-%m-%d')
                start_dt = datetime.strptime(start_date, '%Y-%m-%d')
                today = datetime.now().date()
                
                if maturity_dt.date() <= today:
                    return create_error_response(400, "Maturity date must be in the future")
                
                if start_dt.date() > today:
                    return create_error_response(400, "Start date cannot be in the future")
                
                if start_dt.date() >= maturity_dt.date():
                    return create_error_response(400, "Start date must be before maturity date")
                    
            except ValueError:
                return create_error_response(400, "Invalid date format. Use YYYY-MM-DD")
        
        # Check if asset already exists for this user
        existing_asset = execute_query(
            DATABASE_URL,
            "SELECT asset_id FROM assets WHERE user_id = %s AND ticker_symbol = %s",
            (user_id, ticker_symbol)
        )
        
        if existing_asset:
            return create_error_response(409, f"Asset {ticker_symbol} already exists for this user")
        
        # Create asset with CD-specific fields
        if asset_type == 'CD':
            try:
                # Try to insert with CD columns first
                execute_update(
                    DATABASE_URL,
                    """
                    INSERT INTO assets (user_id, ticker_symbol, asset_type, total_shares, average_cost_basis, currency, interest_rate, maturity_date, start_date)
                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
                    """,
                    (user_id, ticker_symbol, asset_type, total_shares, average_cost_basis, currency, interest_rate, maturity_date, start_date)
                )
                logger.info(f"CD asset created successfully with interest rate {interest_rate}% and maturity {maturity_date}")
                
            except Exception as cd_error:
                logger.warning(f"Failed to insert CD with specific columns: {str(cd_error)}")
                
                # Try to add columns if they don't exist
                try:
                    execute_update(DATABASE_URL, "ALTER TABLE assets ADD COLUMN interest_rate DECIMAL(5,4)")
                    logger.info("Added interest_rate column")
                except:
                    pass
                
                try:
                    execute_update(DATABASE_URL, "ALTER TABLE assets ADD COLUMN maturity_date DATE")
                    logger.info("Added maturity_date column")
                except:
                    pass
                
                try:
                    execute_update(DATABASE_URL, "ALTER TABLE assets ADD COLUMN start_date DATE")
                    logger.info("Added start_date column")
                except:
                    pass
                
                # Try again with CD columns
                try:
                    execute_update(
                        DATABASE_URL,
                        """
                        INSERT INTO assets (user_id, ticker_symbol, asset_type, total_shares, average_cost_basis, currency, interest_rate, maturity_date, start_date)
                        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
                        """,
                        (user_id, ticker_symbol, asset_type, total_shares, average_cost_basis, currency, interest_rate, maturity_date, start_date)
                    )
                    logger.info("CD asset created successfully after adding columns")
                    
                except Exception as retry_error:
                    logger.error(f"Failed to create CD asset even after adding columns: {str(retry_error)}")
                    # Final fallback: create without CD columns
                    execute_update(
                        DATABASE_URL,
                        """
                        INSERT INTO assets (user_id, ticker_symbol, asset_type, total_shares, average_cost_basis, currency)
                        VALUES (%s, %s, %s, %s, %s, %s)
                        """,
                        (user_id, ticker_symbol, asset_type, total_shares, average_cost_basis, currency)
                    )
                    logger.warning("CD asset created without CD-specific columns - manual database update needed")
        else:
            execute_update(
                DATABASE_URL,
                """
                INSERT INTO assets (user_id, ticker_symbol, asset_type, total_shares, average_cost_basis, currency)
                VALUES (%s, %s, %s, %s, %s, %s)
                """,
                (user_id, ticker_symbol, asset_type, total_shares, average_cost_basis, currency)
            )
        
        # Get created asset
        asset = execute_query(
            DATABASE_URL,
            "SELECT * FROM assets WHERE user_id = %s AND ticker_symbol = %s",
            (user_id, ticker_symbol)
        )[0]
        
        # Create initialization transaction
        execute_update(
            DATABASE_URL,
            """
            INSERT INTO transactions (asset_id, transaction_type, transaction_date, shares, price_per_share, currency)
            VALUES (%s, 'Initialization', CURRENT_DATE, %s, %s, %s)
            """,
            (asset['asset_id'], total_shares, average_cost_basis, currency)
        )
        
        return create_response(201, {
            "message": "Asset created successfully",
            "asset": {
                "asset_id": asset['asset_id'],
                "ticker_symbol": asset['ticker_symbol'],
                "asset_type": asset['asset_type'],
                "total_shares": float(asset['total_shares']),
                "average_cost_basis": float(asset['average_cost_basis']),
                "currency": asset['currency'],
                "created_at": asset['created_at'].isoformat()
            }
        })
        
    except Exception as e:
        logger.error(f"Create asset error: {str(e)}")
        return create_error_response(500, "Failed to create asset")

def handle_get_assets(user_id):
    """Get all assets for a user with CD compound interest calculations"""
    try:
        assets = execute_query(
            DATABASE_URL,
            """
            SELECT a.*, 
                   COALESCE(SUM(t.shares), 0) as total_shares_calculated,
                   COUNT(t.transaction_id) as transaction_count
            FROM assets a
            LEFT JOIN transactions t ON a.asset_id = t.asset_id
            WHERE a.user_id = %s
            GROUP BY a.asset_id
            ORDER BY a.created_at DESC
            """,
            (user_id,)
        )
        
        asset_list = []
        for asset in assets:
            asset_data = {
                "asset_id": asset['asset_id'],
                "ticker_symbol": asset['ticker_symbol'],
                "asset_type": asset['asset_type'],
                "total_shares": float(asset['total_shares']),
                "average_cost_basis": float(asset['average_cost_basis']),
                "currency": asset['currency'],
                "transaction_count": asset['transaction_count'],
                "created_at": asset['created_at'].isoformat(),
                "updated_at": asset['updated_at'].isoformat() if asset['updated_at'] else None
            }
            
            # Add CD-specific fields and calculations
            if asset['asset_type'] == 'CD':
                # Safely get CD-specific fields (might be None if columns don't exist yet)
                interest_rate = None
                maturity_date = None
                start_date = None
                
                try:
                    interest_rate = float(asset.get('interest_rate', 0)) if asset.get('interest_rate') else None
                    maturity_date = asset.get('maturity_date').isoformat() if asset.get('maturity_date') else None
                    start_date = asset.get('start_date').isoformat() if asset.get('start_date') else None
                except (TypeError, AttributeError, KeyError):
                    logger.warning(f"CD columns not available for asset {asset['asset_id']}")
                
                asset_data['interest_rate'] = interest_rate
                asset_data['maturity_date'] = maturity_date
                asset_data['start_date'] = start_date
                
                # Calculate compound interest if we have the required fields
                if interest_rate and maturity_date and start_date and interest_rate > 0:
                    principal = float(asset['total_shares']) * float(asset['average_cost_basis'])
                    cd_calculation = calculate_cd_compound_interest(
                        principal=principal,
                        annual_rate=asset_data['interest_rate'],
                        start_date=start_date[:10],  # Extract date part from start_date
                        maturity_date=asset_data['maturity_date'][:10]  # Extract date part
                    )
                    asset_data['cd_details'] = cd_calculation
                    
                    # Update current value to reflect compound interest
                    asset_data['current_market_value'] = cd_calculation['current_value']
                    asset_data['accrued_interest'] = cd_calculation['accrued_interest']
                elif interest_rate and maturity_date and interest_rate > 0:
                    # Fallback to created_at if start_date is not available (for existing CDs)
                    principal = float(asset['total_shares']) * float(asset['average_cost_basis'])
                    cd_calculation = calculate_cd_compound_interest(
                        principal=principal,
                        annual_rate=asset_data['interest_rate'],
                        start_date=asset['created_at'].strftime('%Y-%m-%d'),
                        maturity_date=asset_data['maturity_date'][:10]  # Extract date part
                    )
                    asset_data['cd_details'] = cd_calculation
                    
                    # Update current value to reflect compound interest
                    asset_data['current_market_value'] = cd_calculation['current_value']
                    asset_data['accrued_interest'] = cd_calculation['accrued_interest']
                    logger.warning(f"CD {asset['ticker_symbol']}: Using created_at as fallback for start_date")
            
            asset_list.append(asset_data)
        
        return create_response(200, {
            "assets": asset_list,
            "total_assets": len(asset_list)
        })
        
    except Exception as e:
        logger.error(f"Get assets error: {str(e)}")
        return create_error_response(500, "Failed to retrieve assets")

def handle_get_asset(asset_id, user_id):
    """Get specific asset details"""
    try:
        asset = execute_query(
            DATABASE_URL,
            "SELECT * FROM assets WHERE asset_id = %s AND user_id = %s",
            (asset_id, user_id)
        )
        
        if not asset:
            return create_error_response(404, "Asset not found")
        
        asset = asset[0]
        
        # Get transaction history
        transactions = execute_query(
            DATABASE_URL,
            """
            SELECT * FROM transactions 
            WHERE asset_id = %s 
            ORDER BY transaction_date DESC, created_at DESC
            """,
            (asset_id,)
        )
        
        transaction_list = []
        for txn in transactions:
            transaction_list.append({
                "transaction_id": txn['transaction_id'],
                "transaction_type": txn['transaction_type'],
                "transaction_date": txn['transaction_date'].isoformat(),
                "shares": float(txn['shares']),
                "price_per_share": float(txn['price_per_share']),
                "currency": txn['currency'],
                "created_at": txn['created_at'].isoformat()
            })
        
        return create_response(200, {
            "asset": {
                "asset_id": asset['asset_id'],
                "ticker_symbol": asset['ticker_symbol'],
                "asset_type": asset['asset_type'],
                "total_shares": float(asset['total_shares']),
                "average_cost_basis": float(asset['average_cost_basis']),
                "currency": asset['currency'],
                "created_at": asset['created_at'].isoformat(),
                "updated_at": asset['updated_at'].isoformat() if asset['updated_at'] else None
            },
            "transactions": transaction_list
        })
        
    except Exception as e:
        logger.error(f"Get asset error: {str(e)}")
        return create_error_response(500, "Failed to retrieve asset")

def handle_get_asset_transactions(asset_id, user_id):
    """Get transactions for a specific asset"""
    try:
        # First verify the asset belongs to the user
        asset = execute_query(
            DATABASE_URL,
            "SELECT * FROM assets WHERE asset_id = %s AND user_id = %s",
            (asset_id, user_id)
        )
        
        if not asset:
            return create_error_response(404, "Asset not found")
        
        # Get transaction history
        transactions = execute_query(
            DATABASE_URL,
            """
            SELECT * FROM transactions 
            WHERE asset_id = %s 
            ORDER BY transaction_date DESC, created_at DESC
            """,
            (asset_id,)
        )
        
        transaction_list = []
        for txn in transactions:
            transaction_list.append({
                "transaction_id": txn['transaction_id'],
                "transaction_type": txn['transaction_type'],
                "transaction_date": txn['transaction_date'].isoformat(),
                "shares": float(txn['shares']),
                "price_per_share": float(txn['price_per_share']),
                "currency": txn['currency'],
                "created_at": txn['created_at'].isoformat()
            })
        
        return create_response(200, {
            "transactions": transaction_list,
            "total_count": len(transaction_list)
        })
        
    except Exception as e:
        logger.error(f"Get asset transactions error: {str(e)}")
        return create_error_response(500, "Failed to retrieve asset transactions")

def handle_create_transaction(body, user_id):
    """Handle transaction creation"""
    try:
        asset_id = body.get('asset_id')
        transaction_type = body.get('transaction_type', 'LumpSum')
        
        # Validate transaction type
        valid_types = ['LumpSum', 'Recurring', 'Initialization', 'Dividend']
        if transaction_type not in valid_types:
            return create_error_response(400, f"Invalid transaction type. Must be one of: {', '.join(valid_types)}")
        shares = body.get('shares', 0)
        price_per_share = body.get('price_per_share', 0)
        currency = body.get('currency', 'USD')
        transaction_date = body.get('transaction_date')
        
        if not asset_id:
            return create_error_response(400, "Asset ID is required")
        
        # Handle dividend transactions differently
        if transaction_type == 'Dividend':
            # For dividends, shares should be 0 and price_per_share represents dividend per share
            if shares != 0:
                return create_error_response(400, "Dividend transactions should have shares = 0")
            
            # Validate dividend amount (price_per_share for dividends represents dividend per share)
            dividend_per_share = price_per_share
            if dividend_per_share <= 0:
                return create_error_response(400, "Dividend per share must be greater than 0")
        else:
            # Validate shares and price for non-dividend transactions
            if shares <= 0:
                return create_error_response(400, "Shares must be greater than 0")
            if price_per_share <= 0:
                return create_error_response(400, "Price per share must be greater than 0")
        
        # Verify asset belongs to user
        asset = execute_query(
            DATABASE_URL,
            "SELECT * FROM assets WHERE asset_id = %s AND user_id = %s",
            (asset_id, user_id)
        )
        
        if not asset:
            return create_error_response(404, "Asset not found")
        
        asset = asset[0]
        
        # Parse transaction date
        if transaction_date:
            try:
                from datetime import datetime
                transaction_date = datetime.strptime(transaction_date, '%Y-%m-%d').date()
            except ValueError:
                return create_error_response(400, "Invalid date format. Use YYYY-MM-DD")
        else:
            from datetime import date
            transaction_date = date.today()
        
        # Create transaction
        execute_update(
            DATABASE_URL,
            """
            INSERT INTO transactions (asset_id, transaction_type, transaction_date, shares, price_per_share, currency)
            VALUES (%s, %s, %s, %s, %s, %s)
            """,
            (asset_id, transaction_type, transaction_date, shares, price_per_share, currency)
        )
        
        # Update asset totals (only for non-dividend transactions)
        if transaction_type != 'Dividend':
            new_total_shares = float(asset['total_shares']) + shares
            total_cost = (float(asset['total_shares']) * float(asset['average_cost_basis'])) + (shares * price_per_share)
            new_average_cost = total_cost / new_total_shares if new_total_shares > 0 else 0
            
            execute_update(
                DATABASE_URL,
                """
                UPDATE assets 
                SET total_shares = %s, average_cost_basis = %s, updated_at = CURRENT_TIMESTAMP
                WHERE asset_id = %s
                """,
                (new_total_shares, new_average_cost, asset_id)
            )
        else:
            # For dividends, just update the timestamp without changing shares or cost basis
            execute_update(
                DATABASE_URL,
                """
                UPDATE assets 
                SET updated_at = CURRENT_TIMESTAMP
                WHERE asset_id = %s
                """,
                (asset_id,)
            )
        
        # Get created transaction
        transaction = execute_query(
            DATABASE_URL,
            """
            SELECT * FROM transactions 
            WHERE asset_id = %s AND transaction_date = %s AND shares = %s AND price_per_share = %s
            ORDER BY created_at DESC LIMIT 1
            """,
            (asset_id, transaction_date, shares, price_per_share)
        )[0]
        
        return create_response(201, {
            "message": "Transaction created successfully",
            "transaction": {
                "transaction_id": transaction['transaction_id'],
                "asset_id": transaction['asset_id'],
                "transaction_type": transaction['transaction_type'],
                "transaction_date": transaction['transaction_date'].isoformat(),
                "shares": float(transaction['shares']),
                "price_per_share": float(transaction['price_per_share']),
                "currency": transaction['currency'],
                "created_at": transaction['created_at'].isoformat()
            }
        })
        
    except Exception as e:
        logger.error(f"Create transaction error: {str(e)}")
        return create_error_response(500, "Failed to create transaction")

def handle_get_transactions(user_id):
    """Get all transactions for a user"""
    try:
        transactions = execute_query(
            DATABASE_URL,
            """
            SELECT t.*, a.ticker_symbol, a.asset_type 
            FROM transactions t
            JOIN assets a ON t.asset_id = a.asset_id
            WHERE a.user_id = %s
            ORDER BY t.transaction_date DESC, t.created_at DESC
            """,
            (user_id,)
        )
        
        transaction_list = []
        for txn in transactions:
            transaction_list.append({
                "transaction_id": txn['transaction_id'],
                "asset_id": txn['asset_id'],
                "ticker_symbol": txn['ticker_symbol'],
                "asset_type": txn['asset_type'],
                "transaction_type": txn['transaction_type'],
                "transaction_date": txn['transaction_date'].isoformat(),
                "shares": float(txn['shares']),
                "price_per_share": float(txn['price_per_share']),
                "total_amount": float(txn['shares']) * float(txn['price_per_share']),
                "currency": txn['currency'],
                "created_at": txn['created_at'].isoformat()
            })
        
        return create_response(200, {
            "transactions": transaction_list,
            "total_count": len(transaction_list)
        })
        
    except Exception as e:
        logger.error(f"Get transactions error: {str(e)}")
        return create_error_response(500, "Failed to retrieve transactions")

def handle_update_transaction(transaction_id, body, user_id):
    """Update a transaction and recalculate asset aggregations"""
    try:
        # Verify transaction belongs to user and get current details
        transaction = execute_query(
            DATABASE_URL,
            """
            SELECT t.*, a.user_id, a.asset_id, a.ticker_symbol
            FROM transactions t
            JOIN assets a ON t.asset_id = a.asset_id
            WHERE t.transaction_id = %s AND a.user_id = %s
            """,
            (transaction_id, user_id)
        )
        
        if not transaction:
            return create_error_response(404, "Transaction not found")
        
        transaction = transaction[0]
        asset_id = transaction['asset_id']
        old_shares = float(transaction['shares'])
        old_price = float(transaction['price_per_share'])
        
        # Get update data
        shares = body.get('shares', 0)
        price_per_share = body.get('price_per_share', 0)
        transaction_date = body.get('transaction_date')
        currency = body.get('currency', '').strip()
        
        # Validate input
        if shares <= 0:
            return create_error_response(400, "Shares must be greater than 0")
        
        if price_per_share <= 0:
            return create_error_response(400, "Price per share must be greater than 0")
        
        if not currency:
            return create_error_response(400, "Currency is required")
        
        # Parse transaction date
        if transaction_date:
            try:
                from datetime import datetime
                transaction_date = datetime.strptime(transaction_date, '%Y-%m-%d').date()
            except ValueError:
                return create_error_response(400, "Invalid date format. Use YYYY-MM-DD")
        else:
            transaction_date = transaction['transaction_date']
        
        # Check if shares or price changed (affects asset aggregation)
        shares_changed = abs(float(shares) - old_shares) > 0.000001
        price_changed = abs(float(price_per_share) - old_price) > 0.01
        
        # Update transaction
        execute_update(
            DATABASE_URL,
            """
            UPDATE transactions 
            SET shares = %s, price_per_share = %s, transaction_date = %s, currency = %s
            WHERE transaction_id = %s
            """,
            (shares, price_per_share, transaction_date, currency, transaction_id)
        )
        
        # Recalculate asset aggregations if shares or price changed
        if shares_changed or price_changed:
            logger.info(f"Recalculating asset aggregations for asset {asset_id} due to transaction update")
            
            # Get all transactions for this asset (excluding dividend transactions)
            asset_transactions = execute_query(
                DATABASE_URL,
                """
                SELECT shares, price_per_share, transaction_type
                FROM transactions 
                WHERE asset_id = %s AND transaction_type != 'Dividend'
                ORDER BY transaction_date ASC, created_at ASC
                """,
                (asset_id,)
            )
            
            if asset_transactions:
                # Recalculate totals from all transactions
                total_shares = 0
                total_cost = 0
                
                for txn in asset_transactions:
                    txn_shares = float(txn['shares'])
                    txn_price = float(txn['price_per_share'])
                    total_shares += txn_shares
                    total_cost += txn_shares * txn_price
                
                if total_shares > 0:
                    new_avg_cost = total_cost / total_shares
                    
                    # Update asset with recalculated values
                    execute_update(
                        DATABASE_URL,
                        """
                        UPDATE assets 
                        SET total_shares = %s, average_cost_basis = %s, updated_at = CURRENT_TIMESTAMP
                        WHERE asset_id = %s
                        """,
                        (total_shares, new_avg_cost, asset_id)
                    )
                    
                    logger.info(f"Updated asset {asset_id}: {total_shares} shares @ ${new_avg_cost:.2f}")
                else:
                    # No shares left, delete the asset
                    execute_update(
                        DATABASE_URL,
                        "DELETE FROM assets WHERE asset_id = %s",
                        (asset_id,)
                    )
                    logger.info(f"Deleted asset {asset_id} - no shares remaining")
            else:
                # No transactions left, delete the asset
                execute_update(
                    DATABASE_URL,
                    "DELETE FROM assets WHERE asset_id = %s",
                    (asset_id,)
                )
                logger.info(f"Deleted asset {asset_id} - no transactions remaining")
        
        # Get updated transaction
        updated_transaction = execute_query(
            DATABASE_URL,
            """
            SELECT t.*, a.ticker_symbol, a.asset_type 
            FROM transactions t
            JOIN assets a ON t.asset_id = a.asset_id
            WHERE t.transaction_id = %s
            """,
            (transaction_id,)
        )[0]
        
        return create_response(200, {
            "message": "Transaction updated successfully",
            "transaction": {
                "transaction_id": updated_transaction['transaction_id'],
                "asset_id": updated_transaction['asset_id'],
                "ticker_symbol": updated_transaction['ticker_symbol'],
                "asset_type": updated_transaction['asset_type'],
                "transaction_type": updated_transaction['transaction_type'],
                "transaction_date": updated_transaction['transaction_date'].isoformat(),
                "shares": float(updated_transaction['shares']),
                "price_per_share": float(updated_transaction['price_per_share']),
                "total_amount": float(updated_transaction['shares']) * float(updated_transaction['price_per_share']),
                "currency": updated_transaction['currency'],
                "created_at": updated_transaction['created_at'].isoformat() if updated_transaction['created_at'] else None
            }
        })
        
    except Exception as e:
        logger.error(f"Update transaction error: {str(e)}")
        import traceback
        logger.error(f"Update transaction traceback: {traceback.format_exc()}")
        return create_error_response(500, f"Failed to update transaction: {str(e)}")

def handle_delete_transaction(transaction_id, user_id):
    """Delete a transaction and rollback asset aggregation"""
    try:
        # Verify transaction belongs to user and get transaction details
        transaction = execute_query(
            DATABASE_URL,
            """
            SELECT t.*, a.user_id, a.ticker_symbol, a.asset_id, a.total_shares, a.average_cost_basis
            FROM transactions t
            JOIN assets a ON t.asset_id = a.asset_id
            WHERE t.transaction_id = %s AND a.user_id = %s
            """,
            (transaction_id, user_id)
        )
        
        if not transaction:
            return create_error_response(404, "Transaction not found")
        
        transaction = transaction[0]
        asset_id = transaction['asset_id']
        
        # Handle rollback based on transaction type
        rollback_applied = False
        
        if transaction['transaction_type'] == 'LumpSum':
            # Rollback LumpSum transactions (existing logic)
            # Get current asset totals
            current_total_shares = float(transaction['total_shares'])
            current_avg_cost = float(transaction['average_cost_basis'])
            
            # Get transaction details to rollback
            transaction_shares = float(transaction['shares'])
            transaction_price = float(transaction['price_per_share'])
            
            # Calculate new totals after removing this transaction
            new_total_shares = current_total_shares - transaction_shares
            
            if new_total_shares > 0:
                # Recalculate weighted average cost basis
                # Current total value = current_total_shares * current_avg_cost
                # Transaction value = transaction_shares * transaction_price
                # New total value = current_total_value - transaction_value
                # New avg cost = new_total_value / new_total_shares
                
                current_total_value = current_total_shares * current_avg_cost
                transaction_value = transaction_shares * transaction_price
                new_total_value = current_total_value - transaction_value
                new_avg_cost = new_total_value / new_total_shares
                
                # Update asset with rollback values
                execute_update(
                    DATABASE_URL,
                    """
                    UPDATE assets 
                    SET total_shares = %s, average_cost_basis = %s, updated_at = CURRENT_TIMESTAMP
                    WHERE asset_id = %s
                    """,
                    (new_total_shares, new_avg_cost, asset_id)
                )
            else:
                # If no shares left, delete the asset entirely
                execute_update(
                    DATABASE_URL,
                    "DELETE FROM assets WHERE asset_id = %s",
                    (asset_id,)
                )
            rollback_applied = True
            
        elif transaction['transaction_type'] == 'Recurring':
            # Rollback Recurring transactions - same logic as LumpSum
            logger.info(f"Rolling back recurring transaction {transaction_id}")
            
            # Get current asset totals
            current_total_shares = float(transaction['total_shares'])
            current_avg_cost = float(transaction['average_cost_basis'])
            
            # Get transaction details to rollback
            transaction_shares = float(transaction['shares'])
            transaction_price = float(transaction['price_per_share'])
            
            # Calculate new totals after removing this transaction
            new_total_shares = current_total_shares - transaction_shares
            
            if new_total_shares > 0:
                # Recalculate weighted average cost basis
                current_total_value = current_total_shares * current_avg_cost
                transaction_value = transaction_shares * transaction_price
                new_total_value = current_total_value - transaction_value
                new_avg_cost = new_total_value / new_total_shares
                
                # Update asset with rollback values
                execute_update(
                    DATABASE_URL,
                    """
                    UPDATE assets 
                    SET total_shares = %s, average_cost_basis = %s, updated_at = CURRENT_TIMESTAMP
                    WHERE asset_id = %s
                    """,
                    (new_total_shares, new_avg_cost, asset_id)
                )
                
                logger.info(f"Rolled back recurring transaction: {current_total_shares} -> {new_total_shares} shares")
                logger.info(f"Updated average cost basis: ${current_avg_cost:.2f} -> ${new_avg_cost:.2f}")
            else:
                # If no shares left, delete the asset entirely
                execute_update(
                    DATABASE_URL,
                    "DELETE FROM assets WHERE asset_id = %s",
                    (asset_id,)
                )
                logger.info(f"Deleted asset {asset_id} - no shares remaining after rollback")
            
            rollback_applied = True
            
        elif transaction['transaction_type'] == 'Initialization':
            # Rollback Initialization transactions - similar to LumpSum but more careful
            logger.info(f"Rolling back initialization transaction {transaction_id}")
            
            # For initialization transactions, we need to be extra careful
            # Check if there are other transactions for this asset
            other_transactions = execute_query(
                DATABASE_URL,
                """
                SELECT COUNT(*) as count FROM transactions 
                WHERE asset_id = %s AND transaction_id != %s
                """,
                (asset_id, transaction_id)
            )
            
            if other_transactions[0]['count'] > 0:
                # There are other transactions, so we need to recalculate from scratch
                logger.info("Other transactions exist - recalculating asset totals from remaining transactions")
                
                # Get all remaining transactions for this asset
                remaining_transactions = execute_query(
                    DATABASE_URL,
                    """
                    SELECT shares, price_per_share, transaction_type 
                    FROM transactions 
                    WHERE asset_id = %s AND transaction_id != %s
                    ORDER BY transaction_date ASC, created_at ASC
                    """,
                    (asset_id, transaction_id)
                )
                
                if remaining_transactions:
                    # Recalculate totals from remaining transactions
                    total_shares = 0
                    total_cost = 0
                    
                    for txn in remaining_transactions:
                        if txn['transaction_type'] != 'Dividend':  # Skip dividend transactions
                            shares = float(txn['shares'])
                            price = float(txn['price_per_share'])
                            total_shares += shares
                            total_cost += shares * price
                    
                    if total_shares > 0:
                        new_avg_cost = total_cost / total_shares
                        
                        # Update asset with recalculated values
                        execute_update(
                            DATABASE_URL,
                            """
                            UPDATE assets 
                            SET total_shares = %s, average_cost_basis = %s, updated_at = CURRENT_TIMESTAMP
                            WHERE asset_id = %s
                            """,
                            (total_shares, new_avg_cost, asset_id)
                        )
                        
                        logger.info(f"Recalculated asset totals: {total_shares} shares @ ${new_avg_cost:.2f}")
                    else:
                        # No valid shares left, delete asset
                        execute_update(
                            DATABASE_URL,
                            "DELETE FROM assets WHERE asset_id = %s",
                            (asset_id,)
                        )
                        logger.info(f"Deleted asset {asset_id} - no valid shares remaining")
                else:
                    # No remaining transactions, delete asset
                    execute_update(
                        DATABASE_URL,
                        "DELETE FROM assets WHERE asset_id = %s",
                        (asset_id,)
                    )
                    logger.info(f"Deleted asset {asset_id} - no remaining transactions")
            else:
                # This is the only transaction, delete the entire asset
                execute_update(
                    DATABASE_URL,
                    "DELETE FROM assets WHERE asset_id = %s",
                    (asset_id,)
                )
                logger.info(f"Deleted asset {asset_id} - was the only transaction (initialization)")
            
            rollback_applied = True
            
        elif transaction['transaction_type'] == 'Dividend':
            # Rollback Dividend transactions - find and reset corresponding dividend record
            logger.info(f"Rolling back dividend transaction {transaction_id}")
            
            # Find dividend records that match this transaction
            # We need to find dividends that were processed around the same time and amount
            dividend_records = execute_query(
                DATABASE_URL,
                """
                SELECT dividend_id, total_dividend_amount, is_reinvested 
                FROM dividends 
                WHERE asset_id = %s 
                  AND user_id = %s 
                  AND is_reinvested = TRUE
                  AND ABS(total_dividend_amount - %s) < 0.01
                  AND payment_date = %s
                ORDER BY updated_at DESC
                LIMIT 1
                """,
                (asset_id, user_id, abs(float(transaction['shares']) * float(transaction['price_per_share'])), 
                 transaction['transaction_date'])
            )
            
            if dividend_records:
                dividend_record = dividend_records[0]
                # Reset dividend to pending status
                execute_update(
                    DATABASE_URL,
                    """
                    UPDATE dividends 
                    SET is_reinvested = FALSE, updated_at = CURRENT_TIMESTAMP 
                    WHERE dividend_id = %s
                    """,
                    (dividend_record['dividend_id'],)
                )
                logger.info(f"Reset dividend {dividend_record['dividend_id']} to pending status")
            else:
                logger.warning(f"No matching dividend record found for transaction {transaction_id}")
            
            rollback_applied = True
        
        # Delete the transaction
        execute_update(
            DATABASE_URL,
            "DELETE FROM transactions WHERE transaction_id = %s",
            (transaction_id,)
        )
        
        return create_response(200, {
            "message": f"Transaction for {transaction['ticker_symbol']} deleted successfully",
            "rollback_applied": rollback_applied,
            "transaction_type": transaction['transaction_type']
        })
        
    except Exception as e:
        logger.error(f"Delete transaction error: {str(e)}")
        return create_error_response(500, "Failed to delete transaction")

def handle_update_asset(asset_id, body, user_id):
    """Handle asset update"""
    try:
        # Verify asset belongs to user
        asset = execute_query(
            DATABASE_URL,
            "SELECT * FROM assets WHERE asset_id = %s AND user_id = %s",
            (asset_id, user_id)
        )
        
        if not asset:
            return create_error_response(404, "Asset not found")
        
        # Get update data
        asset_type = body.get('asset_type', '').strip()
        total_shares = body.get('total_shares', 0)
        average_cost_basis = body.get('average_cost_basis', 0)
        currency = body.get('currency', '').strip()
        
        # Validate input
        if not asset_type:
            return create_error_response(400, "Asset type is required")
        
        if total_shares <= 0:
            return create_error_response(400, "Total shares must be greater than 0")
        
        if average_cost_basis <= 0:
            return create_error_response(400, "Average cost basis must be greater than 0")
        
        if not currency:
            return create_error_response(400, "Currency is required")
        
        # Update asset
        execute_update(
            DATABASE_URL,
            """
            UPDATE assets 
            SET asset_type = %s, total_shares = %s, average_cost_basis = %s, 
                currency = %s, updated_at = CURRENT_TIMESTAMP
            WHERE asset_id = %s AND user_id = %s
            """,
            (asset_type, total_shares, average_cost_basis, currency, asset_id, user_id)
        )
        
        # Get updated asset
        updated_asset = execute_query(
            DATABASE_URL,
            "SELECT * FROM assets WHERE asset_id = %s AND user_id = %s",
            (asset_id, user_id)
        )[0]
        
        return create_response(200, {
            "message": "Asset updated successfully",
            "asset": {
                "asset_id": updated_asset['asset_id'],
                "ticker_symbol": updated_asset['ticker_symbol'],
                "asset_type": updated_asset['asset_type'],
                "total_shares": float(updated_asset['total_shares']),
                "average_cost_basis": float(updated_asset['average_cost_basis']),
                "currency": updated_asset['currency'],
                "created_at": updated_asset['created_at'].isoformat(),
                "updated_at": updated_asset['updated_at'].isoformat() if updated_asset['updated_at'] else None
            }
        })
        
    except Exception as e:
        logger.error(f"Update asset error: {str(e)}")
        return create_error_response(500, "Failed to update asset")

def handle_delete_asset(asset_id, user_id):
    """Handle asset deletion"""
    try:
        # Verify asset belongs to user
        asset = execute_query(
            DATABASE_URL,
            "SELECT * FROM assets WHERE asset_id = %s AND user_id = %s",
            (asset_id, user_id)
        )
        
        if not asset:
            return create_error_response(404, "Asset not found")
        
        asset = asset[0]
        
        # Delete associated transactions first (foreign key constraint)
        execute_update(
            DATABASE_URL,
            "DELETE FROM transactions WHERE asset_id = %s",
            (asset_id,)
        )
        
        # Delete the asset
        execute_update(
            DATABASE_URL,
            "DELETE FROM assets WHERE asset_id = %s AND user_id = %s",
            (asset_id, user_id)
        )
        
        return create_response(200, {
            "message": f"Asset {asset['ticker_symbol']} deleted successfully"
        })
        
    except Exception as e:
        logger.error(f"Delete asset error: {str(e)}")
        return create_error_response(500, "Failed to delete asset")

# ============================================================================
# MILESTONE 4: RECURRING INVESTMENTS & AUTOMATION FUNCTIONS
# ============================================================================

def create_recurring_investments_table():
    """Create recurring_investments table if it doesn't exist"""
    try:
        execute_update(
            DATABASE_URL,
            """
            CREATE TABLE IF NOT EXISTS recurring_investments (
                recurring_id SERIAL PRIMARY KEY,
                user_id INTEGER NOT NULL REFERENCES users(user_id) ON DELETE CASCADE,
                ticker_symbol VARCHAR(10) NOT NULL,
                amount DECIMAL(15,2) NOT NULL,
                currency VARCHAR(3) NOT NULL DEFAULT 'USD',
                frequency VARCHAR(20) NOT NULL CHECK (frequency IN ('daily', 'weekly', 'monthly', 'quarterly')),
                start_date DATE NOT NULL,
                next_run_date DATE NOT NULL,
                is_active BOOLEAN DEFAULT TRUE,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
            """
        )
        
        # Drop and recreate the constraint if it exists with wrong values
        try:
            execute_update(
                DATABASE_URL,
                """
                ALTER TABLE recurring_investments 
                DROP CONSTRAINT IF EXISTS recurring_investments_frequency_check
                """
            )
            execute_update(
                DATABASE_URL,
                """
                ALTER TABLE recurring_investments 
                ADD CONSTRAINT recurring_investments_frequency_check 
                CHECK (frequency IN ('daily', 'weekly', 'monthly', 'quarterly'))
                """
            )
        except Exception as constraint_error:
            logger.warning(f"Constraint update warning: {str(constraint_error)}")
        
        logger.info("âœ… RecurringInvestments table created/verified")
    except Exception as e:
        logger.error(f"âŒ Failed to create recurring_investments table: {str(e)}")

def create_fire_profile_table():
    """Create fire_profile table if it doesn't exist and migrate existing tables"""
    try:
        # First, create the table if it doesn't exist (basic structure)
        execute_update(
            DATABASE_URL,
            """
            CREATE TABLE IF NOT EXISTS fire_profile (
                profile_id SERIAL PRIMARY KEY,
                user_id INTEGER NOT NULL UNIQUE REFERENCES users(user_id) ON DELETE CASCADE,
                annual_expenses DECIMAL(15,2),
                safe_withdrawal_rate DECIMAL(5,4) DEFAULT 0.04,
                expected_annual_return DECIMAL(5,4) DEFAULT 0.07,
                target_retirement_age INTEGER,
                barista_monthly_contribution DECIMAL(15,2) DEFAULT 0,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
            """
        )
        
        # Now add the comprehensive fields if they don't exist (migration)
        comprehensive_fields = [
            ("annual_income", "DECIMAL(15,2) DEFAULT 1000000"),
            ("annual_savings", "DECIMAL(15,2) DEFAULT 200000"),
            ("expected_return_pre_retirement", "DECIMAL(5,4) DEFAULT 0.07"),
            ("expected_return_post_retirement", "DECIMAL(5,4) DEFAULT 0.05"),
            ("expected_inflation_rate", "DECIMAL(5,4) DEFAULT 0.025"),
            ("other_passive_income", "DECIMAL(15,2) DEFAULT 0"),
            ("effective_tax_rate", "DECIMAL(5,4) DEFAULT 0.15"),
            ("barista_monthly_contribution", "DECIMAL(15,2) DEFAULT 0"),  # New: monthly contribution for Barista FIRE
            ("inflation_rate", "DECIMAL(5,4) DEFAULT 0.025")  # New: user-specific inflation assumption
        ]
        
        for field_name, field_definition in comprehensive_fields:
            try:
                # Try to add each column if it doesn't exist
                execute_update(
                    DATABASE_URL,
                    f"ALTER TABLE fire_profile ADD COLUMN IF NOT EXISTS {field_name} {field_definition}"
                )
                logger.info(f"âœ… Added/verified column: {field_name}")
            except Exception as e:
                # Column might already exist, which is fine
                logger.info(f"â„¹ï¸ Column {field_name} already exists or error: {str(e)}")
        
        logger.info("âœ… FIREProfile table created/verified with comprehensive fields")
    except Exception as e:
        logger.error(f"âŒ Failed to create/migrate fire_profile table: {str(e)}")

def create_dividends_table():
    """Create dividends table for Milestone 4 dividend tracking"""
    try:
        execute_update(
            DATABASE_URL,
            """
            CREATE TABLE IF NOT EXISTS dividends (
                dividend_id SERIAL PRIMARY KEY,
                asset_id INTEGER NOT NULL REFERENCES assets(asset_id) ON DELETE CASCADE,
                user_id INTEGER NOT NULL REFERENCES users(user_id) ON DELETE CASCADE,
                ticker_symbol VARCHAR(10) NOT NULL,
                ex_dividend_date DATE NOT NULL,
                payment_date DATE,
                dividend_per_share DECIMAL(10,4) NOT NULL,
                total_dividend_amount DECIMAL(15,2) NOT NULL,
                currency VARCHAR(3) NOT NULL DEFAULT 'USD',
                dividend_type VARCHAR(20) DEFAULT 'regular',
                tax_rate DECIMAL(5,2) DEFAULT 20.0,
                is_reinvested BOOLEAN DEFAULT FALSE,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
            """
        )
        logger.info("âœ… Dividends table created/verified")
    except Exception as e:
        logger.error(f"âŒ Failed to create dividends table: {str(e)}")

# ============================================================================
# DIVIDEND MANAGEMENT FUNCTIONS
# ============================================================================

def handle_get_dividends(user_id):
    """Get all dividends for a user with proper currency conversion using asset currencies"""
    try:
        # Get user's base currency
        user = execute_query(
            DATABASE_URL,
            "SELECT base_currency FROM users WHERE user_id = %s",
            (user_id,)
        )
        
        if not user:
            return create_error_response(404, "User not found")
        
        base_currency = user[0]['base_currency']
        
        # Get dividends with asset currency information
        dividends = execute_query(
            DATABASE_URL,
            """
            SELECT d.*, a.ticker_symbol, a.total_shares as shares_owned, a.currency as asset_currency
            FROM dividends d
            JOIN assets a ON d.asset_id = a.asset_id
            WHERE d.user_id = %s
            ORDER BY d.payment_date DESC, d.created_at DESC
            """,
            (user_id,)
        )
        
        # Get exchange rates for currency conversion
        exchange_rates = {}
        # Use asset currencies (not dividend currencies) for conversion
        unique_currencies = set([d['asset_currency'] for d in dividends if d['asset_currency'] != base_currency])
        
        if unique_currencies:
            try:
                # Fetch exchange rates for all unique asset currencies
                cached_rates = get_cached_exchange_rate(base_currency, 'ALL')
                if cached_rates and 'rates' in cached_rates:
                    exchange_rates = cached_rates['rates']
                else:
                    # Fetch fresh rates if not cached
                    url = f"{EXCHANGE_RATE_BASE_URL}/{base_currency}"
                    response = requests.get(url, timeout=10)
                    if response.status_code == 200:
                        data = response.json()
                        exchange_rates = data.get('rates', {})
                        # Cache the rates
                        result = {
                            "success": True,
                            "base": base_currency,
                            "rates": exchange_rates,
                            "last_updated": data.get('date', datetime.utcnow().isoformat()),
                            "source": "ExchangeRate-API",
                            "cached": False
                        }
                        set_cached_exchange_rate(base_currency, 'ALL', result)
            except Exception as e:
                logger.warning(f"Failed to fetch exchange rates: {str(e)}")
                # Continue without conversion if rates unavailable
        
        def convert_to_base_currency(amount, from_currency):
            """Convert amount from asset currency to user's base currency"""
            if from_currency == base_currency:
                return float(amount)
            
            if from_currency in exchange_rates:
                # Convert from asset currency to base currency
                rate = exchange_rates[from_currency]
                if rate > 0:
                    converted = float(amount) / rate
                    logger.info(f"ðŸ’± Converted {amount} {from_currency} to {converted:.2f} {base_currency} (rate: {rate})")
                    return converted
            
            # If conversion fails, return original amount
            logger.warning(f"âš ï¸ Could not convert {amount} {from_currency} to {base_currency}")
            return float(amount)
        
        # Calculate totals with currency conversion using ASSET currencies
        pending_dividends = [d for d in dividends if not d.get('is_reinvested', False)]
        processed_dividends = [d for d in dividends if d.get('is_reinvested', False)]
        
        total_pending_base = sum(
            convert_to_base_currency(d['total_dividend_amount'], d['asset_currency']) 
            for d in pending_dividends
        )
        total_processed_base = sum(
            convert_to_base_currency(d['total_dividend_amount'], d['asset_currency']) 
            for d in processed_dividends
        )
        
        # Format dividends for frontend
        formatted_dividends = []
        for d in dividends:
            original_amount = float(d['total_dividend_amount'])
            asset_currency = d['asset_currency']
            converted_amount = convert_to_base_currency(d['total_dividend_amount'], asset_currency)
            
            formatted_dividends.append({
                'dividend_id': d['dividend_id'],
                'asset_id': d['asset_id'],
                'ticker_symbol': d['ticker_symbol'],
                'dividend_per_share': float(d['dividend_per_share']),
                'ex_dividend_date': d['ex_dividend_date'].isoformat() if d['ex_dividend_date'] else None,
                'payment_date': d['payment_date'].isoformat() if d['payment_date'] else None,
                'total_dividend': original_amount,
                'total_dividend_base_currency': converted_amount,
                'shares_owned': float(d['shares_owned']),
                'currency': asset_currency,  # Use asset currency, not dividend currency
                'base_currency': base_currency,
                'exchange_rate_used': exchange_rates.get(asset_currency) if asset_currency != base_currency else 1.0,
                'tax_rate': float(d['tax_rate']) if 'tax_rate' in d and d['tax_rate'] is not None else 20.0,  # Handle 0 as valid tax rate
                'status': 'processed' if d.get('is_reinvested', False) else 'pending',
                'created_at': d['created_at'].isoformat() if d['created_at'] else None,
                'updated_at': d['updated_at'].isoformat() if d['updated_at'] else None
            })
        
        return create_response(200, {
            "dividends": formatted_dividends,
            "total_pending": float(total_pending_base),
            "total_processed": float(total_processed_base),
            "base_currency": base_currency,
            "exchange_rates_available": len(exchange_rates) > 0,
            "summary": {
                "pending_count": len(pending_dividends),
                "processed_count": len(processed_dividends),
                "total_count": len(dividends),
                "currencies_involved": list(set([d['asset_currency'] for d in dividends]))
            }
        })
        
    except Exception as e:
        logger.error(f"Get dividends error: {str(e)}")
        return create_error_response(500, "Failed to get dividends")

def handle_create_dividend(body, user_id):
    """Create a new dividend manually using the asset's currency"""
    try:
        # Validate required fields (removed currency as it should come from asset)
        required_fields = ['asset_id', 'dividend_per_share', 'ex_dividend_date', 'payment_date']
        for field in required_fields:
            if field not in body:
                return create_error_response(400, f"Missing required field: {field}")
        
        asset_id = body['asset_id']
        dividend_per_share = float(body['dividend_per_share'])
        ex_dividend_date = body['ex_dividend_date']
        payment_date = body['payment_date']
        # Handle tax_rate properly - 0 is a valid value, only use default if not provided
        tax_rate = float(body['tax_rate']) if 'tax_rate' in body else 20.0
        
        # Verify asset belongs to user and get details including currency
        asset = execute_query(
            DATABASE_URL,
            "SELECT * FROM assets WHERE asset_id = %s AND user_id = %s",
            (asset_id, user_id)
        )
        
        if not asset:
            return create_error_response(404, "Asset not found")
        
        asset = asset[0]
        asset_currency = asset['currency']  # Use the asset's currency
        total_dividend = dividend_per_share * float(asset['total_shares'])
        
        # Create dividend record using asset's currency
        dividend_id = execute_update(
            DATABASE_URL,
            """
            INSERT INTO dividends (
                asset_id, user_id, ticker_symbol, ex_dividend_date, payment_date,
                dividend_per_share, total_dividend_amount, currency, tax_rate
            ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
            RETURNING dividend_id
            """,
            (asset_id, user_id, asset['ticker_symbol'], ex_dividend_date, payment_date,
             dividend_per_share, total_dividend, asset_currency, tax_rate)
        )
        
        return create_response(201, {
            "message": "Dividend created successfully",
            "dividend": {
                "dividend_id": dividend_id,
                "asset_id": asset_id,
                "ticker_symbol": asset['ticker_symbol'],
                "dividend_per_share": dividend_per_share,
                "total_dividend": total_dividend,
                "ex_dividend_date": ex_dividend_date,
                "payment_date": payment_date,
                "currency": asset_currency,  # Return asset's currency
                "status": "pending"
            }
        })
        
    except Exception as e:
        logger.error(f"Create dividend error: {str(e)}")
        return create_error_response(500, "Failed to create dividend")

def handle_process_dividend(dividend_id, body, user_id):
    """Process a dividend (reinvest or add to cash)"""
    try:
        action = body.get('action')  # 'reinvest' or 'cash'
        
        if action not in ['reinvest', 'cash']:
            return create_error_response(400, "Action must be 'reinvest' or 'cash'")
        
        # Get dividend details
        dividend = execute_query(
            DATABASE_URL,
            """
            SELECT d.*, a.ticker_symbol
            FROM dividends d
            JOIN assets a ON d.asset_id = a.asset_id
            WHERE d.dividend_id = %s AND d.user_id = %s AND d.is_reinvested = FALSE
            """,
            (dividend_id, user_id)
        )
        
        if not dividend:
            return create_error_response(404, "Dividend not found or already processed")
        
        dividend = dividend[0]
        
        if action == 'reinvest':
            # Reinvest in specified asset
            reinvest_asset_id = body.get('reinvest_asset_id', dividend['asset_id'])
            
            try:
                # Get current stock price for reinvestment
                stock_price_data = fetch_stock_price_with_fallback(dividend['ticker_symbol'])
                if stock_price_data and 'price' in stock_price_data:
                    current_price = stock_price_data['price']
                else:
                    return create_error_response(400, "Unable to get current stock price for reinvestment")
                
                # ðŸ”§ FIXED: Calculate after-tax dividend amount for reinvestment
                # In real life, dividends are taxed before reinvestment
                # Handle tax_rate properly - 0 is a valid value, only use default if not set
                tax_rate = float(dividend['tax_rate']) if 'tax_rate' in dividend and dividend['tax_rate'] is not None else 20.0
                gross_dividend_amount = float(dividend['total_dividend_amount'])
                after_tax_dividend_amount = gross_dividend_amount * (1 - tax_rate / 100)
                
                # Calculate shares to buy with after-tax amount
                shares_to_buy = after_tax_dividend_amount / current_price
                
                logger.info(f"Dividend reinvestment calculation:")
                logger.info(f"  Gross dividend: {gross_dividend_amount}")
                logger.info(f"  Tax rate: {tax_rate}%")
                logger.info(f"  After-tax amount: {after_tax_dividend_amount}")
                logger.info(f"  Current price: {current_price}")
                logger.info(f"  Shares to buy: {shares_to_buy}")
                
                # Create transaction with after-tax amount
                execute_update(
                    DATABASE_URL,
                    """
                    INSERT INTO transactions (
                        asset_id, transaction_type, transaction_date, shares, 
                        price_per_share, currency
                    ) VALUES (%s, %s, %s, %s, %s, %s)
                    """,
                    (reinvest_asset_id, 'Dividend', dividend['payment_date'], 
                     shares_to_buy, current_price, dividend['currency'])
                )
                
                # Update asset totals
                asset = execute_query(
                    DATABASE_URL,
                    "SELECT * FROM assets WHERE asset_id = %s",
                    (reinvest_asset_id,)
                )[0]
                
                new_total_shares = float(asset['total_shares']) + shares_to_buy
                current_total_value = float(asset['total_shares']) * float(asset['average_cost_basis'])
                
                # ðŸ”§ FIXED: Use after-tax amount for investment value calculation
                # This represents the actual cash value invested (after taxes)
                new_investment_value = after_tax_dividend_amount  # Use after-tax amount, not shares * price
                new_total_value = current_total_value + new_investment_value
                new_avg_cost = new_total_value / new_total_shares
                
                logger.info(f"Asset update calculation:")
                logger.info(f"  Previous shares: {asset['total_shares']}")
                logger.info(f"  New shares added: {shares_to_buy}")
                logger.info(f"  Total shares: {new_total_shares}")
                logger.info(f"  Previous avg cost: {asset['average_cost_basis']}")
                logger.info(f"  New avg cost: {new_avg_cost}")
                
                execute_update(
                    DATABASE_URL,
                    """
                    UPDATE assets 
                    SET total_shares = %s, average_cost_basis = %s, updated_at = CURRENT_TIMESTAMP
                    WHERE asset_id = %s
                    """,
                    (new_total_shares, new_avg_cost, reinvest_asset_id)
                )
                
            except Exception as e:
                logger.error(f"Reinvestment error: {str(e)}")
                return create_error_response(500, "Failed to process reinvestment")
                
        elif action == 'cash':
            # Add to specified cash asset or create default if not specified
            cash_asset_id = body.get('cash_asset_id')
            
            # ðŸ”§ FIXED: Calculate after-tax dividend amount for cash
            # In real life, dividends are taxed before being added to cash
            # Handle tax_rate properly - 0 is a valid value, only use default if not set
            tax_rate = float(dividend['tax_rate']) if 'tax_rate' in dividend and dividend['tax_rate'] is not None else 20.0
            gross_dividend_amount = float(dividend['total_dividend_amount'])
            after_tax_dividend_amount = gross_dividend_amount * (1 - tax_rate / 100)
            
            logger.info(f"Dividend cash processing:")
            logger.info(f"  Gross dividend: {gross_dividend_amount}")
            logger.info(f"  Tax rate: {tax_rate}%")
            logger.info(f"  After-tax amount: {after_tax_dividend_amount}")
            
            if cash_asset_id:
                # Use specified cash asset
                cash_asset = execute_query(
                    DATABASE_URL,
                    "SELECT * FROM assets WHERE asset_id = %s AND user_id = %s",
                    (cash_asset_id, user_id)
                )
                
                if not cash_asset:
                    return create_error_response(404, "Specified cash asset not found")
                
                cash_asset = cash_asset[0]
                
                # Update existing cash asset with after-tax amount
                new_cash_amount = float(cash_asset['total_shares']) + after_tax_dividend_amount
                execute_update(
                    DATABASE_URL,
                    """
                    UPDATE assets 
                    SET total_shares = %s, updated_at = CURRENT_TIMESTAMP
                    WHERE asset_id = %s
                    """,
                    (new_cash_amount, cash_asset_id)
                )
                
            else:
                # Fallback to default CASH asset (create if doesn't exist)
                cash_asset = execute_query(
                    DATABASE_URL,
                    "SELECT * FROM assets WHERE user_id = %s AND ticker_symbol = 'CASH'",
                    (user_id,)
                )
                
                if not cash_asset:
                    # Create default cash asset with after-tax amount
                    execute_update(
                        DATABASE_URL,
                        """
                        INSERT INTO assets (
                            user_id, ticker_symbol, asset_type, total_shares, 
                            average_cost_basis, currency
                        ) VALUES (%s, %s, %s, %s, %s, %s)
                        """,
                        (user_id, 'CASH', 'Cash', after_tax_dividend_amount, 
                         1.0, dividend['currency'])
                    )
                    
                    # Get the newly created asset ID
                    cash_asset_id = execute_query(
                        DATABASE_URL,
                        "SELECT asset_id FROM assets WHERE user_id = %s AND ticker_symbol = 'CASH'",
                        (user_id,)
                    )[0]['asset_id']
                else:
                    # Update existing default cash asset with after-tax amount
                    cash_asset = cash_asset[0]
                    cash_asset_id = cash_asset['asset_id']
                    new_cash_amount = float(cash_asset['total_shares']) + after_tax_dividend_amount
                    execute_update(
                        DATABASE_URL,
                        """
                        UPDATE assets 
                        SET total_shares = %s, updated_at = CURRENT_TIMESTAMP
                        WHERE asset_id = %s
                        """,
                        (new_cash_amount, cash_asset_id)
                    )
            
            # Create cash transaction with after-tax amount
            execute_update(
                DATABASE_URL,
                """
                INSERT INTO transactions (
                    asset_id, transaction_type, transaction_date, shares, 
                    price_per_share, currency
                ) VALUES (%s, %s, %s, %s, %s, %s)
                """,
                (cash_asset_id, 'Dividend', dividend['payment_date'], 
                 after_tax_dividend_amount, 1.0, dividend['currency'])
            )
        
        # Mark dividend as processed
        execute_update(
            DATABASE_URL,
            "UPDATE dividends SET is_reinvested = TRUE, updated_at = CURRENT_TIMESTAMP WHERE dividend_id = %s",
            (dividend_id,)
        )
        
        return create_response(200, {
            "message": f"Dividend {action}ed successfully",
            "action": action,
            "amount": float(dividend['total_dividend_amount'])
        })
        
    except Exception as e:
        logger.error(f"Process dividend error: {str(e)}")
        return create_error_response(500, "Failed to process dividend")

def handle_update_dividend(dividend_id, body, user_id):
    """Update a dividend (mainly for tax rate changes)"""
    try:
        # Verify dividend belongs to user
        dividend = execute_query(
            DATABASE_URL,
            "SELECT * FROM dividends WHERE dividend_id = %s AND user_id = %s",
            (dividend_id, user_id)
        )
        
        if not dividend:
            return create_error_response(404, "Dividend not found")
        
        dividend = dividend[0]
        
        # Get update fields from body
        tax_rate = body.get('tax_rate')
        dividend_per_share = body.get('dividend_per_share')
        ex_dividend_date = body.get('ex_dividend_date')
        payment_date = body.get('payment_date')
        
        # Build update query dynamically based on provided fields
        update_fields = []
        update_values = []
        
        if tax_rate is not None:
            update_fields.append("tax_rate = %s")
            update_values.append(float(tax_rate))
        
        if dividend_per_share is not None:
            update_fields.append("dividend_per_share = %s")
            update_values.append(float(dividend_per_share))
            # Also update total dividend amount
            total_dividend = float(dividend_per_share) * float(dividend['total_dividend_amount']) / float(dividend['dividend_per_share'])
            update_fields.append("total_dividend_amount = %s")
            update_values.append(total_dividend)
        
        if ex_dividend_date is not None:
            update_fields.append("ex_dividend_date = %s")
            update_values.append(ex_dividend_date)
        
        if payment_date is not None:
            update_fields.append("payment_date = %s")
            update_values.append(payment_date)
        
        if not update_fields:
            return create_error_response(400, "No valid fields to update")
        
        # Add updated_at timestamp
        update_fields.append("updated_at = CURRENT_TIMESTAMP")
        update_values.append(dividend_id)
        
        # Execute update
        update_query = f"UPDATE dividends SET {', '.join(update_fields)} WHERE dividend_id = %s"
        execute_update(DATABASE_URL, update_query, update_values)
        
        # Get updated dividend
        updated_dividend = execute_query(
            DATABASE_URL,
            """
            SELECT d.*, a.ticker_symbol, a.total_shares as shares_owned, a.currency as asset_currency
            FROM dividends d
            JOIN assets a ON d.asset_id = a.asset_id
            WHERE d.dividend_id = %s
            """,
            (dividend_id,)
        )[0]
        
        return create_response(200, {
            "message": "Dividend updated successfully",
            "dividend": {
                "dividend_id": updated_dividend['dividend_id'],
                "asset_id": updated_dividend['asset_id'],
                "ticker_symbol": updated_dividend['ticker_symbol'],
                "dividend_per_share": float(updated_dividend['dividend_per_share']),
                "ex_dividend_date": updated_dividend['ex_dividend_date'].isoformat() if updated_dividend['ex_dividend_date'] else None,
                "payment_date": updated_dividend['payment_date'].isoformat() if updated_dividend['payment_date'] else None,
                "total_dividend": float(updated_dividend['total_dividend_amount']),
                "shares_owned": float(updated_dividend['shares_owned']),
                "currency": updated_dividend['asset_currency'],
                "tax_rate": float(updated_dividend['tax_rate']) if 'tax_rate' in updated_dividend and updated_dividend['tax_rate'] is not None else 20.0,
                "status": "processed" if updated_dividend.get('is_reinvested', False) else "pending",
                "created_at": updated_dividend['created_at'].isoformat(),
                "updated_at": updated_dividend['updated_at'].isoformat() if updated_dividend['updated_at'] else None
            }
        })
        
    except Exception as e:
        logger.error(f"Update dividend error: {str(e)}")
        return create_error_response(500, "Failed to update dividend")

def handle_delete_dividend(dividend_id, user_id):
    """Delete a dividend"""
    try:
        # Verify dividend belongs to user
        dividend = execute_query(
            DATABASE_URL,
            "SELECT * FROM dividends WHERE dividend_id = %s AND user_id = %s",
            (dividend_id, user_id)
        )
        
        if not dividend:
            return create_error_response(404, "Dividend not found")
        
        # Delete the dividend
        execute_update(
            DATABASE_URL,
            "DELETE FROM dividends WHERE dividend_id = %s",
            (dividend_id,)
        )
        
        return create_response(200, {
            "message": "Dividend deleted successfully"
        })
        
    except Exception as e:
        logger.error(f"Delete dividend error: {str(e)}")
        return create_error_response(500, "Failed to delete dividend")

# ===== DIVIDEND AUTO-DETECTION WITH REAL API INTEGRATION =====

def fetch_dividend_data_from_apis(ticker_symbol):
    """
    Fetch real dividend data from multiple APIs with fallback mechanism
    Returns: dict with dividend information or None if no data found
    """
    dividend_data = None
    
    # Try multiple APIs in order of preference
    apis_to_try = [
        ('yahoo_finance', fetch_dividend_from_yahoo),
        ('alpha_vantage', fetch_dividend_from_alpha_vantage),
        ('finnhub', fetch_dividend_from_finnhub),
    ]
    
    for api_name, fetch_function in apis_to_try:
        try:
            logger.info(f"Trying {api_name} for dividend data: {ticker_symbol}")
            dividend_data = fetch_function(ticker_symbol)
            
            if dividend_data and dividend_data.get('dividend_per_share', 0) > 0:
                logger.info(f"âœ… {api_name} returned dividend data for {ticker_symbol}: ${dividend_data['dividend_per_share']}")
                dividend_data['source'] = api_name
                return dividend_data
            else:
                logger.info(f"âš ï¸ {api_name} returned no dividend data for {ticker_symbol}")
                
        except Exception as e:
            logger.warning(f"âŒ {api_name} failed for {ticker_symbol}: {str(e)}")
            continue
    
    logger.info(f"ðŸ” No dividend data found for {ticker_symbol} from any API")
    return None

def fetch_dividend_from_yahoo(ticker_symbol):
    """
    Fetch dividend data from Yahoo Finance API
    Returns recent dividend information
    """
    try:
        # Yahoo Finance API endpoint for dividend history
        url = f"https://query1.finance.yahoo.com/v8/finance/chart/{ticker_symbol}"
        params = {
            'range': '1y',
            'interval': '1d',
            'events': 'div'
        }
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
        }
        
        response = requests.get(url, params=params, headers=headers, timeout=10)
        response.raise_for_status()
        
        data = response.json()
        
        # Extract dividend information
        chart_data = data.get('chart', {}).get('result', [])
        if not chart_data:
            return None
            
        events = chart_data[0].get('events', {})
        dividends = events.get('dividends', {})
        
        if not dividends:
            return None
        
        # Get the most recent dividend
        recent_dividend = None
        recent_timestamp = 0
        
        for timestamp, div_info in dividends.items():
            timestamp_int = int(timestamp)
            if timestamp_int > recent_timestamp:
                recent_timestamp = timestamp_int
                recent_dividend = div_info
        
        if recent_dividend:
            # Convert timestamp to date
            ex_date = datetime.fromtimestamp(recent_timestamp).date()
            
            return {
                'dividend_per_share': float(recent_dividend.get('amount', 0)),
                'ex_dividend_date': ex_date,
                'payment_date': ex_date + timedelta(days=15),  # Estimate payment date
                'currency': 'USD',
                'dividend_type': 'regular',
                'frequency': 'quarterly'  # Most common
            }
            
    except Exception as e:
        logger.error(f"Yahoo Finance API error for {ticker_symbol}: {str(e)}")
        raise

def fetch_dividend_from_alpha_vantage(ticker_symbol):
    """
    Fetch dividend data from Alpha Vantage API
    """
    try:
        api_key = os.environ.get('ALPHA_VANTAGE_API_KEY')
        if not api_key:
            raise Exception("Alpha Vantage API key not configured")
        
        url = "https://www.alphavantage.co/query"
        params = {
            'function': 'CASH_FLOW',
            'symbol': ticker_symbol,
            'apikey': api_key
        }
        
        response = requests.get(url, params=params, timeout=15)
        response.raise_for_status()
        
        data = response.json()
        
        # Check for API limit
        if 'Note' in data:
            raise Exception("Alpha Vantage API limit reached")
        
        # Extract dividend information from cash flow data
        quarterly_reports = data.get('quarterlyReports', [])
        if not quarterly_reports:
            return None
        
        # Look for dividend payments in recent quarters
        recent_report = quarterly_reports[0]
        dividend_payout = recent_report.get('dividendPayout')
        
        if dividend_payout and dividend_payout != 'None':
            # This is total dividend payout, need to estimate per share
            # For now, we'll use a fallback approach
            return None
            
    except Exception as e:
        logger.error(f"Alpha Vantage API error for {ticker_symbol}: {str(e)}")
        raise

def fetch_dividend_from_finnhub(ticker_symbol):
    """
    Fetch dividend data from Finnhub API
    """
    try:
        api_key = os.environ.get('FINNHUB_API_KEY')
        if not api_key:
            raise Exception("Finnhub API key not configured")
        
        # Get dividend data from Finnhub
        url = "https://finnhub.io/api/v1/stock/dividend"
        params = {
            'symbol': ticker_symbol,
            'from': (datetime.now() - timedelta(days=365)).strftime('%Y-%m-%d'),
            'to': datetime.now().strftime('%Y-%m-%d'),
            'token': api_key
        }
        
        response = requests.get(url, params=params, timeout=10)
        response.raise_for_status()
        
        data = response.json()
        
        if not data or len(data) == 0:
            return None
        
        # Get the most recent dividend
        recent_dividend = data[0]  # Finnhub returns sorted by date desc
        
        return {
            'dividend_per_share': float(recent_dividend.get('amount', 0)),
            'ex_dividend_date': datetime.strptime(recent_dividend.get('exDate'), '%Y-%m-%d').date(),
            'payment_date': datetime.strptime(recent_dividend.get('payDate'), '%Y-%m-%d').date() if recent_dividend.get('payDate') else None,
            'currency': recent_dividend.get('currency', 'USD'),
            'dividend_type': 'regular',
            'frequency': recent_dividend.get('frequency', 'quarterly')
        }
        
    except Exception as e:
        logger.error(f"Finnhub API error for {ticker_symbol}: {str(e)}")
        raise

def get_fallback_dividend_data(ticker_symbol):
    """
    Fallback dividend data for common stocks when APIs fail
    This ensures the feature works even if external APIs are down
    """
    fallback_data = {
        'AAPL': {'dividend_per_share': 0.24, 'frequency': 'quarterly'},
        'MSFT': {'dividend_per_share': 0.75, 'frequency': 'quarterly'},
        'NVDA': {'dividend_per_share': 0.04, 'frequency': 'quarterly'},
        'SPY': {'dividend_per_share': 1.35, 'frequency': 'quarterly'},
        'VTI': {'dividend_per_share': 0.85, 'frequency': 'quarterly'},
        'QQQ': {'dividend_per_share': 0.65, 'frequency': 'quarterly'},
        'VOO': {'dividend_per_share': 1.40, 'frequency': 'quarterly'},
        'VEA': {'dividend_per_share': 0.85, 'frequency': 'quarterly'},
        'VWO': {'dividend_per_share': 0.75, 'frequency': 'quarterly'},
        'BND': {'dividend_per_share': 0.18, 'frequency': 'monthly'},
        'VXUS': {'dividend_per_share': 0.80, 'frequency': 'quarterly'},
        'SCHD': {'dividend_per_share': 0.70, 'frequency': 'quarterly'},
        'JEPI': {'dividend_per_share': 0.45, 'frequency': 'monthly'},
        'JEPQ': {'dividend_per_share': 0.40, 'frequency': 'monthly'},
        # Non-dividend stocks
        'GOOGL': {'dividend_per_share': 0.0, 'frequency': 'none'},
        'GOOG': {'dividend_per_share': 0.0, 'frequency': 'none'},
        'TSLA': {'dividend_per_share': 0.0, 'frequency': 'none'},
        'AMZN': {'dividend_per_share': 0.0, 'frequency': 'none'},
        'META': {'dividend_per_share': 0.0, 'frequency': 'none'},
        'NFLX': {'dividend_per_share': 0.0, 'frequency': 'none'},
    }
    
    if ticker_symbol in fallback_data:
        data = fallback_data[ticker_symbol]
        if data['dividend_per_share'] > 0:
            from datetime import date, timedelta
            return {
                'dividend_per_share': data['dividend_per_share'],
                'ex_dividend_date': date.today() - timedelta(days=30),
                'payment_date': date.today() - timedelta(days=15),
                'currency': 'USD',
                'dividend_type': 'regular',
                'frequency': data['frequency'],
                'source': 'fallback'
            }
    
    return None

def handle_auto_detect_dividends(user_id):
    """
    Enhanced auto-detect dividends with real API integration
    Fetches actual dividend data from Yahoo Finance, Alpha Vantage, and Finnhub
    """
    try:
        logger.info(f"ðŸ” Starting dividend auto-detection for user {user_id}")
        
        # Get user's stock and ETF assets
        assets = execute_query(
            DATABASE_URL,
            """
            SELECT * FROM assets 
            WHERE user_id = %s AND asset_type IN ('Stock', 'ETF')
            ORDER BY ticker_symbol
            """,
            (user_id,)
        )
        
        if not assets:
            logger.info("No stock or ETF assets found for dividend detection")
            return create_response(200, {
                "detected": 0,
                "message": "No stock or ETF assets found for dividend detection"
            })
        
        logger.info(f"Found {len(assets)} assets to check for dividends")
        
        detected_count = 0
        skipped_count = 0
        api_errors = []
        
        for asset in assets:
            ticker = asset['ticker_symbol']
            asset_id = asset['asset_id']
            total_shares = float(asset['total_shares'])
            
            logger.info(f"ðŸ” Checking dividends for {ticker} ({total_shares} shares)")
            
            # Skip if we already have recent dividends for this asset
            existing_dividends = execute_query(
                DATABASE_URL,
                """
                SELECT COUNT(*) as count FROM dividends 
                WHERE asset_id = %s AND ex_dividend_date >= CURRENT_DATE - INTERVAL '90 days'
                """,
                (asset_id,)
            )
            
            if existing_dividends and existing_dividends[0]['count'] > 0:
                logger.info(f"â­ï¸ Skipping {ticker} - recent dividends already exist")
                skipped_count += 1
                continue
            
            # Try to fetch real dividend data from APIs
            dividend_data = None
            
            try:
                dividend_data = fetch_dividend_data_from_apis(ticker)
            except Exception as e:
                logger.warning(f"API fetch failed for {ticker}: {str(e)}")
                api_errors.append(f"{ticker}: {str(e)}")
            
            # If API fetch failed, try fallback data
            if not dividend_data:
                logger.info(f"ðŸ”„ Trying fallback data for {ticker}")
                dividend_data = get_fallback_dividend_data(ticker)
            
            # If we have dividend data, create the record
            if dividend_data and dividend_data.get('dividend_per_share', 0) > 0:
                dividend_per_share = dividend_data['dividend_per_share']
                total_dividend = dividend_per_share * total_shares
                
                # Use dates from API or fallback to recent dates
                ex_date = dividend_data.get('ex_dividend_date')
                pay_date = dividend_data.get('payment_date')
                
                if not ex_date:
                    from datetime import date, timedelta
                    ex_date = date.today() - timedelta(days=30)
                    pay_date = date.today() - timedelta(days=15)
                
                # Insert dividend record using asset's currency
                execute_update(
                    DATABASE_URL,
                    """
                    INSERT INTO dividends (
                        asset_id, user_id, ticker_symbol, ex_dividend_date, payment_date,
                        dividend_per_share, total_dividend_amount, currency, dividend_type, tax_rate
                    ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                    """,
                    (asset_id, user_id, ticker, ex_date, pay_date,
                     dividend_per_share, total_dividend, 
                     asset['currency'],  # Always use asset's currency
                     dividend_data.get('dividend_type', 'regular'),
                     20.0)  # Default tax rate for auto-detected dividends
                )
                
                detected_count += 1
                source = dividend_data.get('source', 'unknown')
                logger.info(f"âœ… Created dividend record for {ticker}: ${dividend_per_share}/share (${total_dividend:.2f} total) from {source}")
            else:
                logger.info(f"âšª No dividend data found for {ticker}")
        
        # Prepare response message
        if detected_count > 0:
            message = f"Successfully detected {detected_count} dividend payment(s)"
            if skipped_count > 0:
                message += f" (skipped {skipped_count} assets with recent dividends)"
            if api_errors:
                message += f". Note: {len(api_errors)} API errors occurred but fallback data was used where available."
        else:
            if skipped_count > 0:
                message = f"No new dividends detected. {skipped_count} assets already have recent dividend records."
            else:
                message = "No dividend-paying assets found in your portfolio."
        
        logger.info(f"ðŸŽ‰ Dividend auto-detection completed: {detected_count} detected, {skipped_count} skipped")
        
        return create_response(200, {
            "detected": detected_count,
            "skipped": skipped_count,
            "message": message,
            "api_errors": len(api_errors) if api_errors else 0
        })
        
    except Exception as e:
        logger.error(f"Auto-detect dividends error: {str(e)}")
        return create_error_response(500, f"Failed to auto-detect dividends: {str(e)}")

def handle_create_recurring_investment(body, user_id):
    """Create a new recurring investment plan"""
    try:
        # Ensure table exists
        create_recurring_investments_table()
        
        # Validate required fields
        required_fields = ['ticker_symbol', 'amount', 'frequency', 'start_date']
        for field in required_fields:
            if field not in body:
                return create_error_response(400, f"Missing required field: {field}")
        
        ticker_symbol = body['ticker_symbol'].upper()
        amount = float(body['amount'])
        currency = body.get('currency', 'USD').upper()
        frequency = body['frequency'].lower()
        start_date = body['start_date']
        
        # Validate frequency
        valid_frequencies = ['daily', 'weekly', 'monthly', 'quarterly']
        if frequency not in valid_frequencies:
            return create_error_response(400, f"Invalid frequency. Must be one of: {', '.join(valid_frequencies)}")
        
        # Calculate next run date based on frequency
        from datetime import datetime, timedelta
        start_dt = datetime.strptime(start_date, '%Y-%m-%d').date()
        
        if frequency == 'daily':
            next_run_date = start_dt + timedelta(days=1)
        elif frequency == 'weekly':
            next_run_date = start_dt + timedelta(weeks=1)
        elif frequency == 'monthly':
            next_run_date = start_dt + relativedelta(months=1)  # Approximate
        elif frequency == 'quarterly':
            next_run_date = start_dt + relativedelta(months=3)  # Approximate
        
        # Create recurring investment
        execute_update(
            DATABASE_URL,
            """
            INSERT INTO recurring_investments 
            (user_id, ticker_symbol, amount, currency, frequency, start_date, next_run_date)
            VALUES (%s, %s, %s, %s, %s, %s, %s)
            """,
            (user_id, ticker_symbol, amount, currency, frequency, start_date, next_run_date)
        )
        
        # Get the created recurring investment
        recurring_investment = execute_query(
            DATABASE_URL,
            """
            SELECT * FROM recurring_investments 
            WHERE user_id = %s AND ticker_symbol = %s AND start_date = %s
            ORDER BY created_at DESC LIMIT 1
            """,
            (user_id, ticker_symbol, start_date)
        )[0]
        
        return create_response(201, {
            "message": "Recurring investment plan created successfully",
            "recurring_investment": {
                "recurring_id": recurring_investment['recurring_id'],
                "ticker_symbol": recurring_investment['ticker_symbol'],
                "amount": float(recurring_investment['amount']),
                "currency": recurring_investment['currency'],
                "frequency": recurring_investment['frequency'],
                "start_date": str(recurring_investment['start_date']),
                "next_run_date": str(recurring_investment['next_run_date']),
                "is_active": recurring_investment['is_active'],
                "created_at": recurring_investment['created_at'].isoformat()
            }
        })
        
    except Exception as e:
        logger.error(f"Create recurring investment error: {str(e)}")
        return create_error_response(500, "Failed to create recurring investment plan")

def handle_get_recurring_investments(user_id):
    """Get all recurring investment plans for a user"""
    try:
        # Ensure table exists
        create_recurring_investments_table()
        
        recurring_investments = execute_query(
            DATABASE_URL,
            """
            SELECT * FROM recurring_investments 
            WHERE user_id = %s 
            ORDER BY created_at DESC
            """,
            (user_id,)
        )
        
        investment_list = []
        for investment in recurring_investments:
            investment_list.append({
                "recurring_id": investment['recurring_id'],
                "ticker_symbol": investment['ticker_symbol'],
                "amount": float(investment['amount']),
                "currency": investment['currency'],
                "frequency": investment['frequency'],
                "start_date": str(investment['start_date']),
                "next_run_date": str(investment['next_run_date']),
                "is_active": investment['is_active'],
                "created_at": investment['created_at'].isoformat(),
                "updated_at": investment['updated_at'].isoformat()
            })
        
        return create_response(200, {
            "recurring_investments": investment_list,
            "total_plans": len(investment_list)
        })
        
    except Exception as e:
        logger.error(f"Get recurring investments error: {str(e)}")
        return create_error_response(500, "Failed to retrieve recurring investment plans")

def handle_update_recurring_investment(recurring_id, body, user_id):
    """Update a recurring investment plan"""
    try:
        # Verify recurring investment belongs to user
        investment = execute_query(
            DATABASE_URL,
            "SELECT * FROM recurring_investments WHERE recurring_id = %s AND user_id = %s",
            (recurring_id, user_id)
        )
        
        if not investment:
            return create_error_response(404, "Recurring investment plan not found")
        
        investment = investment[0]
        
        # Update fields
        amount = body.get('amount', investment['amount'])
        frequency = body.get('frequency', investment['frequency']).lower()
        is_active = body.get('is_active', investment['is_active'])
        start_date = body.get('start_date', investment['start_date'])
        next_run_date = body.get('next_run_date', investment['next_run_date'])
        
        # Validate frequency if provided
        if 'frequency' in body:
            valid_frequencies = ['daily', 'weekly', 'monthly', 'quarterly']
            if frequency not in valid_frequencies:
                return create_error_response(400, f"Invalid frequency. Must be one of: {', '.join(valid_frequencies)}")
        
        # Parse dates if provided
        if 'start_date' in body:
            try:
                from datetime import datetime
                start_date = datetime.strptime(start_date, '%Y-%m-%d').date()
            except ValueError:
                return create_error_response(400, "Invalid start_date format. Use YYYY-MM-DD")
        
        if 'next_run_date' in body:
            try:
                from datetime import datetime
                next_run_date = datetime.strptime(next_run_date, '%Y-%m-%d').date()
            except ValueError:
                return create_error_response(400, "Invalid next_run_date format. Use YYYY-MM-DD")
        
        # Update the recurring investment
        execute_update(
            DATABASE_URL,
            """
            UPDATE recurring_investments 
            SET amount = %s, frequency = %s, is_active = %s, start_date = %s, next_run_date = %s, updated_at = CURRENT_TIMESTAMP
            WHERE recurring_id = %s AND user_id = %s
            """,
            (amount, frequency, is_active, start_date, next_run_date, recurring_id, user_id)
        )
        
        # Get updated investment
        updated_investment = execute_query(
            DATABASE_URL,
            "SELECT * FROM recurring_investments WHERE recurring_id = %s AND user_id = %s",
            (recurring_id, user_id)
        )[0]
        
        return create_response(200, {
            "message": "Recurring investment plan updated successfully",
            "recurring_investment": {
                "recurring_id": updated_investment['recurring_id'],
                "ticker_symbol": updated_investment['ticker_symbol'],
                "amount": float(updated_investment['amount']),
                "currency": updated_investment['currency'],
                "frequency": updated_investment['frequency'],
                "start_date": str(updated_investment['start_date']),
                "next_run_date": str(updated_investment['next_run_date']),
                "is_active": updated_investment['is_active'],
                "updated_at": updated_investment['updated_at'].isoformat()
            }
        })
        
    except Exception as e:
        logger.error(f"Update recurring investment error: {str(e)}")
        return create_error_response(500, "Failed to update recurring investment plan")

def handle_delete_recurring_investment(recurring_id, user_id):
    """Delete a recurring investment plan"""
    try:
        # Verify recurring investment belongs to user
        investment = execute_query(
            DATABASE_URL,
            "SELECT * FROM recurring_investments WHERE recurring_id = %s AND user_id = %s",
            (recurring_id, user_id)
        )
        
        if not investment:
            return create_error_response(404, "Recurring investment plan not found")
        
        # Delete the recurring investment
        execute_update(
            DATABASE_URL,
            "DELETE FROM recurring_investments WHERE recurring_id = %s AND user_id = %s",
            (recurring_id, user_id)
        )
        
        return create_response(200, {
            "message": f"Recurring investment plan for {investment[0]['ticker_symbol']} deleted successfully"
        })
        
    except Exception as e:
        logger.error(f"Delete recurring investment error: {str(e)}")
        return create_error_response(500, "Failed to delete recurring investment plan")

def handle_batch_processing():
    """Handle recurring investments batch processing with multi-market support"""
    from datetime import datetime, timedelta, date
    from decimal import Decimal, ROUND_HALF_UP
    import time
    import pytz
    
    logger.info("ðŸš€ Starting recurring investments batch processing")
    
    # Market holidays for 2025
    US_MARKET_HOLIDAYS_2025 = [
        date(2025, 1, 1),   # New Year's Day
        date(2025, 1, 20),  # Martin Luther King Jr. Day
        date(2025, 2, 17),  # Presidents' Day
        date(2025, 4, 18),  # Good Friday
        date(2025, 5, 26),  # Memorial Day
        date(2025, 6, 19),  # Juneteenth
        date(2025, 7, 4),   # Independence Day
        date(2025, 9, 1),   # Labor Day
        date(2025, 11, 27), # Thanksgiving
        date(2025, 12, 25), # Christmas
    ]
    
    # Taiwan market holidays for 2025 (TSE - Taiwan Stock Exchange)
    TW_MARKET_HOLIDAYS_2025 = [
        date(2025, 1, 1),   # New Year's Day
        date(2025, 1, 27),  # Chinese New Year Eve
        date(2025, 1, 28),  # Chinese New Year
        date(2025, 1, 29),  # Chinese New Year
        date(2025, 1, 30),  # Chinese New Year
        date(2025, 1, 31),  # Chinese New Year
        date(2025, 2, 28),  # Peace Memorial Day
        date(2025, 4, 4),   # Children's Day
        date(2025, 4, 5),   # Tomb Sweeping Day
        date(2025, 5, 1),   # Labor Day
        date(2025, 6, 10),  # Dragon Boat Festival
        date(2025, 9, 17),  # Mid-Autumn Festival
        date(2025, 10, 10), # National Day
    ]
    
    def get_market_type_from_ticker(ticker_symbol):
        """Determine market type from ticker symbol"""
        ticker = ticker_symbol.upper()
        
        # Taiwan stocks typically have .TW suffix or are 4-digit numbers
        if ticker.endswith('.TW') or ticker.endswith('.TWO') or (ticker.isdigit() and len(ticker) == 4):
            return 'TW'
        
        # Default to US market for other tickers
        return 'US'
    
    def is_market_open_today(market_type='US'):
        """Check if the specified market is open today"""
        # Get current time in market timezone
        if market_type == 'TW':
            tz = pytz.timezone('Asia/Taipei')
            holidays = TW_MARKET_HOLIDAYS_2025
            market_name = "Taiwan"
        else:
            tz = pytz.timezone('US/Eastern')
            holidays = US_MARKET_HOLIDAYS_2025
            market_name = "US"
        
        # Get today's date in market timezone
        now = datetime.now(tz)
        today = now.date()
        
        # Check if it's a weekend
        if today.weekday() >= 5:  # Saturday = 5, Sunday = 6
            logger.info(f"{market_name} market closed: Weekend ({today})")
            return False
        
        # Check if it's a holiday
        if today in holidays:
            logger.info(f"{market_name} market closed: Holiday ({today})")
            return False
        
        # Check market hours
        current_time = now.time()
        if market_type == 'TW':
            # Taiwan market: 9:00 AM - 1:30 PM Taiwan time
            market_open = datetime.strptime('09:00', '%H:%M').time()
            market_close = datetime.strptime('13:30', '%H:%M').time()
        else:
            # US market: 9:30 AM - 4:00 PM Eastern time
            market_open = datetime.strptime('09:30', '%H:%M').time()
            market_close = datetime.strptime('16:00', '%H:%M').time()
        
        if current_time < market_open or current_time > market_close:
            logger.info(f"{market_name} market closed: Outside trading hours ({current_time})")
            return False
        
        logger.info(f"{market_name} market is open ({today} {current_time})")
        return True
    
    def calculate_next_run_date(current_date, frequency):
        """Calculate next run date based on frequency"""
        if frequency == 'daily':
            return current_date + timedelta(days=1)
        elif frequency == 'weekly':
            return current_date + timedelta(weeks=1)
        elif frequency == 'monthly':
            # Add one month (handle month-end dates properly)
            if current_date.month == 12:
                return current_date.replace(year=current_date.year + 1, month=1)
            else:
                try:
                    return current_date.replace(month=current_date.month + 1)
                except ValueError:
                    # Handle cases like Jan 31 -> Feb 28/29
                    next_month = current_date.replace(month=current_date.month + 1, day=1)
                    return next_month.replace(day=min(current_date.day, 28))
        elif frequency == 'quarterly':
            return current_date + timedelta(days=90)  # Approximate
        else:
            return current_date + timedelta(days=30)  # Default to monthly
    
    # Initialize counters
    processed_count = 0
    failed_count = 0
    skipped_count = 0
    
    try:
        # Get investments due for processing
        today = date.today()
        
        investments = execute_query(
            DATABASE_URL,
            """
            SELECT ri.*, u.base_currency, u.email, u.name
            FROM recurring_investments ri
            JOIN users u ON ri.user_id = u.user_id
            WHERE ri.is_active = true 
            AND ri.next_run_date <= %s
            ORDER BY ri.next_run_date ASC
            """,
            (today,)
        )
        
        logger.info(f"ðŸ“‹ Found {len(investments)} recurring investments due for execution")
        
        if not investments:
            logger.info("ðŸ“­ No recurring investments due for execution today")
            return create_response(200, {
                'status': 'success',
                'reason': 'no_investments_due',
                'processed': 0,
                'failed': 0,
                'skipped': 0
            })
        
        # Group investments by market type
        us_investments = []
        tw_investments = []
        
        for investment in investments:
            ticker_symbol = investment['ticker_symbol']
            market_type = get_market_type_from_ticker(ticker_symbol)
            
            if market_type == 'TW':
                tw_investments.append(investment)
            else:
                us_investments.append(investment)
        
        logger.info(f"ðŸ“Š Market breakdown: {len(us_investments)} US investments, {len(tw_investments)} Taiwan investments")
        
        # Check market status for each market type
        us_market_open = is_market_open_today('US') if us_investments else True
        tw_market_open = is_market_open_today('TW') if tw_investments else True
        
        # Filter investments based on market status
        processable_investments = []
        
        if us_market_open:
            processable_investments.extend(us_investments)
            logger.info(f"ðŸ‡ºðŸ‡¸ US market is open - processing {len(us_investments)} investments")
        else:
            logger.info(f"ðŸ‡ºðŸ‡¸ US market is closed - skipping {len(us_investments)} investments")
            skipped_count += len(us_investments)
        
        if tw_market_open:
            processable_investments.extend(tw_investments)
            logger.info(f"ðŸ‡¹ðŸ‡¼ Taiwan market is open - processing {len(tw_investments)} investments")
        else:
            logger.info(f"ðŸ‡¹ðŸ‡¼ Taiwan market is closed - skipping {len(tw_investments)} investments")
            skipped_count += len(tw_investments)
        
        if not processable_investments:
            logger.info("ðŸ“´ All relevant markets are closed today, skipping batch processing")
            return create_response(200, {
                'status': 'skipped',
                'reason': 'all_markets_closed',
                'processed': 0,
                'failed': 0,
                'skipped': len(investments)
            })
        
        # Process each investment
        for investment in processable_investments:
            try:
                ticker_symbol = investment['ticker_symbol']
                amount = float(investment['amount'])
                currency = investment['currency']
                user_id = investment['user_id']
                market_type = get_market_type_from_ticker(ticker_symbol)
                
                logger.info(f"ðŸ”„ Processing {ticker_symbol} ({market_type} market) for user {investment['email']} - ${amount} {currency}")
                
                # Get current stock price using existing function
                stock_price_data = fetch_stock_price_with_fallback(ticker_symbol)
                if not stock_price_data:
                    raise Exception(f"Could not get stock price for {ticker_symbol}")
                
                stock_price = stock_price_data.get('price', 0)
                if stock_price <= 0:
                    raise Exception(f"Invalid stock price for {ticker_symbol}: {stock_price}")
                
                # Determine stock currency based on market
                stock_currency = stock_price_data.get('currency', 'USD')
                if market_type == 'TW':
                    stock_currency = 'TWD'
                elif market_type == 'US':
                    stock_currency = 'USD'
                
                # For now, use simple currency logic to avoid timeouts
                if currency == stock_currency:
                    # Same currency - use amount directly (most common case)
                    amount_in_stock_currency = amount
                    logger.info(f"ðŸ’° Same currency ({currency}): using {amount} directly")
                else:
                    # Different currency - for now, assume 1:1 to avoid timeout issues
                    # TODO: Implement proper currency conversion later
                    amount_in_stock_currency = amount
                    logger.warning(f"âš ï¸ Currency conversion needed but skipped: {currency} â†’ {stock_currency}")
                
                # Calculate shares to purchase
                shares = Decimal(str(amount_in_stock_currency / stock_price)).quantize(
                    Decimal('0.000001'), rounding=ROUND_HALF_UP
                )
                
                if shares <= 0:
                    raise Exception(f"Calculated shares ({shares}) is not positive")
                
                # Check if asset exists for this user
                existing_asset = execute_query(
                    DATABASE_URL,
                    "SELECT asset_id FROM assets WHERE user_id = %s AND ticker_symbol = %s",
                    (user_id, ticker_symbol)
                )
                
                if not existing_asset:
                    # Create new asset
                    execute_update(
                        DATABASE_URL,
                        """
                        INSERT INTO assets (user_id, ticker_symbol, asset_type, total_shares, average_cost_basis, currency)
                        VALUES (%s, %s, 'Stock', %s, %s, %s)
                        """,
                        (user_id, ticker_symbol, float(shares), stock_price, stock_currency)
                    )
                    
                    # Get the created asset
                    asset = execute_query(
                        DATABASE_URL,
                        "SELECT asset_id FROM assets WHERE user_id = %s AND ticker_symbol = %s",
                        (user_id, ticker_symbol)
                    )[0]
                    asset_id = asset['asset_id']
                    
                    logger.info(f"âœ… Created new asset {ticker_symbol} for user")
                else:
                    asset_id = existing_asset[0]['asset_id']
                    
                    # Update existing asset (recalculate average cost basis)
                    current_asset = execute_query(
                        DATABASE_URL,
                        "SELECT total_shares, average_cost_basis FROM assets WHERE asset_id = %s",
                        (asset_id,)
                    )[0]
                    
                    current_shares = float(current_asset['total_shares'])
                    current_avg_cost = float(current_asset['average_cost_basis'])
                    
                    new_total_shares = current_shares + float(shares)
                    total_cost = (current_shares * current_avg_cost) + (float(shares) * stock_price)
                    new_avg_cost = total_cost / new_total_shares
                    
                    execute_update(
                        DATABASE_URL,
                        """
                        UPDATE assets 
                        SET total_shares = %s, average_cost_basis = %s, updated_at = CURRENT_TIMESTAMP
                        WHERE asset_id = %s
                        """,
                        (new_total_shares, new_avg_cost, asset_id)
                    )
                    
                    logger.info(f"âœ… Updated asset {ticker_symbol}: {current_shares} + {shares} = {new_total_shares} shares")
                
                # Create transaction record
                execute_update(
                    DATABASE_URL,
                    """
                    INSERT INTO transactions (asset_id, transaction_type, transaction_date, shares, price_per_share, currency)
                    VALUES (%s, 'Recurring', CURRENT_DATE, %s, %s, %s)
                    """,
                    (asset_id, float(shares), stock_price, stock_currency)
                )
                
                # Update next run date
                next_run_date = calculate_next_run_date(date.today(), investment['frequency'])
                
                # Skip weekends and holidays for next run date
                while not is_market_open_today():
                    next_run_date = next_run_date + timedelta(days=1)
                
                execute_update(
                    DATABASE_URL,
                    """
                    UPDATE recurring_investments 
                    SET next_run_date = %s, updated_at = CURRENT_TIMESTAMP
                    WHERE recurring_id = %s
                    """,
                    (next_run_date, investment['recurring_id'])
                )
                
                logger.info(f"âœ… Successfully processed {ticker_symbol}: {shares} shares @ ${stock_price}")
                logger.info(f"ðŸ“… Next run date: {next_run_date}")
                
                processed_count += 1
                
                # Add small delay between API calls
                time.sleep(1)
                
            except Exception as e:
                logger.error(f"âŒ Failed to process investment {investment['ticker_symbol']}: {str(e)}")
                failed_count += 1
                continue
        
        # Final summary
        logger.info(f"ðŸŽ¯ Batch processing completed:")
        logger.info(f"   âœ… Processed: {processed_count}")
        logger.info(f"   âŒ Failed: {failed_count}")
        logger.info(f"   â­ï¸ Skipped: {skipped_count}")
        
        return create_response(200, {
            'status': 'success',
            'processed': processed_count,
            'failed': failed_count,
            'skipped': skipped_count,
            'total_investments': len(investments)
        })
        
    except Exception as e:
        logger.error(f"âŒ Batch processing failed: {str(e)}")
        return create_error_response(500, f"Batch processing failed: {str(e)}")

# ============================================================================
# MILESTONE 2 & 5: FIRE PROFILE MANAGEMENT FUNCTIONS
# ============================================================================

def handle_create_or_update_fire_profile(body, user_id):
    """Create or update FIRE profile for a user with comprehensive fields"""
    try:
        # Ensure table exists
        create_fire_profile_table()
        
        # Extract comprehensive fields
        # Current Financial Snapshot
        annual_income = body.get('annual_income', 1000000)
        # annual_savings removed - now calculated from recurring investments
        
        # Retirement Goals
        annual_expenses = body.get('annual_expenses')
        target_retirement_age = body.get('target_retirement_age')
        
        # Core Assumptions
        safe_withdrawal_rate = body.get('safe_withdrawal_rate', 0.04)
        expected_return_pre_retirement = body.get('expected_return_pre_retirement', 0.07)
        expected_return_post_retirement = body.get('expected_return_post_retirement', 0.05)
        expected_inflation_rate = body.get('expected_inflation_rate', 0.025)
        other_passive_income = body.get('other_passive_income', 0)
        effective_tax_rate = body.get('effective_tax_rate', 0.15)
        
        # Enhanced: New fields for sophisticated calculation
        barista_monthly_contribution = body.get('barista_monthly_contribution', 0)  # Monthly contribution for Barista FIRE
        inflation_rate = body.get('inflation_rate', 0.025)  # User-specific inflation assumption
        
        # Legacy fields for backward compatibility
        expected_annual_return = body.get('expected_annual_return', expected_return_pre_retirement)
        
        # Check if profile already exists
        existing_profile = execute_query(
            DATABASE_URL,
            "SELECT * FROM fire_profile WHERE user_id = %s",
            (user_id,)
        )
        
        if existing_profile:
            # Update existing profile with all comprehensive fields including new ones
            execute_update(
                DATABASE_URL,
                """
                UPDATE fire_profile 
                SET annual_income = %s, annual_expenses = %s, 
                    target_retirement_age = %s, safe_withdrawal_rate = %s,
                    expected_return_pre_retirement = %s, expected_return_post_retirement = %s,
                    expected_inflation_rate = %s, other_passive_income = %s, effective_tax_rate = %s,
                    barista_monthly_contribution = %s, inflation_rate = %s,
                    expected_annual_return = %s, 
                    updated_at = CURRENT_TIMESTAMP
                WHERE user_id = %s
                """,
                (annual_income, annual_expenses, target_retirement_age, 
                 safe_withdrawal_rate, expected_return_pre_retirement, expected_return_post_retirement,
                 expected_inflation_rate, other_passive_income, effective_tax_rate,
                 barista_monthly_contribution, inflation_rate,
                 expected_annual_return, user_id)
            )
            message = "FIRE profile updated successfully"
        else:
            # Create new profile with all comprehensive fields including new ones
            execute_update(
                DATABASE_URL,
                """
                INSERT INTO fire_profile 
                (user_id, annual_income, annual_expenses, target_retirement_age,
                 safe_withdrawal_rate, expected_return_pre_retirement, expected_return_post_retirement,
                 expected_inflation_rate, other_passive_income, effective_tax_rate,
                 barista_monthly_contribution, inflation_rate,
                 expected_annual_return)
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                """,
                (user_id, annual_income, annual_expenses, target_retirement_age,
                 safe_withdrawal_rate, expected_return_pre_retirement, expected_return_post_retirement,
                 expected_inflation_rate, other_passive_income, effective_tax_rate,
                 barista_monthly_contribution, inflation_rate,
                 expected_annual_return)
            )
            message = "FIRE profile created successfully"
        
        # Get the profile
        profile = execute_query(
            DATABASE_URL,
            "SELECT * FROM fire_profile WHERE user_id = %s",
            (user_id,)
        )[0]
        
        return create_response(200, {
            "message": message,
            "fire_profile": {
                "profile_id": profile['profile_id'],
                "user_id": profile['user_id'],
                "annual_expenses": float(profile['annual_expenses']) if profile['annual_expenses'] else None,
                "safe_withdrawal_rate": float(profile['safe_withdrawal_rate']),
                "expected_annual_return": float(profile['expected_annual_return']),
                "target_retirement_age": profile['target_retirement_age'],
                "barista_monthly_contribution": float(profile.get('barista_monthly_contribution', 0)),
                "created_at": profile['created_at'].isoformat(),
                "updated_at": profile['updated_at'].isoformat()
            }
        })
        
    except Exception as e:
        logger.error(f"Create/update FIRE profile error: {str(e)}")
        return create_error_response(500, "Failed to save FIRE profile")

def handle_get_fire_profile(user_id):
    """Get FIRE profile for a user with all comprehensive fields"""
    try:
        # Ensure table exists
        create_fire_profile_table()
        
        profile = execute_query(
            DATABASE_URL,
            "SELECT * FROM fire_profile WHERE user_id = %s",
            (user_id,)
        )
        
        if not profile:
            return create_response(200, {
                "fire_profile": None,
                "message": "No FIRE profile found. Create one to start tracking your FIRE progress."
            })
        
        profile = profile[0]
        
        return create_response(200, {
            "fire_profile": {
                "profile_id": profile['profile_id'],
                "user_id": profile['user_id'],
                
                # Current Financial Snapshot
                "annual_income": float(profile.get('annual_income', 1000000)),
                # annual_savings removed - now calculated from recurring investments
                
                # Retirement Goals
                "annual_expenses": float(profile['annual_expenses']) if profile['annual_expenses'] else None,
                "target_retirement_age": profile['target_retirement_age'],
                
                # Core Assumptions
                "safe_withdrawal_rate": float(profile['safe_withdrawal_rate']),
                "expected_return_pre_retirement": float(profile.get('expected_return_pre_retirement', profile['expected_annual_return'])),
                "expected_return_post_retirement": float(profile.get('expected_return_post_retirement', profile['expected_annual_return'])),
                "expected_inflation_rate": float(profile.get('expected_inflation_rate', 0.025)),
                "other_passive_income": float(profile.get('other_passive_income', 0)),
                "effective_tax_rate": float(profile.get('effective_tax_rate', 0.15)),
                
                # Barista FIRE fields
                "barista_monthly_contribution": float(profile.get('barista_monthly_contribution', 0)),
                "inflation_rate": float(profile.get('inflation_rate', profile.get('expected_inflation_rate', 0.025))),
                
                # Legacy fields for backward compatibility
                "expected_annual_return": float(profile['expected_annual_return']),
                
                "created_at": profile['created_at'].isoformat(),
                "updated_at": profile['updated_at'].isoformat()
            }
        })
        
    except Exception as e:
        logger.error(f"Get FIRE profile error: {str(e)}")
        return create_error_response(500, "Failed to retrieve FIRE profile")

def convert_currency_amount(amount, from_currency, to_currency):
    """Convert an amount from one currency to another using exchange rates"""
    if from_currency == to_currency:
        return amount
    
    try:
        # Try to get cached rates first
        cached_rates = get_cached_exchange_rate(to_currency, 'ALL')
        if cached_rates and 'rates' in cached_rates and from_currency in cached_rates['rates']:
            # This gives us the rate from to_currency to from_currency
            to_to_from_rate = float(cached_rates['rates'][from_currency])
            
            if to_to_from_rate > 0 and to_to_from_rate < 1000:
                # To convert from_currency to to_currency, we need the inverse
                converted_amount = amount / to_to_from_rate
                logger.info(f"ðŸ’± Converted {amount:.2f} {from_currency} â†’ {converted_amount:.2f} {to_currency} (rate: 1/{to_to_from_rate:.6f})")
                return converted_amount
        
        # If not cached, fetch fresh rates
        logger.info(f"ðŸŒ Fetching fresh exchange rates for {to_currency}")
        url = f"{EXCHANGE_RATE_BASE_URL}/{to_currency}"
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        data = response.json()
        
        if 'rates' in data and from_currency in data['rates']:
            exchange_rate = float(data['rates'][from_currency])
            
            if exchange_rate > 0 and exchange_rate < 1000:
                converted_amount = amount / exchange_rate
                logger.info(f"ðŸ’± API Converted {amount:.2f} {from_currency} â†’ {converted_amount:.2f} {to_currency} (rate: 1/{exchange_rate:.6f})")
                
                # Cache the result
                result = {
                    "success": True,
                    "base": data.get('base', to_currency),
                    "rates": data['rates'],
                    "last_updated": data.get('date', datetime.utcnow().isoformat()),
                    "source": "ExchangeRate-API",
                    "cached": False
                }
                set_cached_exchange_rate(to_currency, 'ALL', result)
                
                return converted_amount
        
        # Try the reverse direction as fallback
        logger.info(f"ðŸŒ Trying reverse direction: {from_currency} to ALL")
        url = f"{EXCHANGE_RATE_BASE_URL}/{from_currency}"
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        data = response.json()
        
        if 'rates' in data and to_currency in data['rates']:
            exchange_rate = float(data['rates'][to_currency])
            
            if exchange_rate > 0 and exchange_rate < 1000:
                converted_amount = amount * exchange_rate
                logger.info(f"ðŸ’± Reverse API Converted {amount:.2f} {from_currency} â†’ {converted_amount:.2f} {to_currency} (rate: {exchange_rate:.6f})")
                
                # Cache the result
                result = {
                    "success": True,
                    "base": data.get('base', from_currency),
                    "rates": data['rates'],
                    "last_updated": data.get('date', datetime.utcnow().isoformat()),
                    "source": "ExchangeRate-API",
                    "cached": False
                }
                set_cached_exchange_rate(from_currency, 'ALL', result)
                
                return converted_amount
        
        raise Exception(f"No exchange rate found for {from_currency} to {to_currency}")
        
    except Exception as e:
        logger.error(f"âŒ Currency conversion failed for {from_currency} to {to_currency}: {str(e)}")
        raise e

def get_historical_stock_price(ticker, target_date, fallback_current_price=None):
    """
    Get historical stock price for a specific date with multiple fallback strategies
    
    Strategy 1: Try Alpha Vantage historical data API
    Strategy 2: Use realistic price estimation based on current price
    Strategy 3: Use provided fallback price
    """
    try:
        from datetime import datetime, date, timedelta
        import random
        
        # Convert target_date to string format if needed
        if isinstance(target_date, date):
            date_str = target_date.strftime('%Y-%m-%d')
        else:
            date_str = str(target_date)
        
        logger.info(f"ðŸ” Fetching historical price for {ticker} on {date_str}")
        
        # Strategy 1: Try Alpha Vantage historical data (if we have sufficient API quota)
        try:
            import requests
            
            # Alpha Vantage historical data endpoint
            url = "https://www.alphavantage.co/query"
            params = {
                'function': 'TIME_SERIES_DAILY',
                'symbol': ticker,
                'apikey': ALPHA_VANTAGE_API_KEY,
                'outputsize': 'compact'
            }
            
            response = requests.get(url, params=params, timeout=10)
            data = response.json()
            
            if 'Time Series (Daily)' in data:
                time_series = data['Time Series (Daily)']
                
                # Try exact date first
                if date_str in time_series:
                    historical_price = float(time_series[date_str]['4. close'])
                    logger.info(f"ðŸ“ˆ {ticker}: Found exact historical price ${historical_price:.2f} for {date_str}")
                    return historical_price
                
                # Try nearby dates (within 3 days) for weekends/holidays
                target_dt = datetime.strptime(date_str, '%Y-%m-%d').date()
                for days_offset in range(1, 4):
                    # Try earlier dates
                    earlier_date = (target_dt - timedelta(days=days_offset)).strftime('%Y-%m-%d')
                    if earlier_date in time_series:
                        historical_price = float(time_series[earlier_date]['4. close'])
                        logger.info(f"ðŸ“ˆ {ticker}: Found nearby historical price ${historical_price:.2f} for {earlier_date} (target: {date_str})")
                        return historical_price
                
                logger.warning(f"âš ï¸ No historical data found for {ticker} around {date_str}")
            
            elif 'Note' in data:
                logger.warning(f"âš ï¸ Alpha Vantage API limit reached for {ticker}")
            elif 'Error Message' in data:
                logger.warning(f"âš ï¸ Alpha Vantage error for {ticker}: {data['Error Message']}")
            
        except Exception as e:
            logger.warning(f"âš ï¸ Alpha Vantage historical data failed for {ticker}: {str(e)}")
        
        # Strategy 2: Use realistic price estimation based on current price
        if fallback_current_price:
            # For 7-day period, typical stock volatility is 1-3% per day
            # Generate a realistic price variation (-5% to +5% for 7 days)
            variation_percent = random.uniform(-0.05, 0.05)  # -5% to +5%
            estimated_price = fallback_current_price * (1 + variation_percent)
            
            logger.info(f"ðŸ“Š {ticker}: Estimated historical price ${estimated_price:.2f} ({variation_percent*100:+.1f}% from current ${fallback_current_price:.2f})")
            return estimated_price
        
        # Strategy 3: Fallback to current price if no other option
        logger.warning(f"âš ï¸ Using current price as historical approximation for {ticker}")
        return fallback_current_price
        
    except Exception as e:
        logger.error(f"âŒ Historical price lookup failed for {ticker}: {str(e)}")
        return fallback_current_price

def calculate_7day_twr_performance(user_id):
    """
    Calculate 7-day Time-Weighted Return (TWR) portfolio performance
    
    Step 1: Find portfolio value 7 days ago (start date)
    Step 2: Identify cash flows in the past 7 days
    Step 3: Calculate TWR based on cash flows
    
    Scenario A: No cash flows - Simple calculation: (MV_end / MV_start) - 1
    Scenario B: With cash flows - TWR calculation with sub-periods
    """
    try:
        from datetime import datetime, date, timedelta
        
        logger.info(f"ðŸ“Š Calculating 7-day TWR performance for user {user_id}")
        
        # Get user's base currency
        user = execute_query(
            DATABASE_URL,
            "SELECT base_currency FROM users WHERE user_id = %s",
            (user_id,)
        )[0]
        base_currency = user['base_currency']
        logger.info(f"ðŸ’° User base currency: {base_currency}")
        
        # Step 1: Define the 7-day period
        end_date = date.today()
        start_date = end_date - timedelta(days=7)
        
        logger.info(f"ðŸ“… 7-day period: {start_date} to {end_date}")
        
        # Check if user has any transactions
        first_transaction = execute_query(
            DATABASE_URL,
            """
            SELECT MIN(t.transaction_date) as first_date
            FROM transactions t
            JOIN assets a ON t.asset_id = a.asset_id
            WHERE a.user_id = %s AND t.transaction_type != 'Dividend'
            """,
            (user_id,)
        )
        
        if not first_transaction or not first_transaction[0]['first_date']:
            logger.info("No transactions found for 7-day TWR calculation")
            return {
                'seven_day_return': 0,
                'annualized_return': 0,
                'start_value': 0,
                'end_value': 0,
                'cash_flows': [],
                'calculation_method': 'no_transactions',
                'period_days': 7,
                'start_date': start_date.isoformat(),
                'end_date': end_date.isoformat(),
                'base_currency': base_currency,
                'error_message': 'No investment history found'
            }
        
        # Get the actual first transaction date
        first_date = first_transaction[0]['first_date']
        if isinstance(first_date, str):
            first_date = datetime.strptime(first_date, '%Y-%m-%d').date()
        elif hasattr(first_date, 'date'):
            first_date = first_date.date()
        
        # Adjust start date if first transaction is more recent than 7 days ago
        actual_start_date = max(start_date, first_date)
        actual_period_days = (end_date - actual_start_date).days
        
        if actual_start_date > start_date:
            logger.info(f"ðŸ“… Adjusting start date from {start_date} to {actual_start_date} (first transaction date)")
            logger.info(f"ðŸ“Š Calculating {actual_period_days}-day performance instead of 7-day")
        
        # Get current portfolio holdings (EXCLUDE cash assets from performance calculation)
        current_assets = execute_query(
            DATABASE_URL,
            """
            SELECT ticker_symbol, total_shares, currency, asset_type
            FROM assets 
            WHERE user_id = %s 
            AND total_shares > 0 
            AND asset_type != 'Cash'
            AND ticker_symbol NOT IN ('CASH', 'FIXED DEPOSITE', 'FLEXIBLE')
            """,
            (user_id,)
        )
        
        # Debug: Also get ALL assets to see what's being filtered
        all_assets = execute_query(
            DATABASE_URL,
            """
            SELECT ticker_symbol, total_shares, currency, asset_type
            FROM assets 
            WHERE user_id = %s 
            AND total_shares > 0
            """,
            (user_id,)
        )
        
        logger.info(f"ðŸ” DEBUG: User {user_id} has {len(all_assets)} total assets, {len(current_assets)} investment assets")
        for asset in all_assets:
            logger.info(f"ðŸ” DEBUG: Asset {asset['ticker_symbol']} ({asset['asset_type']}) - {asset['total_shares']} shares")
        
        if not current_assets:
            logger.info("No investment assets found for TWR calculation (cash assets excluded)")
            return {
                'seven_day_return': 0,
                'annualized_return': 0,
                'start_value': 0,
                'end_value': 0,
                'cash_flows': [],
                'calculation_method': 'no_current_assets',
                'period_days': actual_period_days,
                'start_date': actual_start_date.isoformat(),
                'end_date': end_date.isoformat(),
                'base_currency': base_currency,
                'error_message': 'No investment assets in portfolio (cash assets excluded from performance calculation)'
            }
        
        # Step 1: Calculate starting market value (MV_start) - 7 days ago
        mv_start = 0
        start_value_details = []
        
        logger.info(f"ðŸ“Š Calculating starting value for {len(current_assets)} investment assets (cash assets excluded)")
        
        for asset in current_assets:
            ticker = asset['ticker_symbol']
            shares = float(asset['total_shares'])
            currency = asset['currency']
            
            logger.info(f"ðŸ” DEBUG: Processing asset {ticker} - {shares} shares in {currency}")
            
            # Get historical price for stocks/bonds/ETFs (cash assets already excluded)
            historical_price = None
            current_price_for_historical = None
            
            try:
                # First get current price
                price_data = fetch_stock_price_with_fallback(ticker)
                if price_data and 'current_price' in price_data:
                    current_price_for_historical = float(price_data['current_price'])
                    
                    # Use enhanced historical price function
                    historical_price = get_historical_stock_price(
                        ticker, 
                        actual_start_date, 
                        fallback_current_price=current_price_for_historical
                    )
                    
                    if historical_price != current_price_for_historical:
                        price_change = ((current_price_for_historical - historical_price) / historical_price) * 100
                        logger.info(f"ðŸ“ˆ {ticker}: Historical ${historical_price:.2f} â†’ Current ${current_price_for_historical:.2f} ({price_change:+.1f}%)")
                    else:
                        logger.info(f"ðŸ“ˆ {ticker}: Using current price ${historical_price:.2f} as historical approximation")
                else:
                    logger.warning(f"âš ï¸ No price data for {ticker}, using fallback price $1.00")
                    historical_price = 1.0  # Fallback price to prevent empty data
            except Exception as e:
                logger.error(f"âŒ Error fetching price for {ticker}: {str(e)}, using fallback price $1.00")
                historical_price = 1.0  # Fallback price to prevent empty data
            
            # Always try to calculate asset value, even with fallback price
            try:
                # Calculate asset value 7 days ago
                asset_value = shares * historical_price
                
                # Convert to base currency if needed
                if currency != base_currency:
                    try:
                        asset_value = convert_currency_amount(asset_value, currency, base_currency)
                    except Exception as e:
                        logger.error(f"âŒ Currency conversion failed for {ticker}: {str(e)}, using original value")
                        # Keep original value if conversion fails
                
                mv_start += asset_value
                start_value_details.append({
                    'ticker': ticker,
                    'shares': shares,
                    'price': historical_price,
                    'value': asset_value,
                    'currency': currency,
                    'has_price_data': current_price_for_historical is not None,
                    'is_fallback_price': historical_price == 1.0 and current_price_for_historical is None
                })
                
                logger.info(f"ðŸ’µ {ticker}: {shares} Ã— ${historical_price:.2f} = ${asset_value:.2f} {base_currency}")
                
            except Exception as e:
                logger.error(f"âŒ Error calculating start value for {ticker}: {str(e)}")
                # Still add to details with error info
                start_value_details.append({
                    'ticker': ticker,
                    'shares': shares,
                    'price': 0.0,
                    'value': 0.0,
                    'currency': currency,
                    'has_price_data': False,
                    'error': str(e)
                })
        
        # Calculate current market value (MV_end)
        mv_end = 0
        end_value_details = []
        
        logger.info(f"ðŸ“Š Calculating current value for {len(current_assets)} investment assets (cash assets excluded)")
        
        for asset in current_assets:
            ticker = asset['ticker_symbol']
            shares = float(asset['total_shares'])
            currency = asset['currency']
            
            # Get current price for stocks/bonds/ETFs (cash assets already excluded)
            current_price = None
            
            try:
                price_data = fetch_stock_price_with_fallback(ticker)
                if price_data and 'current_price' in price_data:
                    current_price = float(price_data['current_price'])
                else:
                    logger.warning(f"âš ï¸ No current price data for {ticker}, using fallback price $1.00")
                    current_price = 1.0  # Fallback price to prevent empty data
            except Exception as e:
                logger.error(f"âŒ Error fetching current price for {ticker}: {str(e)}, using fallback price $1.00")
                current_price = 1.0  # Fallback price to prevent empty data
            
            # Always try to calculate asset value, even with fallback price
            try:
                # Calculate current asset value
                asset_value = shares * current_price
                
                # Convert to base currency if needed
                if currency != base_currency:
                    try:
                        asset_value = convert_currency_amount(asset_value, currency, base_currency)
                    except Exception as e:
                        logger.error(f"âŒ Currency conversion failed for {ticker}: {str(e)}, using original value")
                        # Keep original value if conversion fails
                
                mv_end += asset_value
                end_value_details.append({
                    'ticker': ticker,
                    'shares': shares,
                    'price': current_price,
                    'value': asset_value,
                    'currency': currency,
                    'has_price_data': price_data is not None and 'current_price' in price_data,
                    'is_fallback_price': current_price == 1.0 and (price_data is None or 'current_price' not in price_data)
                })
                
                logger.info(f"ðŸ’µ {ticker}: {shares} Ã— ${current_price:.2f} = ${asset_value:.2f} {base_currency}")
                
            except Exception as e:
                logger.error(f"âŒ Error calculating current value for {ticker}: {str(e)}")
                # Still add to details with error info
                end_value_details.append({
                    'ticker': ticker,
                    'shares': shares,
                    'price': 0.0,
                    'value': 0.0,
                    'currency': currency,
                    'has_price_data': False,
                    'error': str(e)
                })
                
                logger.info(f"ðŸ’µ {ticker}: {shares} Ã— ${current_price:.2f} = ${asset_value:.2f} {base_currency}")
                
            except Exception as e:
                logger.error(f"âŒ Error calculating current value for {ticker}: {str(e)}")
                continue
        
        # Step 2: Identify cash flows in the actual period
        cash_flows = execute_query(
            DATABASE_URL,
            """
            SELECT t.transaction_date, t.shares, t.price_per_share, t.currency, 
                   t.transaction_type, a.ticker_symbol
            FROM transactions t
            JOIN assets a ON t.asset_id = a.asset_id
            WHERE a.user_id = %s 
            AND t.transaction_date > %s 
            AND t.transaction_date <= %s
            AND t.transaction_type IN ('LumpSum', 'Recurring')
            ORDER BY t.transaction_date
            """,
            (user_id, actual_start_date, end_date)
        )
        
        logger.info(f"ðŸ’° Found {len(cash_flows)} cash flows in the past {actual_period_days} days")
        
        # Step 3: Calculate TWR based on cash flows
        if not cash_flows:
            # Scenario A: No cash flows - Simple calculation
            if mv_start > 0:
                period_return = (mv_end / mv_start) - 1
                logger.info(f"ðŸ“Š Simple calculation: ({mv_end:.2f} / {mv_start:.2f}) - 1 = {period_return:.4f}")
            else:
                period_return = 0
                logger.info("ðŸ“Š Start value is 0, return = 0")
            
            calculation_method = 'simple_no_cash_flows'
            
        else:
            # Scenario B: With cash flows - TWR calculation
            logger.info("ðŸ“Š Using TWR calculation with cash flows")
            
            # For simplicity in this implementation, we'll use a simplified approach
            # In production, you'd want to implement full TWR with sub-periods
            
            # Calculate total cash flows
            total_cash_flows = 0
            cash_flow_details = []
            
            for cf in cash_flows:
                flow_amount = float(cf['shares']) * float(cf['price_per_share'])
                currency = cf['currency']
                
                # Convert to base currency if needed
                if currency != base_currency:
                    flow_amount = convert_currency_amount(flow_amount, currency, base_currency)
                
                total_cash_flows += flow_amount
                cash_flow_details.append({
                    'date': cf['transaction_date'].isoformat() if hasattr(cf['transaction_date'], 'isoformat') else str(cf['transaction_date']),
                    'ticker': cf['ticker_symbol'],
                    'amount': flow_amount,
                    'type': cf['transaction_type'],
                    'currency': currency
                })
                
                logger.info(f"ðŸ’¸ Cash flow: {cf['ticker_symbol']} ${flow_amount:.2f} {base_currency} on {cf['transaction_date']}")
            
            # Simplified TWR calculation
            # TWR = (MV_end) / (MV_start + Cash_flows) - 1
            if (mv_start + total_cash_flows) > 0:
                period_return = (mv_end / (mv_start + total_cash_flows)) - 1
                logger.info(f"ðŸ“Š TWR calculation: {mv_end:.2f} / ({mv_start:.2f} + {total_cash_flows:.2f}) - 1 = {period_return:.4f}")
            else:
                period_return = 0
                logger.info("ðŸ“Š Adjusted start value is 0, return = 0")
            
            calculation_method = 'twr_with_cash_flows'
        
        # Calculate annualized return based on actual period
        if period_return != 0 and actual_period_days > 0:
            # Annualized return = (1 + period return)^(365/days) - 1
            annualized_return = ((1 + period_return) ** (365/actual_period_days)) - 1
        else:
            annualized_return = 0
        
        logger.info(f"ðŸ“ˆ {actual_period_days}-day return: {period_return:.4f} ({period_return*100:.2f}%)")
        logger.info(f"ðŸ“ˆ Annualized return: {annualized_return:.4f} ({annualized_return*100:.2f}%)")
        
        # Debug: Log final results
        logger.info(f"ðŸ” DEBUG: Final results - Start value: ${mv_start:.2f}, End value: ${mv_end:.2f}")
        logger.info(f"ðŸ” DEBUG: Start value details count: {len(start_value_details)}")
        logger.info(f"ðŸ” DEBUG: End value details count: {len(end_value_details)}")
        for detail in start_value_details:
            logger.info(f"ðŸ” DEBUG: Start detail - {detail['ticker']}: {detail['shares']} Ã— ${detail['price']:.2f} = ${detail['value']:.2f}")
        
        return {
            'seven_day_return': period_return,
            'seven_day_return_percent': period_return * 100,
            'annualized_return': annualized_return,
            'annualized_return_percent': annualized_return * 100,
            'start_value': mv_start,
            'end_value': mv_end,
            'cash_flows': cash_flow_details if cash_flows else [],
            'total_cash_flows': total_cash_flows if cash_flows else 0,
            'calculation_method': calculation_method,
            'period_days': actual_period_days,
            'start_date': actual_start_date.isoformat(),
            'end_date': end_date.isoformat(),
            'base_currency': base_currency,
            'start_value_details': start_value_details,
            'end_value_details': end_value_details,
            'is_adjusted_period': actual_start_date > (end_date - timedelta(days=7)),
            'original_requested_days': 7
        }
        
    except Exception as e:
        logger.error(f"âŒ 7-day TWR calculation error: {str(e)}")
        raise e

def calculate_portfolio_performance(user_id, period_months=12):
    """
    Enhanced portfolio performance calculation with better time period handling
    
    For periods <= actual investment time: Uses transaction-based calculation
    For periods > actual investment time: Falls back to asset-based calculation
    
    Logic:
    - Get user's actual investment timeline
    - If requested period is within actual timeline: Use transaction-based calculation
    - If requested period exceeds actual timeline: Use current asset-based calculation
    - Always use proper time periods for annualization
    """
    try:
        logger.info(f"ðŸ“Š Calculating portfolio performance for user {user_id} over {period_months} months")
        
        # Get user's base currency
        user = execute_query(
            DATABASE_URL,
            "SELECT base_currency FROM users WHERE user_id = %s",
            (user_id,)
        )[0]
        base_currency = user['base_currency']
        logger.info(f"ðŸ’° User base currency: {base_currency}")
        
        # Get user's actual investment timeline
        first_transaction = execute_query(
            DATABASE_URL,
            """
            SELECT MIN(t.transaction_date) as first_date
            FROM transactions t
            JOIN assets a ON t.asset_id = a.asset_id
            WHERE a.user_id = %s AND t.transaction_type != 'Dividend'
            """,
            (user_id,)
        )
        
        if not first_transaction or not first_transaction[0]['first_date']:
            logger.info("No transactions found for performance calculation")
            return {
                'real_annual_return': 0,
                'total_return': 0,
                'total_invested': 0,
                'current_value': 0,
                'period_months': period_months,
                'base_currency': base_currency,
                'calculation_method': 'no_transactions'
            }
        
        # Calculate actual months since first transaction
        first_date = first_transaction[0]['first_date']
        from datetime import datetime, date
        if isinstance(first_date, str):
            first_date = datetime.strptime(first_date, '%Y-%m-%d').date()
        elif hasattr(first_date, 'date'):
            first_date = first_date.date()
        
        today = date.today()
        months_diff = (today.year - first_date.year) * 12 + (today.month - first_date.month)
        
        # Add fractional month based on days
        if today.day >= first_date.day:
            days_diff = today.day - first_date.day
        else:
            from calendar import monthrange
            days_in_prev_month = monthrange(today.year, today.month - 1 if today.month > 1 else 12)[1]
            days_diff = days_in_prev_month - first_date.day + today.day
            months_diff -= 1
        
        fractional_month = days_diff / 30.0
        actual_months = max(months_diff + fractional_month, 0.1)
        
        logger.info(f"ðŸ“… User's actual investment period: {actual_months:.2f} months")
        logger.info(f"ðŸŽ¯ Requested period: {period_months} months")
        
        # Determine calculation method based on requested vs actual period
        if period_months > actual_months:
            logger.info(f"âš ï¸ Requested period ({period_months}m) exceeds actual investment time ({actual_months:.1f}m)")
            logger.info("ðŸ“Š Using asset-based calculation with actual time period")
            
            # Use asset-based calculation but with actual time period
            effective_months = actual_months
            calculation_method = 'asset_based_limited_period'
        else:
            logger.info(f"âœ… Requested period ({period_months}m) is within actual investment time ({actual_months:.1f}m)")
            logger.info("ðŸ“Š Using transaction-based calculation for accurate period performance")
            
            # For now, use asset-based but we could enhance this to filter transactions by period
            effective_months = period_months
            calculation_method = 'asset_based_requested_period'
        
        # Get all user assets for current value calculation
        assets = execute_query(
            DATABASE_URL,
            """
            SELECT ticker_symbol, total_shares, average_cost_basis, currency
            FROM assets 
            WHERE user_id = %s AND total_shares > 0
            """,
            (user_id,)
        )
        
        if not assets:
            logger.info("No assets found for performance calculation")
            return {
                'real_annual_return': 0,
                'total_return': 0,
                'total_invested': 0,
                'current_value': 0,
                'period_months': effective_months,
                'base_currency': base_currency,
                'calculation_method': 'no_assets'
            }
        
        total_invested = 0
        current_value = 0
        
        logger.info(f"ðŸ“Š Processing {len(assets)} assets for performance calculation")
        
        for asset in assets:
            ticker = asset['ticker_symbol']
            shares = float(asset['total_shares'])
            avg_cost = float(asset['average_cost_basis'])
            currency = asset['currency']
            
            # Calculate invested amount (shares * average cost basis)
            invested_amount = shares * avg_cost
            logger.info(f"ðŸ’µ {ticker}: {shares} shares Ã— ${avg_cost:.2f} avg cost = ${invested_amount:.2f} {currency} invested")
            
            # Get current market price and calculate current value
            try:
                price_data = fetch_stock_price_with_fallback(ticker)
                if price_data and 'current_price' in price_data:
                    current_price = float(price_data['current_price'])
                    logger.info(f"ðŸ“ˆ {ticker}: Current market price ${current_price:.2f} {currency}")
                else:
                    current_price = avg_cost  # Fallback to cost basis
                    logger.info(f"ðŸ“Š {ticker}: Using cost basis ${current_price:.2f} {currency} (no market data)")
            except Exception as e:
                current_price = avg_cost  # Fallback to cost basis
                logger.warning(f"âš ï¸ {ticker}: Price fetch failed, using cost basis: {str(e)}")
            
            current_amount = shares * current_price
            logger.info(f"ðŸ’° {ticker}: {shares} shares Ã— ${current_price:.2f} current price = ${current_amount:.2f} {currency} current value")
            
            # Convert both amounts to base currency if needed
            if currency != base_currency:
                try:
                    invested_converted = convert_currency_amount(invested_amount, currency, base_currency)
                    current_converted = convert_currency_amount(current_amount, currency, base_currency)
                    
                    logger.info(f"ðŸ’± {ticker}: Invested ${invested_amount:.2f} {currency} â†’ ${invested_converted:.2f} {base_currency}")
                    logger.info(f"ðŸ’± {ticker}: Current ${current_amount:.2f} {currency} â†’ ${current_converted:.2f} {base_currency}")
                    
                    total_invested += invested_converted
                    current_value += current_converted
                    
                except Exception as e:
                    logger.warning(f"âš ï¸ Currency conversion failed for {ticker} ({currency} to {base_currency}): {str(e)}")
                    # Skip this asset rather than use wrong values
                    continue
            else:
                # Same currency - no conversion needed
                total_invested += invested_amount
                current_value += current_amount
                logger.info(f"âœ… {ticker}: Added ${invested_amount:.2f} invested, ${current_amount:.2f} current (same currency)")
        
        logger.info(f"ðŸ’° Portfolio totals (in {base_currency}):")
        logger.info(f"   Total invested: ${total_invested:,.2f}")
        logger.info(f"   Current value: ${current_value:,.2f}")
        
        if total_invested <= 0:
            return {
                'real_annual_return': 0,
                'total_return': 0,
                'total_invested': 0,
                'current_value': current_value,
                'period_months': effective_months,
                'base_currency': base_currency,
                'calculation_method': 'no_investments'
            }
        
        # Calculate total return
        total_return = (current_value - total_invested) / total_invested
        
        # Annualize the return based on the effective period
        if effective_months > 0:
            years = effective_months / 12
            if years > 0 and total_return > -1:  # Avoid negative base for fractional exponent
                annual_return = ((1 + total_return) ** (1/years)) - 1
            else:
                annual_return = total_return / years if years > 0 else 0  # Linear approximation for edge cases
        else:
            annual_return = 0
        
        logger.info(f"ðŸ“Š Performance results: Total return: {total_return:.2%}, Annual return: {annual_return:.2%}")
        
        return {
            'real_annual_return': annual_return,
            'total_return_percentage': total_return * 100,  # Convert to percentage
            'total_return': total_return,
            'total_invested': total_invested,
            'current_value': current_value,
            'absolute_gain_loss': current_value - total_invested,
            'period_months': effective_months,
            'start_date': (datetime.utcnow() - timedelta(days=effective_months * 30)).isoformat(),
            'end_date': datetime.utcnow().isoformat(),
            'base_currency': base_currency,
            'calculation_method': calculation_method,
            'actual_investment_months': actual_months,
            'requested_months': period_months,
            'annualized_return': annual_return * 100  # Convert to percentage
        }
        
    except Exception as e:
        logger.error(f"Portfolio performance calculation error: {str(e)}")
        return {
            'real_annual_return': 0,
            'total_return_percentage': 0,
            'total_return': 0,
            'total_invested': 0,
            'current_value': 0,
            'absolute_gain_loss': 0,
            'period_months': period_months,
            'start_date': datetime.utcnow().isoformat(),
            'end_date': datetime.utcnow().isoformat(),
            'error': str(e),
            'calculation_method': 'error',
            'base_currency': base_currency if 'base_currency' in locals() else 'USD',
            'annualized_return': 0
        }

def calculate_since_inception_performance(user_id):
    """
    Phase 1: Transaction-based Since Inception Performance Calculation
    
    CORRECTED LOGIC:
    - Total Invested = SUM(shares Ã— actual_transaction_price) for each transaction
    - Current Value = SUM(current_shares Ã— current_market_price) for each asset
    - Performance = (Current Value - Total Invested) / Total Invested
    - Annualized using actual time period since first transaction
    
    Example: VT transaction on 2025/7/9, current date 2025/7/14
    - Total Invested: Uses price paid on 2025/7/9
    - Current Value: Uses market price on 2025/7/14
    """
    try:
        logger.info(f"ðŸš€ Phase 1: Calculating transaction-based since inception performance for user {user_id}")
        
        # Get user's base currency
        user = execute_query(
            DATABASE_URL,
            "SELECT base_currency FROM users WHERE user_id = %s",
            (user_id,)
        )[0]
        base_currency = user['base_currency']
        logger.info(f"ðŸ’° User base currency: {base_currency}")
        
        # Get all user transactions (excluding dividends) with asset info
        transactions = execute_query(
            DATABASE_URL,
            """
            SELECT 
                t.transaction_id,
                t.transaction_date,
                t.shares,
                t.price_per_share,
                t.currency,
                t.transaction_type,
                a.ticker_symbol,
                a.asset_type
            FROM transactions t
            JOIN assets a ON t.asset_id = a.asset_id
            WHERE a.user_id = %s AND t.transaction_type != 'Dividend'
            ORDER BY t.transaction_date ASC
            """,
            (user_id,)
        )
        
        if not transactions:
            logger.info("No transactions found for since inception calculation")
            return {
                'real_annual_return': 0,
                'total_return': 0,
                'total_invested': 0,
                'current_value': 0,
                'period_months': 0,
                'base_currency': base_currency,
                'calculation_method': 'no_transactions',
                'inception_date': None
            }
        
        # STEP 1: Calculate Total Invested from actual transaction prices
        total_invested = 0
        first_date = transactions[0]['transaction_date']
        
        logger.info(f"ðŸ“… First transaction date: {first_date}")
        logger.info(f"ðŸ“Š Processing {len(transactions)} transactions for total invested calculation")
        
        for transaction in transactions:
            shares = float(transaction['shares'])
            actual_price_paid = float(transaction['price_per_share'])  # âœ… ACTUAL PRICE PAID
            currency = transaction['currency']
            ticker = transaction['ticker_symbol']
            transaction_date = transaction['transaction_date']
            
            # Calculate invested amount using ACTUAL transaction price
            invested_amount = shares * actual_price_paid
            
            logger.info(f"ðŸ’µ {ticker} ({transaction_date}): {shares} shares Ã— ${actual_price_paid:.2f} = ${invested_amount:.2f} {currency}")
            
            # Convert to base currency if needed
            if currency != base_currency:
                try:
                    invested_converted = convert_currency_amount(invested_amount, currency, base_currency)
                    logger.info(f"ðŸ’± {ticker}: ${invested_amount:.2f} {currency} â†’ ${invested_converted:.2f} {base_currency}")
                    total_invested += invested_converted
                except Exception as e:
                    logger.warning(f"âš ï¸ Currency conversion failed for {ticker} transaction ({currency} to {base_currency}): {str(e)}")
                    # Skip this transaction rather than use wrong values
                    continue
            else:
                total_invested += invested_amount
                logger.info(f"âœ… {ticker}: Added ${invested_amount:.2f} to total invested (same currency)")
        
        logger.info(f"ðŸ’° Total invested from actual transactions (in {base_currency}): ${total_invested:,.2f}")
        
        # STEP 2: Calculate Current Value using current market prices (EXCLUDE cash assets)
        current_assets = execute_query(
            DATABASE_URL,
            """
            SELECT ticker_symbol, total_shares, currency, asset_type
            FROM assets 
            WHERE user_id = %s 
            AND total_shares > 0
            AND asset_type != 'Cash'
            AND ticker_symbol NOT IN ('CASH', 'FIXED DEPOSITE', 'FLEXIBLE')
            """,
            (user_id,)
        )
        
        current_value = 0
        
        logger.info(f"ðŸ“ˆ Calculating current value for {len(current_assets)} assets")
        
        for asset in current_assets:
            ticker = asset['ticker_symbol']
            shares = float(asset['total_shares'])
            currency = asset['currency']
            
            # Get current market price (TODAY's price or last trading day)
            try:
                price_data = fetch_stock_price_with_fallback(ticker)
                if price_data and 'current_price' in price_data:
                    current_market_price = float(price_data['current_price'])
                    logger.info(f"ðŸ“ˆ {ticker}: Current market price ${current_market_price:.2f} {currency}")
                else:
                    logger.warning(f"âš ï¸ {ticker}: No current market price available, skipping from current value")
                    continue
            except Exception as e:
                logger.warning(f"âš ï¸ {ticker}: Price fetch failed: {str(e)}")
                continue
            
            # Calculate current value for this asset
            asset_current_value = shares * current_market_price
            logger.info(f"ðŸ’° {ticker}: {shares} shares Ã— ${current_market_price:.2f} = ${asset_current_value:.2f} {currency}")
            
            # Convert to base currency if needed
            if currency != base_currency:
                try:
                    value_converted = convert_currency_amount(asset_current_value, currency, base_currency)
                    logger.info(f"ðŸ’± {ticker}: ${asset_current_value:.2f} {currency} â†’ ${value_converted:.2f} {base_currency}")
                    current_value += value_converted
                except Exception as e:
                    logger.warning(f"âš ï¸ Currency conversion failed for {ticker} value ({currency} to {base_currency}): {str(e)}")
                    continue
            else:
                current_value += asset_current_value
                logger.info(f"âœ… {ticker}: Added ${asset_current_value:.2f} to current value (same currency)")
        
        logger.info(f"ðŸ’° Current portfolio value (in {base_currency}): ${current_value:,.2f}")
        
        # STEP 3: Calculate actual time period since inception
        from datetime import datetime, date
        if isinstance(first_date, str):
            first_date = datetime.strptime(first_date, '%Y-%m-%d').date()
        elif hasattr(first_date, 'date'):
            first_date = first_date.date()
        
        today = date.today()
        
        # Calculate months with more precision
        months_diff = (today.year - first_date.year) * 12 + (today.month - first_date.month)
        
        # Add fractional month based on days
        if today.day >= first_date.day:
            days_diff = today.day - first_date.day
        else:
            # Handle case where current day is before the start day of month
            from calendar import monthrange
            days_in_prev_month = monthrange(today.year, today.month - 1 if today.month > 1 else 12)[1]
            days_diff = days_in_prev_month - first_date.day + today.day
            months_diff -= 1
        
        # Convert days to fraction of month (approximate)
        fractional_month = days_diff / 30.0
        actual_months = max(months_diff + fractional_month, 0.1)  # Minimum 0.1 months
        
        logger.info(f"ðŸ“Š Actual investment period: {actual_months:.2f} months ({actual_months/12:.2f} years)")
        
        # STEP 4: Calculate performance metrics
        if total_invested <= 0:
            logger.warning("Total invested is zero or negative, cannot calculate performance")
            return {
                'real_annual_return': 0,
                'total_return': 0,
                'total_invested': 0,
                'current_value': current_value,
                'period_months': actual_months,
                'base_currency': base_currency,
                'calculation_method': 'no_investments',
                'inception_date': first_date.isoformat()
            }
        
        # Calculate total return
        total_return = (current_value - total_invested) / total_invested
        
        # Calculate annualized return
        years = actual_months / 12
        if years > 0 and total_return > -1:  # Avoid negative base for fractional exponent
            annual_return = ((1 + total_return) ** (1/years)) - 1
        else:
            annual_return = total_return / years if years > 0 else 0  # Linear approximation for edge cases
        
        logger.info(f"ðŸ“Š Performance Results:")
        logger.info(f"   Total Invested: ${total_invested:,.2f} {base_currency}")
        logger.info(f"   Current Value: ${current_value:,.2f} {base_currency}")
        logger.info(f"   Total Return: {total_return:.2%}")
        logger.info(f"   Annualized Return: {annual_return:.2%}")
        logger.info(f"   Gain/Loss: ${current_value - total_invested:,.2f}")
        
        return {
            'real_annual_return': annual_return,
            'total_return': total_return,
            'total_invested': total_invested,
            'current_value': current_value,
            'period_months': actual_months,
            'base_currency': base_currency,
            'calculation_method': 'transaction_based_since_inception',
            'inception_date': first_date.isoformat(),
            'years_invested': years,
            'total_transactions': len(transactions)
        }
        
    except Exception as e:
        logger.error(f"âŒ Since inception performance calculation error: {str(e)}")
        return {
            'real_annual_return': 0,
            'total_return': 0,
            'total_invested': 0,
            'current_value': 0,
            'period_months': 0,
            'error': str(e),
            'calculation_method': 'error',
            'base_currency': 'USD'
        }

def handle_get_7day_twr_performance(user_id):
    """Get 7-day Time-Weighted Return portfolio performance for a user"""
    try:
        performance = calculate_7day_twr_performance(user_id)
        
        # Add additional metrics
        performance_data = {
            **performance,
            'timestamp': datetime.utcnow().isoformat(),
            'user_id': user_id
        }
        
        return create_response(200, {
            "seven_day_twr_performance": performance_data
        })
        
    except Exception as e:
        logger.error(f"Get 7-day TWR performance error: {str(e)}")
        return create_error_response(500, "Failed to calculate 7-day TWR performance")

def handle_get_portfolio_performance(user_id, period_months=12):
    """Get portfolio performance metrics for a user with proper multi-currency support"""
    try:
        performance = calculate_portfolio_performance(user_id, period_months)
        
        # Add additional metrics
        performance_data = {
            **performance,
            'timestamp': datetime.utcnow().isoformat(),
            'user_id': user_id
        }
        
        return create_response(200, {
            "portfolio_performance": performance_data
        })
        
    except Exception as e:
        logger.error(f"Get portfolio performance error: {str(e)}")
        return create_error_response(500, "Failed to calculate portfolio performance")

def get_monthly_recurring_total(user_id):
    """ðŸ”§ FIXED: Get total monthly recurring investments for user with proper currency conversion"""
    try:
        recurring_investments = execute_query(
            DATABASE_URL,
            """
            SELECT amount, currency, frequency, ticker_symbol FROM recurring_investments 
            WHERE user_id = %s AND is_active = true
            """,
            (user_id,)
        )
        
        # Get user's base currency
        user = execute_query(
            DATABASE_URL,
            "SELECT base_currency FROM users WHERE user_id = %s",
            (user_id,)
        )[0]
        base_currency = user['base_currency']
        
        logger.info(f"ðŸ” Processing {len(recurring_investments)} recurring investments for user {user_id}")
        logger.info(f"ðŸ’° User base currency: {base_currency}")
        
        # Group investments by currency and sum them
        currency_totals = {}
        
        for investment in recurring_investments:
            amount = float(investment['amount'])
            currency = investment['currency']
            frequency = investment.get('frequency', 'monthly')
            ticker = investment.get('ticker_symbol', 'N/A')
            
            # Convert to monthly amount based on frequency
            if frequency == 'weekly':
                monthly_amount = amount * 4.33  # Average weeks per month
            elif frequency == 'bi-weekly':
                monthly_amount = amount * 2.17  # Average bi-weeks per month
            elif frequency == 'monthly':
                monthly_amount = amount
            elif frequency == 'quarterly':
                monthly_amount = amount / 3
            elif frequency == 'annually':
                monthly_amount = amount / 12
            else:
                monthly_amount = amount  # Default to monthly
            
            logger.info(f"ðŸ“Š {ticker}: {amount} {currency}/{frequency} â†’ {monthly_amount:.2f} {currency}/month")
            
            # Sum by currency
            if currency not in currency_totals:
                currency_totals[currency] = 0
            currency_totals[currency] += monthly_amount
        
        logger.info(f"ðŸ’µ Currency totals before conversion: {currency_totals}")
        
        # Convert each currency total to base currency
        total_monthly = 0
        
        for currency, amount in currency_totals.items():
            if currency == base_currency:
                # Same currency - no conversion needed
                total_monthly += amount
                logger.info(f"âœ… Same currency: {amount:.2f} {currency} â†’ {amount:.2f} {base_currency}")
            else:
                # Different currency - need conversion
                converted_amount = None
                
                try:
                    # ðŸ”§ FIX 1: Fetch exchange rates if not cached
                    exchange_rates = None
                    
                    # Try to get cached rates first
                    cached_rates = get_cached_exchange_rate(base_currency, 'ALL')
                    if cached_rates and 'rates' in cached_rates:
                        exchange_rates = cached_rates['rates']
                        logger.info(f"ðŸ’° Using cached rates for {base_currency}")
                    else:
                        # Fetch fresh rates from API
                        logger.info(f"ðŸŒ Fetching fresh exchange rates for {base_currency}")
                        try:
                            url = f"{EXCHANGE_RATE_BASE_URL}/{base_currency}"
                            response = requests.get(url, timeout=10)
                            response.raise_for_status()
                            data = response.json()
                            
                            if 'rates' in data:
                                exchange_rates = data['rates']
                                
                                # Cache the result
                                result = {
                                    "success": True,
                                    "base": data.get('base', base_currency),
                                    "rates": exchange_rates,
                                    "last_updated": data.get('date', datetime.utcnow().isoformat()),
                                    "source": "ExchangeRate-API",
                                    "cached": False
                                }
                                set_cached_exchange_rate(base_currency, 'ALL', result)
                                logger.info(f"âœ… Fetched and cached exchange rates for {base_currency}")
                            else:
                                logger.error(f"âŒ No rates in API response for {base_currency}")
                        except Exception as api_error:
                            logger.error(f"âŒ Failed to fetch exchange rates: {str(api_error)}")
                    
                    # Now try to convert using the exchange rates
                    if exchange_rates and currency in exchange_rates:
                        # This gives us the rate from base_currency to foreign currency
                        base_to_foreign_rate = float(exchange_rates[currency])
                        
                        # Validate the rate is reasonable
                        if base_to_foreign_rate > 0 and base_to_foreign_rate < 1000:
                            # To convert foreign currency to base currency, we need the inverse
                            converted_amount = amount / base_to_foreign_rate
                            logger.info(f"ðŸ’± SUCCESS: {amount:.2f} {currency} â†’ {converted_amount:.2f} {base_currency} (rate: 1/{base_to_foreign_rate:.6f})")
                        else:
                            logger.warning(f"âš ï¸ Invalid rate: {base_to_foreign_rate}")
                    
                    # ðŸ”§ FIX 2: Fallback method - try the reverse direction
                    if converted_amount is None:
                        # Try to get rates from foreign currency to base currency
                        cached_rates = get_cached_exchange_rate(currency, 'ALL')
                        if cached_rates and 'rates' in cached_rates and base_currency in cached_rates['rates']:
                            foreign_to_base_rate = float(cached_rates['rates'][base_currency])
                            
                            if foreign_to_base_rate > 0 and foreign_to_base_rate < 1000:
                                converted_amount = amount * foreign_to_base_rate
                                logger.info(f"ðŸ’± FALLBACK SUCCESS: {amount:.2f} {currency} â†’ {converted_amount:.2f} {base_currency} (rate: {foreign_to_base_rate:.6f})")
                            else:
                                logger.warning(f"âš ï¸ Invalid fallback rate: {foreign_to_base_rate}")
                        else:
                            # Try to fetch rates from the foreign currency perspective
                            try:
                                url = f"{EXCHANGE_RATE_BASE_URL}/{currency}"
                                response = requests.get(url, timeout=10)
                                response.raise_for_status()
                                data = response.json()
                                
                                if 'rates' in data and base_currency in data['rates']:
                                    foreign_to_base_rate = float(data['rates'][base_currency])
                                    
                                    if foreign_to_base_rate > 0 and foreign_to_base_rate < 1000:
                                        converted_amount = amount * foreign_to_base_rate
                                        logger.info(f"ðŸ’± API FALLBACK SUCCESS: {amount:.2f} {currency} â†’ {converted_amount:.2f} {base_currency} (rate: {foreign_to_base_rate:.6f})")
                                        
                                        # Cache this result too
                                        result = {
                                            "success": True,
                                            "base": data.get('base', currency),
                                            "rates": data['rates'],
                                            "last_updated": data.get('date', datetime.utcnow().isoformat()),
                                            "source": "ExchangeRate-API",
                                            "cached": False
                                        }
                                        set_cached_exchange_rate(currency, 'ALL', result)
                                    else:
                                        logger.warning(f"âš ï¸ Invalid API fallback rate: {foreign_to_base_rate}")
                            except Exception as fallback_error:
                                logger.error(f"âŒ Fallback API call failed: {str(fallback_error)}")
                    
                    # ðŸ”§ FIX 3: Only add once, with validation
                    if converted_amount is not None and converted_amount > 0:
                        total_monthly += converted_amount
                        logger.info(f"âœ… Added {converted_amount:.2f} {base_currency} to total")
                    else:
                        logger.warning(f"âŒ No valid conversion for {currency} to {base_currency}")
                        logger.warning(f"âš ï¸ Skipping {amount:.2f} {currency} due to conversion error")
                        
                except Exception as e:
                    logger.error(f"âŒ Exchange rate conversion failed for {currency}: {str(e)}")
                    logger.warning(f"âš ï¸ Skipping {amount:.2f} {currency} due to conversion error")
        
        logger.info(f"ðŸŽ¯ Final total monthly recurring: {total_monthly:.2f} {base_currency}")
        return total_monthly
        
    except Exception as e:
        logger.error(f"âŒ Error getting monthly recurring total: {str(e)}")
        return 0

def get_portfolio_total_value(user_id):
    """Get current portfolio value with real-time prices and proper currency conversion"""
    try:
        # Get user's base currency
        user = execute_query(
            DATABASE_URL,
            "SELECT base_currency FROM users WHERE user_id = %s",
            (user_id,)
        )[0]
        base_currency = user['base_currency']
        
        # Get assets with asset type information
        assets = execute_query(
            DATABASE_URL,
            """
            SELECT ticker_symbol, total_shares, average_cost_basis, currency, asset_type, 
                   interest_rate, maturity_date, start_date, created_at
            FROM assets WHERE user_id = %s AND total_shares > 0
            """,
            (user_id,)
        )
        
        total_value = 0
        
        for asset in assets:
            ticker = asset['ticker_symbol']
            shares = float(asset['total_shares'])
            currency = asset.get('currency', 'USD')
            asset_type = asset.get('asset_type', 'Stock')
            
            # Handle CD assets with compound interest calculation
            if asset_type == 'CD':
                interest_rate = asset.get('interest_rate')
                maturity_date = asset.get('maturity_date')
                start_date = asset.get('start_date')
                
                if interest_rate and maturity_date:
                    # Calculate CD compound interest
                    principal = shares * float(asset['average_cost_basis'])
                    
                    # Use start_date if available, otherwise fall back to created_at
                    if start_date:
                        start_date_str = start_date.strftime('%Y-%m-%d') if hasattr(start_date, 'strftime') else str(start_date)
                        logger.info(f"ðŸ’° CD {ticker}: Using start_date {start_date_str}")
                    else:
                        # Fallback to created_at for existing CDs without start_date
                        created_at = asset.get('created_at')
                        if created_at:
                            start_date_str = created_at.strftime('%Y-%m-%d') if hasattr(created_at, 'strftime') else str(created_at)
                            logger.warning(f"âš ï¸ CD {ticker}: Using created_at as fallback start_date {start_date_str}")
                        else:
                            # Final fallback to principal if no dates available
                            asset_value = principal
                            logger.warning(f"âš ï¸ CD {ticker}: No start date available, using principal ${asset_value}")
                            continue
                    
                    maturity_date_str = maturity_date.strftime('%Y-%m-%d') if hasattr(maturity_date, 'strftime') else str(maturity_date)
                    
                    cd_calculation = calculate_cd_compound_interest(
                        principal=principal,
                        annual_rate=float(interest_rate),
                        start_date=start_date_str,
                        maturity_date=maturity_date_str,
                        compounding_frequency='daily'
                    )
                    
                    asset_value = cd_calculation['current_value']
                    logger.info(f"ðŸ’° CD {ticker}: ${principal} â†’ ${asset_value} (${cd_calculation['accrued_interest']} interest)")
                else:
                    # Fallback to cost basis if CD data is incomplete
                    asset_value = shares * float(asset['average_cost_basis'])
                    logger.warning(f"âš ï¸ CD {ticker}: Missing rate/maturity, using cost basis ${asset_value}")
            else:
                # Handle stocks, bonds, cash, etc. with market prices
                try:
                    price_data = fetch_stock_price_with_fallback(ticker)
                    if price_data and 'current_price' in price_data:
                        current_price = float(price_data['current_price'])
                    else:
                        current_price = float(asset['average_cost_basis'])
                except:
                    current_price = float(asset['average_cost_basis'])
                
                asset_value = shares * current_price
            
            # Convert to base currency if needed
            if currency != base_currency:
                try:
                    # ðŸ”§ FIXED: Fetch exchange rates if not cached, same logic as recurring investments
                    exchange_rates = None
                    
                    # Try to get cached rates first
                    cached_rates = get_cached_exchange_rate(base_currency, 'ALL')
                    if cached_rates and 'rates' in cached_rates:
                        exchange_rates = cached_rates['rates']
                        logger.info(f"ðŸ’° Using cached rates for {base_currency}")
                    else:
                        # Fetch fresh rates from API
                        logger.info(f"ðŸŒ Fetching fresh exchange rates for {base_currency}")
                        try:
                            url = f"{EXCHANGE_RATE_BASE_URL}/{base_currency}"
                            response = requests.get(url, timeout=10)
                            response.raise_for_status()
                            data = response.json()
                            
                            if 'rates' in data:
                                exchange_rates = data['rates']
                                
                                # Cache the result
                                result = {
                                    "success": True,
                                    "base": data.get('base', base_currency),
                                    "rates": exchange_rates,
                                    "last_updated": data.get('date', datetime.utcnow().isoformat()),
                                    "source": "ExchangeRate-API",
                                    "cached": False
                                }
                                set_cached_exchange_rate(base_currency, 'ALL', result)
                                logger.info(f"âœ… Fetched and cached exchange rates for {base_currency}")
                            else:
                                logger.error(f"âŒ No rates in API response for {base_currency}")
                        except Exception as api_error:
                            logger.error(f"âŒ Failed to fetch exchange rates: {str(api_error)}")
                    
                    # Now try to convert using the exchange rates
                    if exchange_rates and currency in exchange_rates:
                        # This gives us the rate from base_currency to foreign currency
                        base_to_foreign_rate = float(exchange_rates[currency])
                        
                        # Validate the rate is reasonable
                        if base_to_foreign_rate > 0 and base_to_foreign_rate < 1000:
                            # To convert foreign currency to base currency, we need the inverse
                            asset_value = asset_value / base_to_foreign_rate
                            logger.info(f"ðŸ’± Converted asset {ticker}: {asset_value * base_to_foreign_rate:.2f} {currency} â†’ {asset_value:.2f} {base_currency} (rate: 1/{base_to_foreign_rate:.6f})")
                        else:
                            logger.warning(f"âš ï¸ Invalid rate: {base_to_foreign_rate}")
                    else:
                        logger.warning(f"No exchange rate available for {currency} to {base_currency}, using original value")
                        
                except Exception as e:
                    logger.warning(f"Currency conversion failed for {ticker}: {str(e)}")
            
            total_value += asset_value
        
        return total_value
        
    except Exception as e:
        logger.error(f"Error getting portfolio total value: {str(e)}")
        return 0

def get_inflation_rate_from_profile(user_id):
    """Get inflation rate from user's FIRE profile, with fallback to default"""
    try:
        profile = execute_query(
            DATABASE_URL,
            "SELECT inflation_rate FROM fire_profile WHERE user_id = %s",
            (user_id,)
        )
        
        if profile and profile[0]['inflation_rate']:
            return float(profile[0]['inflation_rate'])
        else:
            return 0.025  # Default 2.5% inflation
            
    except Exception as e:
        logger.error(f"Error getting inflation rate: {str(e)}")
        return 0.025  # Default fallback


def convert_barista_income_to_base_currency(barista_income, barista_currency, base_currency):
    """Convert barista annual income to user's base currency"""
    if barista_currency == base_currency:
        return barista_income
    
    try:
        # Get exchange rate from barista currency to base currency
        exchange_rates = get_exchange_rates(barista_currency)
        if exchange_rates and base_currency in exchange_rates:
            conversion_rate = exchange_rates[base_currency]
            converted_amount = barista_income * conversion_rate
            logger.info(f"Converted barista income: {barista_income} {barista_currency} -> {converted_amount} {base_currency} (rate: {conversion_rate})")
            return converted_amount
        else:
            logger.warning(f"Could not get exchange rate from {barista_currency} to {base_currency}, using original amount")
            return barista_income
    except Exception as e:
        logger.error(f"Error converting barista income currency: {str(e)}")
        return barista_income

def calculate_fire_progress(user_id):
    """Calculate FIRE progress using proper coast-fire-calculator algorithms with inflation"""
    try:
        # Get user's FIRE profile
        profile = execute_query(
            DATABASE_URL,
            "SELECT * FROM fire_profile WHERE user_id = %s",
            (user_id,)
        )
        
        if not profile:
            return create_error_response(404, "FIRE profile not found. Please create a FIRE profile first.")
        
        profile = profile[0]
        
        # Get user info for age calculation and base currency
        user = execute_query(
            DATABASE_URL,
            "SELECT birth_year, base_currency FROM users WHERE user_id = %s",
            (user_id,)
        )[0]
        
        current_year = datetime.now().year
        current_age = current_year - user['birth_year']
        base_currency = user['base_currency']
        
        # Get current portfolio value with real-time prices
        current_portfolio_value = get_portfolio_total_value(user_id)
        
        # âœ… CORRECTED: Use monthly recurring investments for timeline calculation
        # This represents the user's actual investment capacity from their recurring plans
        monthly_contribution = get_monthly_recurring_total(user_id)
        
        # Annual expenses is the ONLY parameter needed from Basic Financial Information
        # It's used to calculate FIRE targets, not investment capacity
        
        # Get inflation rate from profile or use default
        inflation_rate = get_inflation_rate_from_profile(user_id)
        
        # Initialize FIRE calculator
        calculator = FIRECalculator()
        
        # Prepare calculation data with correct field mapping
        calculation_data = {
            'current_age': current_age,
            'target_retirement_age': profile['target_retirement_age'],
            'annual_expenses': float(profile['annual_expenses']),  # âœ… ONLY parameter from Basic Financial Info
            'safe_withdrawal_rate': float(profile['safe_withdrawal_rate']),
            # ðŸ”§ Use correct field name from profile
            'expected_annual_return': float(profile.get('expected_return_pre_retirement', profile.get('expected_annual_return', 0.07))),
            'inflation_rate': inflation_rate,
            'monthly_contribution': monthly_contribution,  # âœ… CORRECTED: From recurring investments
            # ðŸ”§ Calculate monthly barista contribution properly (separate from basic financial info)
            'monthly_barista_contribution': convert_barista_income_to_base_currency(
                float(profile.get('barista_annual_income', 30000)), 
                profile.get('barista_income_currency', base_currency), 
                base_currency
            ) / 12,
            'current_portfolio_value': current_portfolio_value
        }
        
        # Calculate comprehensive FIRE results (simplified without inflation)
        fire_results = calculator.calculate_comprehensive_fire_simple(calculation_data)
        
        # Create calculations array for backward compatibility with simplified data
        calculations = [
            {
                "fire_type": "Traditional",
                "target_amount": fire_results['traditional_fire']['target'],
                "annual_income": fire_results['traditional_fire']['annual_income'],
                "annual_expenses": fire_results['traditional_fire']['annual_expenses'],
                "safe_withdrawal_rate": fire_results['traditional_fire']['safe_withdrawal_rate'],
                "current_progress": current_portfolio_value,
                "progress_percentage": fire_results['traditional_fire']['progress_percentage'],
                "achieved": fire_results['traditional_fire']['achieved'],
                "years_remaining": fire_results['traditional_fire']['years_remaining'],
                "monthly_investment_needed": fire_results['traditional_fire']['monthly_investment_needed'],
                "method": fire_results['traditional_fire']['method'],
                "message": fire_results['traditional_fire']['message']
            },
            {
                "fire_type": "Coast",
                "target_amount": fire_results['coast_fire']['target'],
                "expected_return": fire_results['coast_fire']['expected_return'],
                "current_progress": current_portfolio_value,
                "progress_percentage": fire_results['coast_fire']['progress_percentage'],
                "achieved": fire_results['coast_fire']['achieved'],
                "years_remaining": fire_results['coast_fire']['years_remaining'],
                "monthly_investment_needed": fire_results['coast_fire']['monthly_investment_needed'],
                "final_value_at_retirement": fire_results['coast_fire']['final_value_at_retirement'],
                "method": fire_results['coast_fire']['method'],
                "message": fire_results['coast_fire']['message']
            },
            {
                "fire_type": "Barista",
                "target_amount": fire_results['barista_fire']['target'],
                "traditional_fire_target": fire_results['barista_fire']['traditional_fire_target'],
                "coast_fire_target": fire_results['barista_fire']['coast_fire_target'],
                "crossover_point": fire_results['barista_fire']['crossover_point'],
                "barista_annual_contribution": fire_results['barista_fire']['barista_annual_contribution'],
                "full_time_contribution": fire_results['barista_fire']['full_time_contribution'],
                "current_progress": current_portfolio_value,
                "progress_percentage": fire_results['barista_fire']['progress_percentage'],
                "achieved": fire_results['barista_fire']['achieved'],
                "years_remaining": fire_results['barista_fire']['years_remaining'],
                "monthly_investment_needed": fire_results['barista_fire']['monthly_investment_needed'],
                "concept": fire_results['barista_fire']['concept'],
                "explanation": fire_results['barista_fire']['explanation'],
                "method": fire_results['barista_fire']['method'],
                "message": fire_results['barista_fire']['message']
            }
        ]
        
        return create_response(200, {
            "fire_progress": {
                "current_total_assets": current_portfolio_value,
                "traditional_fire_target": fire_results['traditional_fire']['target'],
                "barista_fire_target": fire_results['barista_fire']['target'],
                "coast_fire_target": fire_results['coast_fire']['target'],
                "traditional_fire_progress": fire_results['traditional_fire']['progress_percentage'],
                "barista_fire_progress": fire_results['barista_fire']['progress_percentage'],
                "coast_fire_progress": fire_results['coast_fire']['progress_percentage'],
                # ðŸ†• Enhanced calculations - no more TODOs!
                "years_to_traditional_fire": fire_results['traditional_fire']['years_remaining'],
                "years_to_barista_fire": fire_results['barista_fire']['years_remaining'],
                "years_to_coast_fire": fire_results['coast_fire']['years_remaining'],
                "monthly_investment_needed_traditional": fire_results['traditional_fire']['monthly_investment_needed'],
                "monthly_investment_needed_barista": fire_results['barista_fire']['monthly_investment_needed'],
                "monthly_investment_needed_coast": fire_results['coast_fire']['monthly_investment_needed'],
                "is_coast_fire_achieved": fire_results['coast_fire']['achieved'],
                "is_barista_fire_achieved": fire_results['barista_fire']['achieved'],
                "is_traditional_fire_achieved": fire_results['traditional_fire']['achieved'],
                # ðŸ†• Summary insights
                "fastest_fire_type": fire_results['summary_metrics']['fastest_fire_type'],
                "most_achievable_target": fire_results['summary_metrics']['most_achievable_target'],
                "current_monthly_contribution": monthly_contribution
            },
            "calculations": calculations,
            "summary_metrics": fire_results['summary_metrics'],
            "user_age": current_age,
            "base_currency": base_currency,
            "calculation_method": fire_results['metadata']['calculation_method'],
            "calculation_timestamp": datetime.now().isoformat()
        })
        
    except Exception as e:
        logger.error(f"Calculate FIRE progress error: {str(e)}")
        return create_error_response(500, f"Failed to calculate FIRE progress: {str(e)}")

def handle_get_stock_prices_multi_api(query_params):
    """Handle multi-API stock price requests with fallback"""
    try:
        symbols = query_params.get('symbols', '').split(',')
        symbols = [s.strip().upper() for s in symbols if s.strip()]
        
        if not symbols:
            return create_error_response(400, "No symbols provided")
        
        logger.info(f"Fetching stock prices for symbols: {symbols}")
        
        results = {}
        cache_hits = 0
        api_calls = 0
        
        for symbol in symbols:
            price_data = fetch_stock_price_with_fallback(symbol)
            if price_data:
                results[symbol] = price_data
                if price_data.get('cached', False):
                    cache_hits += 1
                else:
                    api_calls += 1
        
        return create_response(200, {
            "prices": results,
            "timestamp": datetime.now().isoformat(),
            "symbols_requested": len(symbols),
            "symbols_found": len(results),
            "cache_stats": {
                "cache_hits": cache_hits,
                "api_calls": api_calls,
                "cache_hit_rate": f"{(cache_hits / len(symbols) * 100):.1f}%" if symbols else "0%"
            }
        })
        
    except Exception as e:
        logger.error(f"Multi-API stock price error: {str(e)}")
        return create_error_response(500, "Failed to fetch stock prices")

def fetch_stock_price_with_fallback(symbol):
    """Fetch stock price with multiple API fallback strategy and caching"""
    
    # First, check cache
    cached_price = get_cached_stock_price(symbol)
    if cached_price:
        return cached_price
    
    # API priority order: For Taiwan stocks, prioritize Yahoo Finance direct HTTP
    # For other stocks, use Finnhub -> Alpha Vantage -> Yahoo Finance -> Mock Data
    if symbol.upper().endswith('.TW') or symbol.upper().endswith('.TWO'):
        # Taiwan stocks: Use Yahoo Finance direct HTTP first (no numpy dependency)
        apis = [
            ('yahoo_direct', fetch_from_yahoo_finance_direct),
            ('finnhub', fetch_from_finnhub), 
            ('alphavantage', fetch_from_alphavantage_single)
        ]
        logger.info(f"ðŸ‡¹ðŸ‡¼ Taiwan stock detected: {symbol}, using Yahoo Finance direct HTTP first")
    else:
        # Other stocks: Standard priority order
        apis = [
            ('finnhub', fetch_from_finnhub), 
            ('alphavantage', fetch_from_alphavantage_single),
            ('yahoo', fetch_from_yahoo_finance)
        ]
    
    for api_name, fetch_func in apis:
        try:
            logger.info(f"Trying {api_name} API for {symbol}")
            price_data = fetch_func(symbol)
            
            if price_data:
                logger.info(f"âœ… Successfully fetched {symbol} from {api_name}")
                price_data['source'] = api_name
                
                # Cache the successful result
                set_cached_stock_price(symbol, price_data)
                
                return price_data
                
        except Exception as e:
            logger.warning(f"âŒ {api_name} API failed for {symbol}: {str(e)}")
            continue
    
    # If all APIs fail, return mock data (don't cache mock data)
    logger.warning(f"ðŸŽ­ All APIs failed for {symbol}, using mock data")
    mock_data = get_mock_stock_price(symbol)
    mock_data['source'] = 'mock'
    return mock_data

def fetch_from_finnhub(symbol):
    """Fetch from Finnhub API using official Python client"""
    api_key = os.getenv('FINNHUB_API_KEY') or os.getenv('REACT_APP_FINNHUB_API_KEY')
    if not api_key:
        raise Exception("Finnhub API key not configured")
    
    try:
        import finnhub
        
        # Create Finnhub client
        finnhub_client = finnhub.Client(api_key=api_key)
        
        # Get quote data
        quote = finnhub_client.quote(symbol)
        
        if not quote or not quote.get('c'):
            raise Exception("No data from Finnhub API")
        
        # Try to get additional company info (optional, don't fail if it doesn't work)
        company_profile = None
        try:
            company_profile = finnhub_client.company_profile2(symbol=symbol)
        except:
            pass  # Company profile is optional
        
        # Finnhub quote response format:
        # c: Current price
        # d: Change
        # dp: Percent change
        # h: High price of the day
        # l: Low price of the day
        # o: Open price of the day
        # pc: Previous close price
        # t: Timestamp
        
        result = {
            'symbol': symbol,
            'price': quote['c'],  # current price
            'change': quote['d'],  # change
            'changePercent': quote['dp'],  # percent change
            'currency': 'USD',
            'lastUpdated': datetime.now().isoformat(),
            'marketStatus': determine_market_status(),
            'high': quote.get('h', quote['c']),
            'low': quote.get('l', quote['c']),
            'open': quote.get('o', quote['c']),
            'previousClose': quote.get('pc', quote['c']),
            'timestamp': quote.get('t', 0)
        }
        
        # Add company info if available
        if company_profile:
            result.update({
                'companyName': company_profile.get('name', symbol),
                'industry': company_profile.get('finnhubIndustry', ''),
                'marketCap': company_profile.get('marketCapitalization', 0),
                'country': company_profile.get('country', 'US')
            })
        
        return result
        
    except ImportError:
        # Fallback to HTTP requests if finnhub package not available
        logger.warning("Finnhub package not available, falling back to HTTP requests")
        return fetch_from_finnhub_http(symbol)
    except Exception as e:
        logger.error(f"Finnhub API error: {str(e)}")
        raise e

def fetch_from_finnhub_http(symbol):
    """Fallback HTTP implementation for Finnhub API"""
    api_key = os.getenv('FINNHUB_API_KEY') or os.getenv('REACT_APP_FINNHUB_API_KEY')
    if not api_key:
        raise Exception("Finnhub API key not configured")
    
    url = "https://finnhub.io/api/v1/quote"
    params = {'symbol': symbol, 'token': api_key}
    
    response = requests.get(url, params=params, timeout=10)
    response.raise_for_status()
    
    data = response.json()
    
    if not data.get('c'):
        raise Exception("No data from Finnhub API")
    
    return {
        'symbol': symbol,
        'price': data['c'],  # current price
        'change': data['d'],  # change
        'changePercent': data['dp'],  # percent change
        'currency': 'USD',
        'lastUpdated': datetime.now().isoformat(),
        'marketStatus': determine_market_status(),
        'high': data.get('h', data['c']),
        'low': data.get('l', data['c']),
        'open': data.get('o', data['c']),
        'previousClose': data.get('pc', data['c'])
    }

def fetch_from_alphavantage_single(symbol):
    """Fetch from Alpha Vantage API (existing implementation)"""
    api_key = os.getenv('ALPHA_VANTAGE_API_KEY')
    if not api_key:
        raise Exception("Alpha Vantage API key not configured")
    
    import requests
    
    url = "https://www.alphavantage.co/query"
    params = {
        'function': 'GLOBAL_QUOTE',
        'symbol': symbol,
        'apikey': api_key
    }
    
    response = requests.get(url, params=params, timeout=10)
    response.raise_for_status()
    
    data = response.json()
    
    # Check for rate limit
    if data.get('Information') and 'rate limit' in data['Information'].lower():
        raise Exception("Alpha Vantage rate limit reached")
    
    if data.get('Note') and 'rate limit' in data['Note'].lower():
        raise Exception("Alpha Vantage rate limit reached")
    
    quote = data.get('Global Quote')
    if not quote:
        raise Exception("No data from Alpha Vantage API")
    
    return {
        'symbol': quote['01. symbol'],
        'price': float(quote['05. price']),
        'change': float(quote['09. change']),
        'changePercent': float(quote['10. change percent'].replace('%', '')),
        'currency': 'USD',
        'lastUpdated': datetime.now().isoformat(),
        'marketStatus': determine_market_status(),
        'high': float(quote['03. high']),
        'low': float(quote['04. low']),
        'open': float(quote['02. open']),
        'previousClose': float(quote['08. previous close']),
        'volume': int(quote['06. volume'])
    }

def fetch_from_yahoo_finance(symbol):
    """Fetch from Yahoo Finance using yfinance library (no API key required)"""
    try:
        import yfinance as yf
        logger.info(f"âœ… yfinance imported successfully for {symbol}")
        
        # Create a Ticker object
        ticker = yf.Ticker(symbol)
        
        # Get ticker info
        info = ticker.info
        logger.info(f"ðŸ“Š Got ticker info for {symbol}, keys: {len(info.keys())}")
        
        # Try to get current price from multiple sources
        current_price = None
        previous_close = None
        
        # Method 1: Try regularMarketPrice and previousClose from info
        current_price = info.get('regularMarketPrice')
        previous_close = info.get('previousClose')
        logger.info(f"Method 1 - regularMarketPrice: {current_price}, previousClose: {previous_close}")
        
        # Method 2: If not available, try currentPrice
        if current_price is None:
            current_price = info.get('currentPrice')
            logger.info(f"Method 2 - currentPrice: {current_price}")
        
        # Method 3: If still not available, try historical data
        if current_price is None or previous_close is None:
            logger.info(f"Trying historical data for {symbol}")
            try:
                hist = ticker.history(period="2d")  # Get last 2 days
                logger.info(f"Historical data shape: {hist.shape if not hist.empty else 'empty'}")
                if not hist.empty:
                    if current_price is None:
                        current_price = hist['Close'].iloc[-1]  # Latest close
                        logger.info(f"Got current_price from history: {current_price}")
                    if previous_close is None and len(hist) > 1:
                        previous_close = hist['Close'].iloc[-2]  # Previous close
                        logger.info(f"Got previous_close from history: {previous_close}")
                    elif previous_close is None:
                        previous_close = current_price  # Use same price if only 1 day available
                        logger.info(f"Using current_price as previous_close: {previous_close}")
            except Exception as hist_error:
                logger.warning(f"Historical data failed for {symbol}: {str(hist_error)}")
        
        if current_price is None:
            raise Exception("Could not retrieve current price from yfinance")
        
        if previous_close is None:
            previous_close = current_price  # Fallback to current price
        
        # Calculate change and change percent
        change = current_price - previous_close
        change_percent = (change / previous_close) * 100 if previous_close > 0 else 0
        
        # Get additional data with fallbacks
        currency = info.get('currency', 'USD')
        market_state = info.get('marketState', 'CLOSED')
        
        logger.info(f"âœ… yfinance success for {symbol}: price={current_price}, currency={currency}")
        
        return {
            'symbol': symbol,
            'price': float(current_price),
            'change': float(change),
            'changePercent': float(change_percent),
            'currency': currency,
            'lastUpdated': datetime.now().isoformat(),
            'marketStatus': map_yahoo_market_status(market_state),
            'high': float(info.get('regularMarketDayHigh', current_price)),
            'low': float(info.get('regularMarketDayLow', current_price)),
            'open': float(info.get('regularMarketOpen', current_price)),
            'previousClose': float(previous_close),
            'volume': int(info.get('regularMarketVolume', 0))
        }
        
    except ImportError as import_error:
        # Fallback to direct HTTP if yfinance is not available
        logger.warning(f"yfinance not available for {symbol}: {str(import_error)}")
        return fetch_from_yahoo_finance_direct(symbol)
    except Exception as e:
        logger.error(f"yfinance error for {symbol}: {str(e)}")
        # Try direct HTTP as fallback
        logger.info(f"Trying direct HTTP fallback for {symbol}")
        return fetch_from_yahoo_finance_direct(symbol)

def fetch_from_yahoo_finance_direct(symbol):
    """Fallback: Fetch from Yahoo Finance using direct HTTP - Updated to match working implementation"""
    import requests
    
    url = f"https://query1.finance.yahoo.com/v8/finance/chart/{symbol}"
    headers = {
        'User-Agent': 'Mozilla/5.0 (compatible; Worthy-Portfolio-App/1.0)'
    }
    
    logger.info(f"ðŸŒ Fetching {symbol} from Yahoo Finance direct HTTP: {url}")
    
    try:
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()  # Raise an HTTPError for bad responses (4xx or 5xx)
        
        data = response.json()
        logger.info(f"ðŸ“Š Yahoo Finance response structure for {symbol}: chart={bool(data.get('chart'))}")
        
        # Extract the price from the response - matching your working code
        if data and 'chart' in data and 'result' in data['chart'] and data['chart']['result']:
            meta_data = data['chart']['result'][0]['meta']
            logger.info(f"ðŸ“ˆ Meta data keys for {symbol}: {list(meta_data.keys())}")
            
            current_price = meta_data.get('regularMarketPrice')
            if current_price is None:
                current_price = meta_data.get('previousClose')  # Fallback to previous close
                logger.info(f"âš ï¸ Using previousClose as fallback for {symbol}: {current_price}")
            
            if current_price:
                previous_close = meta_data.get('previousClose', current_price)
                change = current_price - previous_close
                change_percent = (change / previous_close) * 100 if previous_close > 0 else 0
                
                currency = meta_data.get('currency', 'USD')
                logger.info(f"âœ… Yahoo Finance direct success for {symbol}: price={current_price}, currency={currency}")
                
                return {
                    'symbol': symbol,
                    'price': float(current_price),
                    'change': float(change),
                    'changePercent': float(change_percent),
                    'currency': currency,
                    'lastUpdated': datetime.now().isoformat(),
                    'marketStatus': map_yahoo_market_status(meta_data.get('marketState', 'CLOSED')),
                    'high': float(meta_data.get('regularMarketDayHigh', current_price)),
                    'low': float(meta_data.get('regularMarketDayLow', current_price)),
                    'open': float(meta_data.get('regularMarketOpen', current_price)),
                    'previousClose': float(previous_close),
                    'volume': int(meta_data.get('regularMarketVolume', 0))
                }
            else:
                logger.error(f"âŒ Could not find price data in the response for {symbol}")
                raise Exception(f"Could not find price data for {symbol}")
        else:
            logger.error(f"âŒ No valid chart data found for {symbol}")
            raise Exception(f"No valid chart data found for {symbol}")
            
    except requests.exceptions.HTTPError as errh:
        logger.error(f"âŒ HTTP Error for {symbol}: {errh}")
        raise Exception(f"HTTP Error: {errh}")
    except requests.exceptions.ConnectionError as errc:
        logger.error(f"âŒ Connection Error for {symbol}: {errc}")
        raise Exception(f"Connection Error: {errc}")
    except requests.exceptions.Timeout as errt:
        logger.error(f"âŒ Timeout Error for {symbol}: {errt}")
        raise Exception(f"Timeout Error: {errt}")
    except requests.exceptions.RequestException as err:
        logger.error(f"âŒ Request Error for {symbol}: {err}")
        raise Exception(f"Request Error: {err}")
    except ValueError as e:  # For json.JSONDecodeError if response is not JSON
        logger.error(f"âŒ JSON Decode Error for {symbol}: {e}")
        logger.error(f"Response content: {response.text[:200]}...")
        raise Exception(f"JSON Decode Error: {e}")

def get_mock_stock_price(symbol):
    """Get mock stock price data as fallback"""
    mock_prices = {
        'AAPL': {'price': 175.50, 'change': 2.30, 'changePercent': 1.33},
        'TSLA': {'price': 248.75, 'change': -5.20, 'changePercent': -2.05},
        'MSFT': {'price': 378.85, 'change': 4.12, 'changePercent': 1.10},
        'GOOGL': {'price': 142.56, 'change': -1.23, 'changePercent': -0.85},
        'AMZN': {'price': 145.32, 'change': 2.87, 'changePercent': 2.01},
        'NVDA': {'price': 875.30, 'change': 15.20, 'changePercent': 1.77},
        'META': {'price': 325.40, 'change': -8.90, 'changePercent': -2.66},
        'NFLX': {'price': 445.60, 'change': 12.30, 'changePercent': 2.84}
    }
    
    mock_data = mock_prices.get(symbol, {
        'price': 100.00,
        'change': 0.00,
        'changePercent': 0.00
    })
    
    return {
        'symbol': symbol,
        'price': mock_data['price'],
        'change': mock_data['change'],
        'changePercent': mock_data['changePercent'],
        'currency': 'USD',
        'lastUpdated': datetime.now().isoformat(),
        'marketStatus': determine_market_status(),
        'source': 'mock'
    }

def determine_market_status():
    """Determine current market status"""
    now = datetime.now()
    hour = now.hour
    weekday = now.weekday()
    
    # Simple market hours check (9:30 AM - 4:00 PM EST)
    if weekday >= 5:  # Weekend
        return 'CLOSED'
    elif 9 <= hour < 16:
        return 'OPEN'
    elif 4 <= hour < 9:
        return 'PRE_MARKET'
    else:
        return 'AFTER_HOURS'

def map_yahoo_market_status(status):
    """Map Yahoo Finance market status to our format"""
    status_map = {
        'REGULAR': 'OPEN',
        'CLOSED': 'CLOSED',
        'PRE': 'PRE_MARKET',
        'POST': 'AFTER_HOURS'
    }
    return status_map.get(status.upper(), 'CLOSED')

def handle_register(body):
    try:
        # Validate input
        name = body.get('name', '').strip()
        email = body.get('email', '').strip().lower()
        password = body.get('password', '')
        base_currency = body.get('base_currency', 'USD')
        birth_year = body.get('birth_year')
        
        if not name or not email or not password:
            return create_error_response(400, "Name, email and password are required")
        
        # Validate name length
        if len(name) < 2 or len(name) > 50:
            return create_error_response(400, "Name must be between 2 and 50 characters")
        
        # Validate email format
        try:
            validate_email(email)
        except EmailNotValidError:
            return create_error_response(400, "Invalid email format")
        
        # Validate password strength
        if len(password) < 8:
            return create_error_response(400, "Password must be at least 8 characters long")
        
        # Check if user already exists
        existing_user = execute_query(
            DATABASE_URL,
            "SELECT user_id FROM users WHERE email = %s",
            (email,)
        )
        
        if existing_user:
            return create_error_response(409, "User with this email already exists")
        
        # Hash password
        password_hash = hash_password(password)
        
        # Create user
        execute_update(
            DATABASE_URL,
            """
            INSERT INTO users (name, email, password_hash, base_currency, birth_year)
            VALUES (%s, %s, %s, %s, %s)
            """,
            (name, email, password_hash, base_currency, birth_year)
        )
        
        # Get created user
        user = execute_query(
            DATABASE_URL,
            "SELECT user_id, name, email, base_currency, birth_year, created_at FROM users WHERE email = %s",
            (email,)
        )[0]
        
        # Generate JWT token
        token = generate_token(user['user_id'], email)
        
        return create_response(201, {
            "message": "User registered successfully",
            "user": {
                "user_id": user['user_id'],
                "name": user['name'],
                "email": user['email'],
                "base_currency": user['base_currency'],
                "birth_year": user['birth_year'],
                "created_at": user['created_at'].isoformat()
            },
            "token": token
        })
        
    except Exception as e:
        logger.error(f"Registration error: {str(e)}")
        return create_error_response(500, "Registration failed")

def handle_login(body):
    """Handle user login"""
    try:
        email = body.get('email', '').strip().lower()
        password = body.get('password', '')
        
        if not email or not password:
            return create_error_response(400, "Email and password are required")
        
        # Get user from database
        users = execute_query(
            DATABASE_URL,
            "SELECT user_id, name, email, password_hash, base_currency, birth_year FROM users WHERE email = %s",
            (email,)
        )
        
        if not users:
            return create_error_response(401, "Invalid email or password")
        
        user = users[0]
        
        # Verify password
        if not verify_password(password, user['password_hash']):
            return create_error_response(401, "Invalid email or password")
        
        # Generate JWT token
        token = generate_token(user['user_id'], user['email'])
        
        return create_response(200, {
            "message": "Login successful",
            "user": {
                "user_id": user['user_id'],
                "name": user['name'],
                "email": user['email'],
                "base_currency": user['base_currency'],
                "birth_year": user['birth_year']
            },
            "token": token
        })
        
    except Exception as e:
        logger.error(f"Login error: {str(e)}")
        return create_error_response(500, "Login failed")

def handle_logout(headers):
    """Handle user logout"""
    return create_response(200, {"message": "Logout successful"})

def handle_refresh_token(headers):
    """Handle token refresh"""
    try:
        auth_result = verify_token(headers)
        if auth_result.get('error'):
            return create_error_response(401, auth_result['error'])
        
        user_id = auth_result['user_id']
        email = auth_result['email']
        
        # Generate new token
        token = generate_token(user_id, email)
        
        return create_response(200, {
            "message": "Token refreshed successfully",
            "token": token
        })
        
    except Exception as e:
        logger.error(f"Token refresh error: {str(e)}")
        return create_error_response(500, "Token refresh failed")

def handle_verify_token(headers):
    """Handle token verification"""
    auth_result = verify_token(headers)
    if auth_result.get('error'):
        return create_error_response(401, auth_result['error'])
    else:
        return create_response(200, {
            "valid": True,
            "user_id": auth_result['user_id'],
            "email": auth_result['email']
        })

def handle_get_exchange_rates(base_currency='USD'):
    """Proxy endpoint for exchange rates with caching"""
    try:
        logger.info(f"Fetching exchange rates for base currency: {base_currency}")
        
        # Check cache first
        cached_rates = get_cached_exchange_rate(base_currency, 'ALL')
        if cached_rates:
            logger.info(f"ðŸ“¦ Using cached exchange rates for {base_currency}")
            return create_response(200, cached_rates)
        
        # Make request to ExchangeRate-API
        url = f"{EXCHANGE_RATE_BASE_URL}/{base_currency}"
        
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        
        data = response.json()
        
        result = {
            "success": True,
            "base": data.get('base', base_currency),
            "rates": data.get('rates', {}),
            "last_updated": data.get('date', datetime.utcnow().isoformat()),
            "source": "ExchangeRate-API",
            "cached": False
        }
        
        # Cache the result
        set_cached_exchange_rate(base_currency, 'ALL', result)
        
        return create_response(200, result)
        
    except requests.exceptions.RequestException as e:
        logger.error(f"Exchange rate API error: {str(e)}")
        return create_error_response(503, f"Exchange rate service unavailable: {str(e)}")
    except Exception as e:
        logger.error(f"Exchange rate handler error: {str(e)}")
        return create_error_response(500, "Failed to fetch exchange rates")

def handle_get_stock_price(symbol):
    """Proxy endpoint for stock prices"""
    try:
        logger.info(f"Fetching stock price for symbol: {symbol}")
        
        # Make request to Alpha Vantage API
        params = {
            'function': 'GLOBAL_QUOTE',
            'symbol': symbol.upper(),
            'apikey': ALPHA_VANTAGE_API_KEY
        }
        
        response = requests.get(ALPHA_VANTAGE_BASE_URL, params=params, timeout=15)
        response.raise_for_status()
        
        data = response.json()
        
        # Check for API errors
        if 'Error Message' in data:
            return create_error_response(400, f"Invalid symbol: {symbol}")
        
        if 'Note' in data:
            return create_error_response(429, "API rate limit exceeded")
        
        if 'Global Quote' not in data:
            return create_error_response(404, f"No data found for symbol: {symbol}")
        
        quote = data['Global Quote']
        
        # Parse and format the response
        stock_data = {
            "symbol": quote.get('01. symbol', symbol),
            "price": float(quote.get('05. price', 0)),
            "change": float(quote.get('09. change', 0)),
            "change_percent": quote.get('10. change percent', '0%').replace('%', ''),
            "volume": quote.get('06. volume', '0'),
            "latest_trading_day": quote.get('07. latest trading day', ''),
            "previous_close": float(quote.get('08. previous close', 0)),
            "currency": "USD",
            "source": "Alpha Vantage",
            "last_updated": datetime.utcnow().isoformat()
        }
        
        return create_response(200, {
            "success": True,
            "data": stock_data
        })
        
    except requests.exceptions.RequestException as e:
        logger.error(f"Stock price API error: {str(e)}")
        return create_error_response(503, f"Stock price service unavailable: {str(e)}")
    except ValueError as e:
        logger.error(f"Stock price parsing error: {str(e)}")
        return create_error_response(500, "Failed to parse stock price data")
    except Exception as e:
        logger.error(f"Stock price handler error: {str(e)}")
        return create_error_response(500, "Failed to fetch stock price")

def handle_get_multiple_stock_prices(symbols):
    """Proxy endpoint for multiple stock prices"""
    try:
        logger.info(f"Fetching stock prices for symbols: {symbols}")
        
        if not symbols or len(symbols) == 0:
            return create_error_response(400, "No symbols provided")
        
        if len(symbols) > 10:
            return create_error_response(400, "Too many symbols (max 10)")
        
        results = {}
        errors = []
        
        for symbol in symbols:
            try:
                # Make individual requests (Alpha Vantage doesn't support batch requests)
                params = {
                    'function': 'GLOBAL_QUOTE',
                    'symbol': symbol.upper(),
                    'apikey': ALPHA_VANTAGE_API_KEY
                }
                
                response = requests.get(ALPHA_VANTAGE_BASE_URL, params=params, timeout=15)
                response.raise_for_status()
                
                data = response.json()
                
                if 'Global Quote' in data:
                    quote = data['Global Quote']
                    results[symbol.upper()] = {
                        "symbol": quote.get('01. symbol', symbol),
                        "price": float(quote.get('05. price', 0)),
                        "change": float(quote.get('09. change', 0)),
                        "change_percent": quote.get('10. change percent', '0%').replace('%', ''),
                        "currency": "USD",
                        "last_updated": datetime.utcnow().isoformat()
                    }
                else:
                    errors.append(f"No data for {symbol}")
                
                # Rate limiting: wait between requests
                import time
                time.sleep(12)  # 12 seconds between requests (5 calls per minute limit)
                
            except Exception as e:
                errors.append(f"Error fetching {symbol}: {str(e)}")
        
        return create_response(200, {
            "success": True,
            "data": results,
            "errors": errors,
            "source": "Alpha Vantage"
        })
        
    except Exception as e:
        logger.error(f"Multiple stock prices handler error: {str(e)}")
        return create_error_response(500, "Failed to fetch stock prices")

# Main Lambda handler
def lambda_handler(event, context):
    """Main Lambda handler for Worthy API"""
    try:
        # Log the incoming event
        logger.info(f"Received event: {json.dumps(event, default=str)}")
        
        # Ensure CD columns exist (run once per cold start)
        ensure_cd_columns_exist()
        
        # Extract HTTP method and path
        http_method = event.get('httpMethod', '').upper()
        path = event.get('path', '')
        
        # Handle CORS preflight requests
        if http_method == 'OPTIONS':
            return create_response(200, {})
        
        # Route the request
        if http_method == 'GET' and path == '/health':
            import os as os_module
            return create_response(200, {
                "status": "healthy",
                "timestamp": datetime.utcnow().isoformat(),
                "environment": os_module.getenv('AWS_LAMBDA_FUNCTION_NAME', 'local')
            })
        
        elif http_method == 'GET' and path == '/test/cd-calculation':
            # Test CD calculation endpoint
            try:
                # Example CD calculation
                example_cd = calculate_cd_compound_interest(
                    principal=10000,  # $10,000 initial investment
                    annual_rate=4.5,  # 4.5% annual interest rate
                    start_date='2024-01-01',  # Started January 1, 2024
                    maturity_date='2025-01-01',  # Matures January 1, 2025
                    compounding_frequency='daily'
                )
                
                return create_response(200, {
                    "message": "CD calculation example",
                    "example": {
                        "principal": 10000,
                        "annual_rate": "4.5%",
                        "term": "1 year (365 days)",
                        "compounding": "daily",
                        "start_date": "2024-01-01",
                        "maturity_date": "2025-01-01"
                    },
                    "calculation": example_cd,
                    "explanation": {
                        "formula": "A = P(1 + r/n)^(nt)",
                        "where": {
                            "A": "Final amount",
                            "P": "Principal ($10,000)",
                            "r": "Annual rate (0.045)",
                            "n": "Compounding periods per year (365)",
                            "t": "Time in years"
                        }
                    }
                })
            except Exception as e:
                return create_error_response(500, f"CD calculation error: {str(e)}")
        
        elif http_method == 'POST' and path == '/admin/migrate-cd-columns':
            # Manual database migration endpoint for CD columns
            try:
                # Add interest_rate column
                try:
                    execute_update(DATABASE_URL, "ALTER TABLE assets ADD COLUMN interest_rate DECIMAL(5,4)")
                    logger.info("Added interest_rate column")
                    interest_rate_added = True
                except Exception as e:
                    logger.info(f"Interest rate column may already exist: {str(e)}")
                    interest_rate_added = False
                
                # Add maturity_date column
                try:
                    execute_update(DATABASE_URL, "ALTER TABLE assets ADD COLUMN maturity_date DATE")
                    logger.info("Added maturity_date column")
                    maturity_date_added = True
                except Exception as e:
                    logger.info(f"Maturity date column may already exist: {str(e)}")
                    maturity_date_added = False
                
                # Test the columns
                test_result = execute_query(DATABASE_URL, "SELECT interest_rate, maturity_date FROM assets LIMIT 1")
                
                return create_response(200, {
                    "message": "CD column migration completed",
                    "results": {
                        "interest_rate_added": interest_rate_added,
                        "maturity_date_added": maturity_date_added,
                        "columns_working": True
                    },
                    "next_steps": "You can now create CD assets with interest rates and maturity dates"
                })
                
            except Exception as e:
                return create_error_response(500, f"Migration failed: {str(e)}")
        
        elif http_method == 'GET' and path == '/cache/status':
            # Cache status endpoint for monitoring
            cache_stats = get_cache_stats()
            return create_response(200, {
                "cache_status": cache_stats,
                "timestamp": datetime.utcnow().isoformat(),
                "cache_enabled": True
            })
        
        elif http_method == 'GET' and path == '/debug/currency':
            # ðŸ”§ DEBUG: Currency conversion troubleshooting endpoint
            request_headers = event.get('headers', {})
            auth_result = verify_jwt_token(request_headers.get('Authorization', ''))
            
            if not auth_result['valid']:
                return create_error_response(401, "Invalid or missing token")
            
            user_id = auth_result['user_id']
            
            try:
                # Get user info
                user = execute_query(DATABASE_URL, "SELECT base_currency, email FROM users WHERE user_id = %s", (user_id,))[0]
                
                # Get recurring investments
                investments_raw = execute_query(
                    DATABASE_URL,
                    "SELECT amount, currency, frequency, ticker_symbol FROM recurring_investments WHERE user_id = %s AND is_active = true",
                    (user_id,)
                )
                
                # Convert Decimal objects to float for JSON serialization
                investments = []
                for inv in investments_raw:
                    investments.append({
                        'amount': float(inv['amount']) if inv['amount'] is not None else 0.0,
                        'currency': inv['currency'],
                        'frequency': inv['frequency'],
                        'ticker_symbol': inv['ticker_symbol']
                    })
                
                # Test currency conversion
                monthly_total = get_monthly_recurring_total(user_id)
                
                # Get exchange rates for debugging
                unique_currencies = list(set([inv['currency'] for inv in investments]))
                exchange_rates = {}
                
                for currency in unique_currencies:
                    if currency != user['base_currency']:
                        try:
                            rates1 = get_cached_exchange_rate(user['base_currency'], 'ALL')
                            rates2 = get_cached_exchange_rate(currency, 'ALL')
                            exchange_rates[currency] = {
                                f"{user['base_currency']}_to_ALL": rates1,
                                f"{currency}_to_ALL": rates2
                            }
                        except Exception as e:
                            exchange_rates[currency] = {"error": str(e)}
                
                return create_response(200, {
                    "user": {
                        "email": user['email'],
                        "base_currency": user['base_currency']
                    },
                    "recurring_investments": investments,
                    "monthly_total_converted": float(monthly_total) if monthly_total is not None else 0.0,
                    "exchange_rates": exchange_rates,
                    "debug_timestamp": datetime.utcnow().isoformat()
                })
                
            except Exception as e:
                logger.error(f"Debug currency endpoint error: {str(e)}")
                return create_error_response(500, f"Debug failed: {str(e)}")
        
        elif http_method == 'POST' and path == '/cache/clear':
            # Cache clear endpoint (for admin use)
            with _cache_lock:
                stock_count = len(stock_price_cache)
                rate_count = len(exchange_rate_cache)
                stock_price_cache.clear()
                exchange_rate_cache.clear()
                
            logger.info(f"ðŸ§¹ Cache cleared - removed {stock_count} stock prices and {rate_count} exchange rates")
            return create_response(200, {
                "message": "Cache cleared successfully",
                "cleared": {
                    "stock_prices": stock_count,
                    "exchange_rates": rate_count
                },
                "timestamp": datetime.utcnow().isoformat()
            })
        
        elif http_method == 'GET' and path == '/':
            return create_response(200, {
                "message": "Worthy API is running",
                "version": "1.0.0",
                "environment": "lambda"
            })
        
        # User profile routes
        elif path.startswith('/user/'):
            # Verify JWT token
            request_headers = event.get('headers', {})
            auth_result = verify_jwt_token(request_headers.get('Authorization', ''))
            
            if not auth_result['valid']:
                return create_error_response(401, "Invalid or missing token")
            
            user_id = auth_result['user_id']
            
            # Handle user profile routes
            if http_method == 'PUT' and path == '/user/profile':
                # Update user profile
                try:
                    body = json.loads(event.get('body', '{}'))
                    result = update_user_profile(user_id, body)
                    
                    if result['success']:
                        return create_response(200, result)
                    else:
                        return create_error_response(400, result['message'])
                except Exception as e:
                    logger.error(f"Error updating user profile: {str(e)}")
                    return create_error_response(500, f"Error updating profile: {str(e)}")
            
            elif http_method == 'GET' and path == '/user/profile':
                # Get user profile
                try:
                    user = execute_query(
                        DATABASE_URL,
                        "SELECT user_id, name, email, base_currency, birth_year, created_at FROM users WHERE user_id = %s",
                        (user_id,)
                    )[0]
                    
                    return create_response(200, {"user": user})
                except Exception as e:
                    logger.error(f"Error getting user profile: {str(e)}")
                    return create_error_response(500, f"Error getting profile: {str(e)}")
            
            else:
                return create_error_response(404, f"Endpoint not found: {path}")
        
        # Authentication endpoints
        elif path.startswith('/auth/'):
            # Parse request body for POST requests
            body = {}
            if http_method in ['POST', 'PUT'] and event.get('body'):
                try:
                    body = json.loads(event['body'])
                except json.JSONDecodeError:
                    return create_error_response(400, "Invalid JSON in request body")
            
            # Get headers for token verification
            request_headers = event.get('headers', {})
            
            # Route to specific auth endpoints
            if http_method == 'POST' and path == '/auth/register':
                return handle_register(body)
            
            elif http_method == 'POST' and path == '/auth/login':
                return handle_login(body)
            
            elif http_method == 'POST' and path == '/auth/logout':
                return handle_logout(request_headers)
            
            elif http_method == 'POST' and path == '/auth/refresh':
                return handle_refresh_token(request_headers)
            
            elif http_method == 'GET' and path == '/auth/verify':
                return handle_verify_token(request_headers)
            
            else:
                return create_error_response(404, f"Auth endpoint not found: {path}")
        
        # Asset management endpoints
        elif path == '/assets' and http_method == 'POST':
            # Create asset - requires authentication
            body = {}
            if event.get('body'):
                try:
                    body = json.loads(event['body'])
                except json.JSONDecodeError:
                    return create_error_response(400, "Invalid JSON in request body")
            
            request_headers = event.get('headers', {})
            auth_result = verify_jwt_token(request_headers.get('Authorization', ''))
            if not auth_result['valid']:
                return create_error_response(401, "Invalid or missing token")
            
            return handle_create_asset(body, auth_result['user_id'])
        
        elif path == '/assets' and http_method == 'GET':
            # Get user assets - requires authentication
            request_headers = event.get('headers', {})
            auth_result = verify_jwt_token(request_headers.get('Authorization', ''))
            if not auth_result['valid']:
                return create_error_response(401, "Invalid or missing token")
            
            return handle_get_assets(auth_result['user_id'])
        
        elif path.startswith('/assets/') and http_method == 'GET':
            # Get specific asset or asset transactions - requires authentication
            request_headers = event.get('headers', {})
            auth_result = verify_jwt_token(request_headers.get('Authorization', ''))
            if not auth_result['valid']:
                return create_error_response(401, "Invalid or missing token")
            
            try:
                # Check if this is a request for asset transactions
                if path.endswith('/transactions'):
                    # Extract asset ID from path like /assets/4/transactions
                    asset_id = int(path.split('/')[-2])
                    return handle_get_asset_transactions(asset_id, auth_result['user_id'])
                else:
                    # Regular asset request
                    asset_id = int(path.split('/')[-1])
                    return handle_get_asset(asset_id, auth_result['user_id'])
            except ValueError:
                return create_error_response(400, "Invalid asset ID")
        
        elif path.startswith('/assets/') and http_method == 'PUT':
            # Update asset - requires authentication
            body = {}
            if event.get('body'):
                try:
                    body = json.loads(event['body'])
                except json.JSONDecodeError:
                    return create_error_response(400, "Invalid JSON in request body")
            
            request_headers = event.get('headers', {})
            auth_result = verify_jwt_token(request_headers.get('Authorization', ''))
            if not auth_result['valid']:
                return create_error_response(401, "Invalid or missing token")
            
            try:
                asset_id = int(path.split('/')[-1])
                return handle_update_asset(asset_id, body, auth_result['user_id'])
            except ValueError:
                return create_error_response(400, "Invalid asset ID")
        
        elif path.startswith('/assets/') and http_method == 'DELETE':
            # Delete asset - requires authentication
            request_headers = event.get('headers', {})
            auth_result = verify_jwt_token(request_headers.get('Authorization', ''))
            if not auth_result['valid']:
                return create_error_response(401, "Invalid or missing token")
            
            try:
                asset_id = int(path.split('/')[-1])
                return handle_delete_asset(asset_id, auth_result['user_id'])
            except ValueError:
                return create_error_response(400, "Invalid asset ID")
        
        elif path == '/transactions' and http_method == 'POST':
            # Create transaction - requires authentication
            body = {}
            if event.get('body'):
                try:
                    body = json.loads(event['body'])
                except json.JSONDecodeError:
                    return create_error_response(400, "Invalid JSON in request body")
            
            request_headers = event.get('headers', {})
            auth_result = verify_jwt_token(request_headers.get('Authorization', ''))
            if not auth_result['valid']:
                return create_error_response(401, "Invalid or missing token")
            
            return handle_create_transaction(body, auth_result['user_id'])
        
        elif path == '/transactions' and http_method == 'GET':
            # Get all user transactions - requires authentication
            request_headers = event.get('headers', {})
            auth_result = verify_jwt_token(request_headers.get('Authorization', ''))
            if not auth_result['valid']:
                return create_error_response(401, "Invalid or missing token")
            
            return handle_get_transactions(auth_result['user_id'])
        
        elif path.startswith('/transactions/') and http_method == 'PUT':
            # Update transaction - requires authentication
            body = {}
            if event.get('body'):
                try:
                    body = json.loads(event['body'])
                except json.JSONDecodeError:
                    return create_error_response(400, "Invalid JSON in request body")
            
            request_headers = event.get('headers', {})
            auth_result = verify_jwt_token(request_headers.get('Authorization', ''))
            if not auth_result['valid']:
                return create_error_response(401, "Invalid or missing token")
            
            try:
                transaction_id = int(path.split('/')[-1])
                return handle_update_transaction(transaction_id, body, auth_result['user_id'])
            except ValueError:
                return create_error_response(400, "Invalid transaction ID")
        
        elif path.startswith('/transactions/') and http_method == 'DELETE':
            # Delete transaction - requires authentication
            request_headers = event.get('headers', {})
            auth_result = verify_jwt_token(request_headers.get('Authorization', ''))
            if not auth_result['valid']:
                return create_error_response(401, "Invalid or missing token")
            
            try:
                transaction_id = int(path.split('/')[-1])
                return handle_delete_transaction(transaction_id, auth_result['user_id'])
            except ValueError:
                return create_error_response(400, "Invalid transaction ID")
        
        # ============================================================================
        # MILESTONE 4: RECURRING INVESTMENTS ENDPOINTS
        # ============================================================================
        
        elif path == '/recurring-investments' and http_method == 'POST':
            # Create recurring investment plan - requires authentication
            body = {}
            if event.get('body'):
                try:
                    body = json.loads(event['body'])
                except json.JSONDecodeError:
                    return create_error_response(400, "Invalid JSON in request body")
            
            request_headers = event.get('headers', {})
            auth_result = verify_jwt_token(request_headers.get('Authorization', ''))
            if not auth_result['valid']:
                return create_error_response(401, "Invalid or missing token")
            
            return handle_create_recurring_investment(body, auth_result['user_id'])
        
        elif path == '/recurring-investments' and http_method == 'GET':
            # Get user's recurring investment plans - requires authentication
            request_headers = event.get('headers', {})
            auth_result = verify_jwt_token(request_headers.get('Authorization', ''))
            if not auth_result['valid']:
                return create_error_response(401, "Invalid or missing token")
            
            return handle_get_recurring_investments(auth_result['user_id'])
        
        elif path.startswith('/recurring-investments/') and http_method == 'PUT':
            # Update recurring investment plan - requires authentication
            body = {}
            if event.get('body'):
                try:
                    body = json.loads(event['body'])
                except json.JSONDecodeError:
                    return create_error_response(400, "Invalid JSON in request body")
            
            request_headers = event.get('headers', {})
            auth_result = verify_jwt_token(request_headers.get('Authorization', ''))
            if not auth_result['valid']:
                return create_error_response(401, "Invalid or missing token")
            
            try:
                recurring_id = int(path.split('/')[-1])
                return handle_update_recurring_investment(recurring_id, body, auth_result['user_id'])
            except ValueError:
                return create_error_response(400, "Invalid recurring investment ID")
        
        elif path.startswith('/recurring-investments/') and http_method == 'DELETE':
            # Delete recurring investment plan - requires authentication
            request_headers = event.get('headers', {})
            auth_result = verify_jwt_token(request_headers.get('Authorization', ''))
            if not auth_result['valid']:
                return create_error_response(401, "Invalid or missing token")
            
            try:
                recurring_id = int(path.split('/')[-1])
                return handle_delete_recurring_investment(recurring_id, auth_result['user_id'])
            except ValueError:
                return create_error_response(400, "Invalid recurring investment ID")
        
        # ============================================================================
        # MILESTONE 2 & 5: FIRE PROFILE ENDPOINTS
        # ============================================================================
        
        elif path == '/fire-profile' and http_method == 'POST':
            # Create or update FIRE profile - requires authentication
            body = {}
            if event.get('body'):
                try:
                    body = json.loads(event['body'])
                except json.JSONDecodeError:
                    return create_error_response(400, "Invalid JSON in request body")
            
            request_headers = event.get('headers', {})
            auth_result = verify_jwt_token(request_headers.get('Authorization', ''))
            if not auth_result['valid']:
                return create_error_response(401, "Invalid or missing token")
            
            return handle_create_or_update_fire_profile(body, auth_result['user_id'])
        
        elif path == '/fire-profile' and http_method == 'GET':
            # Get FIRE profile - requires authentication
            request_headers = event.get('headers', {})
            auth_result = verify_jwt_token(request_headers.get('Authorization', ''))
            if not auth_result['valid']:
                return create_error_response(401, "Invalid or missing token")
            
            return handle_get_fire_profile(auth_result['user_id'])
        
        elif path == '/recurring-investments/raw' and http_method == 'GET':
            # Get raw recurring investments data without currency conversion - requires authentication
            request_headers = event.get('headers', {})
            auth_result = verify_jwt_token(request_headers.get('Authorization', ''))
            if not auth_result['valid']:
                return create_error_response(401, "Invalid or missing token")
            
            return handle_get_raw_recurring_investments(auth_result['user_id'])
        
        elif path == '/fire-progress' and http_method == 'GET':
            # Calculate FIRE progress - requires authentication
            request_headers = event.get('headers', {})
            auth_result = verify_jwt_token(request_headers.get('Authorization', ''))
            if not auth_result['valid']:
                return create_error_response(401, "Invalid or missing token")
            
            return calculate_fire_progress(auth_result['user_id'])
        
        elif path == '/portfolio/performance' and http_method == 'GET':
            # Get portfolio performance - requires authentication
            request_headers = event.get('headers', {})
            auth_result = verify_jwt_token(request_headers.get('Authorization', ''))
            if not auth_result['valid']:
                return create_error_response(401, "Invalid or missing token")
            
            # Get period parameter (default to 12 months)
            query_params = event.get('queryStringParameters') or {}
            try:
                period_months = float(query_params.get('period', 12))
                # Ensure minimum period of 0.1 months to avoid division by zero
                period_months = max(period_months, 0.1)
            except (ValueError, TypeError):
                period_months = 12
            
            return handle_get_portfolio_performance(auth_result['user_id'], period_months)
        
        elif path == '/portfolio/performance/7day' and http_method == 'GET':
            # Get 7-day portfolio performance - requires authentication
            request_headers = event.get('headers', {})
            auth_result = verify_jwt_token(request_headers.get('Authorization', ''))
            if not auth_result['valid']:
                return create_error_response(401, "Invalid or missing token")
            
            return handle_get_7day_twr_performance(auth_result['user_id'])
        
        # ============================================================================
        # DIVIDEND MANAGEMENT ENDPOINTS
        # ============================================================================
        
        elif path == '/dividends' and http_method == 'GET':
            # Get user's dividends - requires authentication
            request_headers = event.get('headers', {})
            auth_result = verify_jwt_token(request_headers.get('Authorization', ''))
            if not auth_result['valid']:
                return create_error_response(401, "Invalid or missing token")
            
            return handle_get_dividends(auth_result['user_id'])
        
        elif path == '/dividends' and http_method == 'POST':
            # Create dividend - requires authentication
            body = {}
            if event.get('body'):
                try:
                    body = json.loads(event['body'])
                except json.JSONDecodeError:
                    return create_error_response(400, "Invalid JSON in request body")
            
            request_headers = event.get('headers', {})
            auth_result = verify_jwt_token(request_headers.get('Authorization', ''))
            if not auth_result['valid']:
                return create_error_response(401, "Invalid or missing token")
            
            return handle_create_dividend(body, auth_result['user_id'])
        
        elif path.startswith('/dividends/') and '/process' in path and http_method == 'POST':
            # Process dividend - requires authentication
            try:
                dividend_id = int(path.split('/')[2])
            except (ValueError, IndexError):
                return create_error_response(400, "Invalid dividend ID")
            
            body = {}
            if event.get('body'):
                try:
                    body = json.loads(event['body'])
                except json.JSONDecodeError:
                    return create_error_response(400, "Invalid JSON in request body")
            
            request_headers = event.get('headers', {})
            auth_result = verify_jwt_token(request_headers.get('Authorization', ''))
            if not auth_result['valid']:
                return create_error_response(401, "Invalid or missing token")
            
            return handle_process_dividend(dividend_id, body, auth_result['user_id'])
        
        elif path.startswith('/dividends/') and http_method == 'PUT':
            # Update dividend - requires authentication
            try:
                dividend_id = int(path.split('/')[2])
            except (ValueError, IndexError):
                return create_error_response(400, "Invalid dividend ID")
            
            body = {}
            if event.get('body'):
                try:
                    body = json.loads(event['body'])
                except json.JSONDecodeError:
                    return create_error_response(400, "Invalid JSON in request body")
            
            request_headers = event.get('headers', {})
            auth_result = verify_jwt_token(request_headers.get('Authorization', ''))
            if not auth_result['valid']:
                return create_error_response(401, "Invalid or missing token")
            
            return handle_update_dividend(dividend_id, body, auth_result['user_id'])
        
        elif path.startswith('/dividends/') and http_method == 'DELETE':
            # Delete dividend - requires authentication
            try:
                dividend_id = int(path.split('/')[2])
            except (ValueError, IndexError):
                return create_error_response(400, "Invalid dividend ID")
            
            request_headers = event.get('headers', {})
            auth_result = verify_jwt_token(request_headers.get('Authorization', ''))
            if not auth_result['valid']:
                return create_error_response(401, "Invalid or missing token")
            
            return handle_delete_dividend(dividend_id, auth_result['user_id'])
        
        elif path == '/dividends/auto-detect' and http_method == 'POST':
            # Auto-detect dividends - requires authentication
            request_headers = event.get('headers', {})
            auth_result = verify_jwt_token(request_headers.get('Authorization', ''))
            if not auth_result['valid']:
                return create_error_response(401, "Invalid or missing token")
            
            return handle_auto_detect_dividends(auth_result['user_id'])
        
        # ============================================================================
        # EXTERNAL API PROXY ENDPOINTS
        # ============================================================================
        elif path == '/api/exchange-rates' and http_method == 'GET':
            # Get exchange rates - requires authentication
            request_headers = event.get('headers', {})
            auth_result = verify_jwt_token(request_headers.get('Authorization', ''))
            if not auth_result['valid']:
                return create_error_response(401, "Invalid or missing token")
            
            # Get base currency from query parameters
            query_params = event.get('queryStringParameters') or {}
            base_currency = query_params.get('base', 'USD')
            
            return handle_get_exchange_rates(base_currency)
        
        elif path.startswith('/api/stock-price/') and http_method == 'GET':
            # Get single stock price - requires authentication
            request_headers = event.get('headers', {})
            auth_result = verify_jwt_token(request_headers.get('Authorization', ''))
            if not auth_result['valid']:
                return create_error_response(401, "Invalid or missing token")
            
            # Extract symbol from path
            symbol = path.split('/api/stock-price/')[-1]
            if not symbol:
                return create_error_response(400, "Stock symbol is required")
            
            return handle_get_stock_price(symbol)
        
        elif path == '/api/stock-prices' and http_method == 'POST':
            # Get multiple stock prices - requires authentication
            request_headers = event.get('headers', {})
            auth_result = verify_jwt_token(request_headers.get('Authorization', ''))
            if not auth_result['valid']:
                return create_error_response(401, "Invalid or missing token")
            
            body = {}
            if event.get('body'):
                try:
                    body = json.loads(event['body'])
                except json.JSONDecodeError:
                    return create_error_response(400, "Invalid JSON in request body")
            
            symbols = body.get('symbols', [])
            if not symbols:
                return create_error_response(400, "Symbols array is required")
            
            return handle_get_multiple_stock_prices(symbols)
        
        elif path == '/admin/delete-user' and http_method == 'DELETE':
            # Delete user endpoint (admin only)
            query_params = event.get('queryStringParameters') or {}
            email = query_params.get('email', '').strip().lower()
            
            if not email:
                return create_error_response(400, "Email parameter is required")
            
            try:
                # First check if user exists
                users = execute_query(
                    DATABASE_URL,
                    "SELECT user_id, name, email FROM users WHERE email = %s",
                    (email,)
                )
                
                if not users:
                    return create_error_response(404, f"User not found: {email}")
                
                user = users[0]
                user_id = user['user_id']
                
                # Delete user's related data first (foreign key constraints)
                # Delete transactions
                execute_query(
                    DATABASE_URL,
                    "DELETE FROM transactions WHERE asset_id IN (SELECT asset_id FROM assets WHERE user_id = %s)",
                    (user_id,)
                )
                
                # Delete assets
                execute_query(
                    DATABASE_URL,
                    "DELETE FROM assets WHERE user_id = %s",
                    (user_id,)
                )
                
                # Delete recurring investments
                execute_query(
                    DATABASE_URL,
                    "DELETE FROM recurring_investments WHERE user_id = %s",
                    (user_id,)
                )
                
                # Delete FIRE profiles
                execute_query(
                    DATABASE_URL,
                    "DELETE FROM fire_profiles WHERE user_id = %s",
                    (user_id,)
                )
                
                # Finally delete the user
                execute_query(
                    DATABASE_URL,
                    "DELETE FROM users WHERE user_id = %s",
                    (user_id,)
                )
                
                return create_response(200, {
                    "success": True,
                    "message": f"User {email} (ID: {user_id}, Name: {user['name']}) has been deleted successfully",
                    "deleted_user": {
                        "user_id": user_id,
                        "name": user['name'],
                        "email": user['email']
                    }
                })
                
            except Exception as e:
                logger.error(f"User deletion error: {str(e)}")
                return create_error_response(500, f"Failed to delete user: {str(e)}")
        
        elif path == '/admin/test-psycopg2' and http_method == 'GET':
            # Test psycopg2 specifically
            try:
                import sys
                import os
                
                # Check Python path
                python_path = sys.path
                
                # Try to import psycopg2
                try:
                    import psycopg2
                    psycopg2_status = f"âœ… psycopg2 {psycopg2.__version__} imported successfully"
                    psycopg2_file = psycopg2.__file__
                except ImportError as e:
                    psycopg2_status = f"âŒ psycopg2 import failed: {str(e)}"
                    psycopg2_file = "Not available"
                
                # Check if /opt/python is in path
                opt_python_in_path = "/opt/python" in python_path
                
                # List contents of /opt/python if it exists
                opt_python_contents = []
                try:
                    import os
                    if os.path.exists("/opt/python"):
                        opt_python_contents = os.listdir("/opt/python")[:10]  # First 10 items
                    else:
                        opt_python_contents = ["Directory does not exist"]
                except Exception as e:
                    opt_python_contents = [f"Error listing: {str(e)}"]
                
                return create_response(200, {
                    "psycopg2_status": psycopg2_status,
                    "psycopg2_file": psycopg2_file,
                    "python_path": python_path,
                    "opt_python_in_path": opt_python_in_path,
                    "opt_python_contents": opt_python_contents,
                    "pythonpath_env": os.environ.get('PYTHONPATH', 'Not set'),
                    "lambda_runtime_dir": os.environ.get('LAMBDA_RUNTIME_DIR', 'Not set'),
                    "lambda_task_root": os.environ.get('LAMBDA_TASK_ROOT', 'Not set')
                })
                
            except Exception as e:
                return create_error_response(500, f"Test error: {str(e)}")
        
        elif path == '/admin/db-test' and http_method == 'GET':
            # Test database connectivity
            try:
                # Test basic connection
                result = execute_query(DATABASE_URL, "SELECT version(), current_database(), current_user")
                
                if result:
                    db_info = result[0]
                    
                    # Test if tables exist
                    tables = execute_query(
                        DATABASE_URL,
                        "SELECT table_name FROM information_schema.tables WHERE table_schema = 'public'"
                    )
                    
                    table_list = [table['table_name'] for table in tables]
                    
                    return create_response(200, {
                        "database_connected": True,
                        "database_info": {
                            "version": db_info['version'],
                            "database": db_info['current_database'],
                            "user": db_info['current_user']
                        },
                        "tables": table_list,
                        "database_url_preview": DATABASE_URL[:50] + "..." if len(DATABASE_URL) > 50 else DATABASE_URL
                    })
                else:
                    return create_error_response(500, "No result from database query")
                    
            except Exception as e:
                logger.error(f"Database connectivity test error: {str(e)}")
                return create_error_response(500, f"Database connection failed: {str(e)}")
        
        elif path == '/admin/list-users' and http_method == 'GET':
            # Temporary admin endpoint to list all users (for debugging)
            try:
                users = execute_query(
                    DATABASE_URL,
                    "SELECT user_id, name, email, base_currency, birth_year, created_at FROM users ORDER BY created_at DESC LIMIT 10"
                )
                
                user_list = []
                for user in users:
                    user_list.append({
                        "user_id": user['user_id'],
                        "name": user['name'],
                        "email": user['email'],
                        "base_currency": user['base_currency'],
                        "birth_year": user['birth_year'],
                        "created_at": user['created_at'].isoformat()
                    })
                
                return create_response(200, {
                    "total_users": len(user_list),
                    "users": user_list
                })
                    
            except Exception as e:
                logger.error(f"Database query error: {str(e)}")
                return create_error_response(500, f"Database error: {str(e)}")
        
        elif path == '/admin/check-user' and http_method == 'GET':
            # Temporary admin endpoint to check user existence
            query_params = event.get('queryStringParameters') or {}
            email = query_params.get('email', '').strip().lower()
            
            if not email:
                return create_error_response(400, "Email parameter is required")
            
            try:
                # Check if user exists
                users = execute_query(
                    DATABASE_URL,
                    "SELECT user_id, name, email, base_currency, birth_year, created_at FROM users WHERE email = %s",
                    (email,)
                )
                
                if users:
                    user = users[0]
                    
                    # Get user's assets
                    assets = execute_query(
                        DATABASE_URL,
                        "SELECT * FROM assets WHERE user_id = %s ORDER BY ticker_symbol",
                        (user['user_id'],)
                    )
                    
                    # Get user's transactions
                    transactions = execute_query(
                        DATABASE_URL,
                        """
                        SELECT t.*, a.ticker_symbol, a.asset_type 
                        FROM transactions t
                        JOIN assets a ON t.asset_id = a.asset_id
                        WHERE a.user_id = %s
                        ORDER BY t.transaction_date DESC, t.created_at DESC
                        """,
                        (user['user_id'],)
                    )
                    
                    # Get user's dividends
                    dividends = execute_query(
                        DATABASE_URL,
                        """
                        SELECT d.*, a.ticker_symbol, a.total_shares as shares_owned, a.currency as asset_currency
                        FROM dividends d
                        JOIN assets a ON d.asset_id = a.asset_id
                        WHERE d.user_id = %s
                        ORDER BY d.payment_date DESC, d.created_at DESC
                        """,
                        (user['user_id'],)
                    )
                    
                    # Format the data
                    asset_list = []
                    for asset in assets:
                        asset_list.append({
                            "asset_id": asset['asset_id'],
                            "ticker_symbol": asset['ticker_symbol'],
                            "asset_type": asset['asset_type'],
                            "total_shares": float(asset['total_shares']),
                            "average_cost_basis": float(asset['average_cost_basis']),
                            "currency": asset['currency'],
                            "created_at": asset['created_at'].isoformat()
                        })
                    
                    transaction_list = []
                    for txn in transactions:
                        transaction_list.append({
                            "transaction_id": txn['transaction_id'],
                            "asset_id": txn['asset_id'],
                            "ticker_symbol": txn['ticker_symbol'],
                            "asset_type": txn['asset_type'],
                            "transaction_type": txn['transaction_type'],
                            "transaction_date": txn['transaction_date'].isoformat(),
                            "shares": float(txn['shares']),
                            "price_per_share": float(txn['price_per_share']),
                            "total_amount": float(txn['shares']) * float(txn['price_per_share']),
                            "currency": txn['currency'],
                            "created_at": txn['created_at'].isoformat()
                        })
                    
                    dividend_list = []
                    for div in dividends:
                        dividend_list.append({
                            "dividend_id": div['dividend_id'],
                            "asset_id": div['asset_id'],
                            "ticker_symbol": div['ticker_symbol'],
                            "dividend_per_share": float(div['dividend_per_share']),
                            "total_dividend_amount": float(div['total_dividend_amount']),
                            "shares_owned": float(div['shares_owned']),
                            "currency": div['asset_currency'],
                            "ex_dividend_date": div['ex_dividend_date'].isoformat() if div['ex_dividend_date'] else None,
                            "payment_date": div['payment_date'].isoformat() if div['payment_date'] else None,
                            "is_reinvested": div.get('is_reinvested', False),
                            "created_at": div['created_at'].isoformat()
                        })
                    
                    return create_response(200, {
                        "user_found": True,
                        "user": {
                            "user_id": user['user_id'],
                            "name": user['name'],
                            "email": user['email'],
                            "base_currency": user['base_currency'],
                            "birth_year": user['birth_year'],
                            "created_at": user['created_at'].isoformat()
                        },
                        "assets": asset_list,
                        "transactions": transaction_list,
                        "dividends": dividend_list,
                        "summary": {
                            "total_assets": len(asset_list),
                            "total_transactions": len(transaction_list),
                            "total_dividends": len(dividend_list)
                        }
                    })
                else:
                    return create_response(200, {
                        "user_found": False,
                        "message": f"No user found with email: {email}"
                    })
                    
            except Exception as e:
                logger.error(f"Check user error: {str(e)}")
                return create_error_response(500, f"Database error: {str(e)}")
        
        elif path == '/test/stock-prices' and http_method == 'GET':
            # Test stock prices without authentication
            query_params = event.get('queryStringParameters') or {}
            return handle_get_stock_prices_multi_api(query_params)
        
        elif path == '/api/stock-prices-multi' and http_method == 'GET':
            # Get stock prices with multi-API fallback - requires authentication
            request_headers = event.get('headers', {})
            auth_result = verify_jwt_token(request_headers.get('Authorization', ''))
            if not auth_result['valid']:
                return create_error_response(401, "Invalid or missing token")
            
            query_params = event.get('queryStringParameters') or {}
            return handle_get_stock_prices_multi_api(query_params)
        
        elif path == '/batch/recurring-investments' and http_method == 'POST':
            # Batch processing for recurring investments - no authentication required (internal)
            return handle_batch_processing()
        
        else:
            return create_error_response(404, f"Endpoint not found: {path}")
        
    except Exception as e:
        logger.error(f"Unhandled error: {str(e)}", exc_info=True)
        return create_error_response(500, "Internal server error")
